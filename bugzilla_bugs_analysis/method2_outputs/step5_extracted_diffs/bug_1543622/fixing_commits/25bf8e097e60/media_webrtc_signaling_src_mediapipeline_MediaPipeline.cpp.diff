# ==============================================================================
# FIXING COMMIT DIFF
# ==============================================================================
# File: media/webrtc/signaling/src/mediapipeline/MediaPipeline.cpp
# Commit: 25bf8e097e60
# Full Hash: 25bf8e097e604cca2842af6754c2c1698db5618a
# Author: Dan Minor <dminor@mozilla.com>
# Date: 2019-10-29 21:27:48
# Description:
#   Bug 1543622 - Make number of channels out param of GetAudioFrame; r=pehrsons
#   
#   The number of channels is available in mAudioFrame in GetAudioFrame so
#   there is no reason to calculate it after the fact in MediaPipeline.
#   
# ==============================================================================

diff -r 4139bfe5e7f9 -r 25bf8e097e60 media/webrtc/signaling/src/mediapipeline/MediaPipeline.cpp
--- a/media/webrtc/signaling/src/mediapipeline/MediaPipeline.cpp	Tue Oct 29 16:04:29 2019 +0000
+++ b/media/webrtc/signaling/src/mediapipeline/MediaPipeline.cpp	Tue Oct 29 17:30:03 2019 +0000
@@ -1320,11 +1320,12 @@
     // in the graph rate.
 
     while (mPlayedTicks < aDesiredTime) {
-      const int scratchBufferLength =
+      constexpr size_t scratchBufferLength =
           AUDIO_SAMPLE_BUFFER_MAX_BYTES / sizeof(int16_t);
       int16_t scratchBuffer[scratchBufferLength];
 
-      int samplesLength = scratchBufferLength;
+      size_t channelCount = 0;
+      size_t samplesLength = scratchBufferLength;
 
       // This fetches 10ms of data, either mono or stereo
       MediaConduitErrorCode err =
@@ -1332,7 +1333,7 @@
               ->GetAudioFrame(scratchBuffer, mRate,
                               0,  // TODO(ekr@rtfm.com): better estimate of
                                   // "capture" (really playout) delay
-                              samplesLength);
+                              channelCount, samplesLength);
 
       if (err != kMediaConduitNoError) {
         // Insert silence on conduit/GIPS failure (extremely unlikely)
@@ -1341,6 +1342,7 @@
                  " (desired %" PRId64 " -> %f)",
                  err, mPlayedTicks, aDesiredTime,
                  mSource->TrackTimeToSeconds(aDesiredTime)));
+        channelCount = 1;
         // if this is not enough we'll loop and provide more
         samplesLength = samplesPer10ms;
         PodArrayZero(scratchBuffer);
@@ -1349,16 +1351,12 @@
       MOZ_RELEASE_ASSERT(samplesLength <= scratchBufferLength);
 
       MOZ_LOG(gMediaPipelineLog, LogLevel::Debug,
-              ("Audio conduit returned buffer of length %u", samplesLength));
+              ("Audio conduit returned buffer of length %zu", samplesLength));
 
       RefPtr<SharedBuffer> samples =
           SharedBuffer::Create(samplesLength * sizeof(uint16_t));
       int16_t* samplesData = static_cast<int16_t*>(samples->Data());
       AudioSegment segment;
-      // We derive the number of channels of the stream from the number of
-      // samples the AudioConduit gives us, considering it gives us packets of
-      // 10ms and we know the rate.
-      uint32_t channelCount = samplesLength / samplesPer10ms;
       AutoTArray<int16_t*, 2> channels;
       AutoTArray<const int16_t*, 2> outputChannels;
       size_t frames = samplesLength / channelCount;
