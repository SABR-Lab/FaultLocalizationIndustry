# ==============================================================================
# REGRESSOR COMMIT DIFF
# ==============================================================================
# File: media/webrtc/signaling/src/mediapipeline/MediaPipeline.cpp
# Commit: 6a52b92ff037
# Full Hash: 6a52b92ff03731a1e2ef13aa7f7349a1e7e48bee
# Author: Dan Minor <dminor@mozilla.com>
# Date: 2018-11-03 09:44:53
# Regressor Bug: 1376873
# File Overlap Count: 1
# Description:
#   Bug 1376873 - Mediapipeline updates; r=pehrsons
#   
#   Support for native_handle() has been removed by upstream.
#   
#   Differential Revision: https://phabricator.services.mozilla.com/D7437
# ==============================================================================

diff -r 6a6771656fe5 -r 6a52b92ff037 media/webrtc/signaling/src/mediapipeline/MediaPipeline.cpp
--- a/media/webrtc/signaling/src/mediapipeline/MediaPipeline.cpp	Thu Feb 15 15:14:58 2018 -0500
+++ b/media/webrtc/signaling/src/mediapipeline/MediaPipeline.cpp	Fri Feb 16 09:15:44 2018 -0500
@@ -49,11 +49,10 @@
 #include "Tracing.h"
 #include "WebrtcImageBuffer.h"
 
-#include "webrtc/base/bind.h"
-#include "webrtc/base/keep_ref_until_done.h"
+#include "webrtc/rtc_base/bind.h"
+#include "webrtc/rtc_base/keep_ref_until_done.h"
 #include "webrtc/common_video/include/i420_buffer_pool.h"
 #include "webrtc/common_video/include/video_frame_buffer.h"
-#include "webrtc/video_frame.h"
 
 // Max size given stereo is 480*2*2 = 1920 (10ms of 16-bits stereo audio at
 // 48KHz)
@@ -2053,24 +2052,24 @@
     MOZ_ASSERT(aBuffer.type() == webrtc::VideoFrameBuffer::Type::kI420);
     rtc::scoped_refptr<const webrtc::I420BufferInterface> i420 = aBuffer.GetI420();
 
-    MOZ_ASSERT(aBuffer.DataY());
+    MOZ_ASSERT(i420->DataY());
     // Create a video frame using |buffer|.
     RefPtr<PlanarYCbCrImage> yuvImage =
       mImageContainer->CreatePlanarYCbCrImage();
 
     PlanarYCbCrData yuvData;
-    yuvData.mYChannel = const_cast<uint8_t*>(aBuffer.DataY());
-    yuvData.mYSize = IntSize(aBuffer.width(), aBuffer.height());
-    yuvData.mYStride = aBuffer.StrideY();
-    MOZ_ASSERT(aBuffer.StrideU() == aBuffer.StrideV());
-    yuvData.mCbCrStride = aBuffer.StrideU();
-    yuvData.mCbChannel = const_cast<uint8_t*>(aBuffer.DataU());
-    yuvData.mCrChannel = const_cast<uint8_t*>(aBuffer.DataV());
+    yuvData.mYChannel = const_cast<uint8_t*>(i420->DataY());
+    yuvData.mYSize = IntSize(i420->width(), i420->height());
+    yuvData.mYStride = i420->StrideY();
+    MOZ_ASSERT(i420->StrideU() == i420->StrideV());
+    yuvData.mCbCrStride = i420->StrideU();
+    yuvData.mCbChannel = const_cast<uint8_t*>(i420->DataU());
+    yuvData.mCrChannel = const_cast<uint8_t*>(i420->DataV());
     yuvData.mCbCrSize =
-      IntSize((aBuffer.width() + 1) >> 1, (aBuffer.height() + 1) >> 1);
+      IntSize((i420->width() + 1) >> 1, (i420->height() + 1) >> 1);
     yuvData.mPicX = 0;
     yuvData.mPicY = 0;
-    yuvData.mPicSize = IntSize(aBuffer.width(), aBuffer.height());
+    yuvData.mPicSize = IntSize(i420->width(), i420->height());
     yuvData.mStereoMode = StereoMode::MONO;
 
     if (!yuvImage->CopyData(yuvData)) {