# ==============================================================================
# REGRESSOR COMMIT DIFF
# ==============================================================================
# File: tools/profiler/core/ProfileBuffer.cpp
# Commit: d7ee4148aad9
# Full Hash: d7ee4148aad9c8416749b5054afb393ecf40c8f7
# Author: Gerald Squelart <gsquelart@mozilla.com>
# Date: 2019-09-17 15:54:53
# Regressor Bug: 1576551
# File Overlap Count: 2
# Description:
#   Bug 1576551 - Use BlocksRingBuffer in ProfileBuffer - r=gregtatum
#   
#   This just replaces `ProfileBuffer`'s self-managed circular buffer with a
#   `BlocksRingBuffer`.
#   
# ==============================================================================

diff -r ec72dfc7301e -r d7ee4148aad9 tools/profiler/core/ProfileBuffer.cpp
--- a/tools/profiler/core/ProfileBuffer.cpp	Tue Sep 17 01:49:37 2019 +0000
+++ b/tools/profiler/core/ProfileBuffer.cpp	Tue Sep 17 01:49:59 2019 +0000
@@ -16,11 +16,14 @@
 
 using namespace mozilla;
 
+// 65536 bytes should be plenty for a single backtrace.
+static constexpr auto DuplicationBufferBytes = MakePowerOfTwo32<65536>();
+
+// mEntries doesn't need its own mutex, because it is guarded by gPSMutex.
 ProfileBuffer::ProfileBuffer(PowerOfTwo32 aCapacity)
-    : mEntries(MakeUnique<ProfileBufferEntry[]>(aCapacity.Value())),
-      mEntryIndexMask(aCapacity.Mask()),
-      mRangeStart(0),
-      mRangeEnd(0) {}
+    : mEntries(BlocksRingBuffer::ThreadSafety::WithoutMutex, aCapacity),
+      mDuplicationBuffer(MakeUnique<BlocksRingBuffer::Byte[]>(
+          DuplicationBufferBytes.Value())) {}
 
 ProfileBuffer::~ProfileBuffer() {
   while (mStoredMarkers.peek()) {
@@ -28,26 +31,43 @@
   }
 }
 
-// Called from signal, call only reentrant functions
-void ProfileBuffer::AddEntry(const ProfileBufferEntry& aEntry) {
-  GetEntry(mRangeEnd++) = aEntry;
+/* static */
+BlocksRingBuffer::BlockIndex ProfileBuffer::AddEntry(
+    BlocksRingBuffer& aBlocksRingBuffer, const ProfileBufferEntry& aEntry) {
+  switch (aEntry.GetKind()) {
+#define SWITCH_KIND(KIND, TYPE, SIZE)                      \
+  case ProfileBufferEntry::Kind::KIND: {                   \
+    return aBlocksRingBuffer.PutFrom(&aEntry, 1 + (SIZE)); \
+    break;                                                 \
+  }
 
-  // The distance between mRangeStart and mRangeEnd must never exceed
-  // capacity, so advance mRangeStart if necessary.
-  if (mRangeEnd - mRangeStart > mEntryIndexMask.MaskValue() + 1) {
-    mRangeStart++;
+    FOR_EACH_PROFILE_BUFFER_ENTRY_KIND(SWITCH_KIND)
+
+#undef SWITCH_KIND
+    default:
+      MOZ_ASSERT(false, "Unhandled ProfilerBuffer entry KIND");
+      return BlockIndex{};
   }
 }
 
-uint64_t ProfileBuffer::AddThreadIdEntry(int aThreadId) {
-  uint64_t pos = mRangeEnd;
-  AddEntry(ProfileBufferEntry::ThreadId(aThreadId));
-  return pos;
+// Called from signal, call only reentrant functions
+uint64_t ProfileBuffer::AddEntry(const ProfileBufferEntry& aEntry) {
+  return AddEntry(mEntries, aEntry).ConvertToU64();
 }
 
-void ProfileBuffer::AddStoredMarker(ProfilerMarker* aStoredMarker) {
-  aStoredMarker->SetPositionInBuffer(mRangeEnd);
-  mStoredMarkers.insert(aStoredMarker);
+/* static */
+BlocksRingBuffer::BlockIndex ProfileBuffer::AddThreadIdEntry(
+    BlocksRingBuffer& aBlocksRingBuffer, int aThreadId) {
+  return AddEntry(aBlocksRingBuffer, ProfileBufferEntry::ThreadId(aThreadId));
+}
+
+uint64_t ProfileBuffer::AddThreadIdEntry(int aThreadId) {
+  return AddThreadIdEntry(mEntries, aThreadId).ConvertToU64();
+}
+
+void ProfileBuffer::AddMarker(ProfilerMarker* aMarker) {
+  aMarker->SetPositionInBuffer(AddEntry(ProfileBufferEntry::Marker(aMarker)));
+  mStoredMarkers.insert(aMarker);
 }
 
 void ProfileBuffer::CollectCodeLocation(
@@ -93,22 +113,21 @@
   // Delete markers of samples that have been overwritten due to circular
   // buffer wraparound.
   while (mStoredMarkers.peek() &&
-         mStoredMarkers.peek()->HasExpired(mRangeStart)) {
+         mStoredMarkers.peek()->HasExpired(BufferRangeStart())) {
     delete mStoredMarkers.popHead();
   }
 }
 
-size_t ProfileBuffer::SizeOfIncludingThis(
-    mozilla::MallocSizeOf aMallocSizeOf) const {
-  size_t n = aMallocSizeOf(this);
-  n += aMallocSizeOf(mEntries.get());
-
+size_t ProfileBuffer::SizeOfExcludingThis(MallocSizeOf aMallocSizeOf) const {
   // Measurement of the following members may be added later if DMD finds it
   // is worthwhile:
   // - memory pointed to by the elements within mEntries
   // - mStoredMarkers
+  return mEntries.SizeOfExcludingThis(aMallocSizeOf);
+}
 
-  return n;
+size_t ProfileBuffer::SizeOfIncludingThis(MallocSizeOf aMallocSizeOf) const {
+  return aMallocSizeOf(this) + SizeOfExcludingThis(aMallocSizeOf);
 }
 
 void ProfileBuffer::CollectOverheadStats(TimeDuration aSamplingTime,
@@ -146,9 +165,10 @@
 }
 
 ProfilerBufferInfo ProfileBuffer::GetProfilerBufferInfo() const {
-  return {mRangeStart,  mRangeEnd,    mEntryIndexMask.MaskValue() + 1,
-          mIntervalsNs, mOverheadsNs, mLockingsNs,
-          mCleaningsNs, mCountersNs,  mThreadsNs};
+  return {
+      BufferRangeStart(), BufferRangeEnd(), mEntries.BufferLength()->Value(),
+      mIntervalsNs,       mOverheadsNs,     mLockingsNs,
+      mCleaningsNs,       mCountersNs,      mThreadsNs};
 }
 
 /* ProfileBufferCollector */