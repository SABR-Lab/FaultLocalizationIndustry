# ==============================================================================
# REGRESSOR COMMIT DIFF
# ==============================================================================
# File: dom/media/MediaDecoderStateMachine.cpp
# Commit: c57c41e8c39e
# Full Hash: c57c41e8c39ea51e96c13af8ecdcbe1640e2a9d6
# Author: Andreas Pehrson <apehrson@mozilla.com>
# Date: 2019-11-14 17:12:31
# Regressor Bug: 1172394
# File Overlap Count: 1
# Description:
#   Bug 1172394 - Refactor how DecodedStream is set up. r=padenot
#   
#   This patch removes the responsibility of js-facing MediaStreamTracks from the
#   MediaDecoder stack, and moves the machinery for setting up DecodedStream to
#   higher order functions like state mirroring and watchables.
# ==============================================================================

diff -r a796541fe5ef -r c57c41e8c39e dom/media/MediaDecoderStateMachine.cpp
--- a/dom/media/MediaDecoderStateMachine.cpp	Wed Nov 13 08:55:29 2019 +0000
+++ b/dom/media/MediaDecoderStateMachine.cpp	Wed Nov 13 08:55:39 2019 +0000
@@ -11,7 +11,6 @@
 #include "mediasink/AudioSink.h"
 #include "mediasink/AudioSinkWrapper.h"
 #include "mediasink/DecodedStream.h"
-#include "mediasink/OutputStreamManager.h"
 #include "mediasink/VideoSink.h"
 #include "mozilla/Logging.h"
 #include "mozilla/MathAlgorithms.h"
@@ -2592,6 +2591,9 @@
   master->mVolume.DisconnectIfConnected();
   master->mPreservesPitch.DisconnectIfConnected();
   master->mLooping.DisconnectIfConnected();
+  master->mOutputCaptured.DisconnectIfConnected();
+  master->mOutputTracks.DisconnectIfConnected();
+  master->mOutputPrincipal.DisconnectIfConnected();
 
   master->mDuration.DisconnectAll();
   master->mCurrentPosition.DisconnectAll();
@@ -2627,12 +2629,10 @@
       mReader(new ReaderProxy(mTaskQueue, aReader)),
       mPlaybackRate(1.0),
       mAmpleAudioThreshold(detail::AMPLE_AUDIO_THRESHOLD),
-      mAudioCaptured(false),
       mMinimizePreroll(aDecoder->GetMinimizePreroll()),
       mSentFirstFrameLoadedEvent(false),
       mVideoDecodeSuspended(false),
       mVideoDecodeSuspendTimer(mTaskQueue),
-      mOutputStreamManager(nullptr),
       mVideoDecodeMode(VideoDecodeMode::Normal),
       mIsMSE(aDecoder->IsMSE()),
       mSeamlessLoopingAllowed(false),
@@ -2641,6 +2641,12 @@
       INIT_MIRROR(mVolume, 1.0),
       INIT_MIRROR(mPreservesPitch, true),
       INIT_MIRROR(mLooping, false),
+      INIT_MIRROR(mOutputCaptured, false),
+      INIT_MIRROR(mOutputTracks, nsTArray<RefPtr<ProcessedMediaTrack>>()),
+      INIT_MIRROR(mOutputPrincipal, PRINCIPAL_HANDLE_NONE),
+      INIT_CANONICAL(mCanonicalOutputTracks,
+                     nsTArray<RefPtr<ProcessedMediaTrack>>()),
+      INIT_CANONICAL(mCanonicalOutputPrincipal, PRINCIPAL_HANDLE_NONE),
       INIT_CANONICAL(mDuration, NullableTimeUnit()),
       INIT_CANONICAL(mCurrentPosition, TimeUnit::Zero()),
       INIT_CANONICAL(mIsAudioDataAudible, false),
@@ -2671,6 +2677,9 @@
   mVolume.Connect(aDecoder->CanonicalVolume());
   mPreservesPitch.Connect(aDecoder->CanonicalPreservesPitch());
   mLooping.Connect(aDecoder->CanonicalLooping());
+  mOutputCaptured.Connect(aDecoder->CanonicalOutputCaptured());
+  mOutputTracks.Connect(aDecoder->CanonicalOutputTracks());
+  mOutputPrincipal.Connect(aDecoder->CanonicalOutputPrincipal());
 
   // Initialize watchers.
   mWatchManager.Watch(mBuffered,
@@ -2680,6 +2689,14 @@
                       &MediaDecoderStateMachine::PreservesPitchChanged);
   mWatchManager.Watch(mPlayState, &MediaDecoderStateMachine::PlayStateChanged);
   mWatchManager.Watch(mLooping, &MediaDecoderStateMachine::LoopingChanged);
+  mWatchManager.Watch(mOutputCaptured,
+                      &MediaDecoderStateMachine::UpdateOutputCaptured);
+  mWatchManager.Watch(mOutputTracks,
+                      &MediaDecoderStateMachine::UpdateOutputCaptured);
+  mWatchManager.Watch(mOutputTracks,
+                      &MediaDecoderStateMachine::OutputTracksChanged);
+  mWatchManager.Watch(mOutputPrincipal,
+                      &MediaDecoderStateMachine::OutputPrincipalChanged);
 
   MOZ_ASSERT(!mStateObj);
   auto* s = new DecodeMetadataState(this);
@@ -2708,12 +2725,11 @@
 }
 
 already_AddRefed<MediaSink> MediaDecoderStateMachine::CreateMediaSink(
-    bool aAudioCaptured, OutputStreamManager* aManager) {
-  MOZ_ASSERT_IF(aAudioCaptured, aManager);
+    bool aOutputCaptured) {
   RefPtr<MediaSink> audioSink =
-      aAudioCaptured ? new DecodedStream(mTaskQueue, mAbstractMainThread,
-                                         mAudioQueue, mVideoQueue, aManager)
-                     : CreateAudioSink();
+      aOutputCaptured
+          ? new DecodedStream(this, mOutputTracks, mAudioQueue, mVideoQueue)
+          : CreateAudioSink();
 
   RefPtr<MediaSink> mediaSink =
       new VideoSink(mTaskQueue, audioSink, mVideoQueue, mVideoFrameContainer,
@@ -2803,7 +2819,7 @@
   mOnMediaNotSeekable = mReader->OnMediaNotSeekable().Connect(
       OwnerThread(), this, &MediaDecoderStateMachine::SetMediaNotSeekable);
 
-  mMediaSink = CreateMediaSink(mAudioCaptured, mOutputStreamManager);
+  mMediaSink = CreateMediaSink(mOutputCaptured);
 
   nsresult rv = mReader->Init();
   NS_ENSURE_SUCCESS(rv, rv);
@@ -3340,9 +3356,6 @@
 
 RefPtr<ShutdownPromise> MediaDecoderStateMachine::BeginShutdown() {
   MOZ_ASSERT(NS_IsMainThread());
-  if (mOutputStreamManager) {
-    mOutputStreamManager->Disconnect();
-  }
   return InvokeAsync(OwnerThread(), this, __func__,
                      &MediaDecoderStateMachine::Shutdown);
 }
@@ -3431,7 +3444,7 @@
     }
   }
   // Note we have to update playback position before releasing the monitor.
-  // Otherwise, MediaDecoder::AddOutputStream could kick in when we are outside
+  // Otherwise, MediaDecoder::AddOutputTrack could kick in when we are outside
   // the monitor and get a staled value from GetCurrentTimeUs() which hits the
   // assertion in GetClock().
 
@@ -3517,6 +3530,41 @@
   }
 }
 
+void MediaDecoderStateMachine::UpdateOutputCaptured() {
+  MOZ_ASSERT(OnTaskQueue());
+
+  // Reset these flags so they are consistent with the status of the sink.
+  // TODO: Move these flags into MediaSink to improve cohesion so we don't need
+  // to reset these flags when switching MediaSinks.
+  mAudioCompleted = false;
+  mVideoCompleted = false;
+
+  // Stop and shut down the existing sink.
+  StopMediaSink();
+  mMediaSink->Shutdown();
+
+  // Create a new sink according to whether output is captured.
+  mMediaSink = CreateMediaSink(mOutputCaptured);
+
+  // Don't buffer as much when audio is captured because we don't need to worry
+  // about high latency audio devices.
+  mAmpleAudioThreshold = mOutputCaptured ? detail::AMPLE_AUDIO_THRESHOLD / 2
+                                         : detail::AMPLE_AUDIO_THRESHOLD;
+
+  mStateObj->HandleAudioCaptured();
+}
+
+void MediaDecoderStateMachine::OutputTracksChanged() {
+  MOZ_ASSERT(OnTaskQueue());
+  LOG("OutputTracksChanged, tracks=%zu", mOutputTracks.Ref().Length());
+  mCanonicalOutputTracks = mOutputTracks;
+}
+
+void MediaDecoderStateMachine::OutputPrincipalChanged() {
+  MOZ_ASSERT(OnTaskQueue());
+  mCanonicalOutputPrincipal = mOutputPrincipal;
+}
+
 RefPtr<GenericPromise> MediaDecoderStateMachine::InvokeSetSink(
     RefPtr<AudioDeviceInfo> aSink) {
   MOZ_ASSERT(NS_IsMainThread());
@@ -3530,7 +3578,7 @@
 RefPtr<GenericPromise> MediaDecoderStateMachine::SetSink(
     RefPtr<AudioDeviceInfo> aSink) {
   MOZ_ASSERT(OnTaskQueue());
-  if (mAudioCaptured) {
+  if (mOutputCaptured) {
     // Not supported yet.
     return GenericPromise::CreateAndReject(NS_ERROR_ABORT, __func__);
   }
@@ -3656,43 +3704,6 @@
   DecodeError(MediaResult(NS_ERROR_DOM_MEDIA_MEDIASINK_ERR, __func__));
 }
 
-void MediaDecoderStateMachine::SetAudioCaptured(bool aCaptured,
-                                                OutputStreamManager* aManager) {
-  MOZ_ASSERT(OnTaskQueue());
-
-  if (aCaptured == mAudioCaptured) {
-    return;
-  }
-
-  // Rest these flags so they are consistent with the status of the sink.
-  // TODO: Move these flags into MediaSink to improve cohesion so we don't need
-  // to reset these flags when switching MediaSinks.
-  mAudioCompleted = false;
-  mVideoCompleted = false;
-
-  // Backup current playback parameters.
-  MediaSink::PlaybackParams params = mMediaSink->GetPlaybackParams();
-
-  // Stop and shut down the existing sink.
-  StopMediaSink();
-  mMediaSink->Shutdown();
-
-  // Create a new sink according to whether audio is captured.
-  mMediaSink = CreateMediaSink(aCaptured, aManager);
-
-  // Restore playback parameters.
-  mMediaSink->SetPlaybackParams(params);
-
-  mAudioCaptured = aCaptured;
-
-  // Don't buffer as much when audio is captured because we don't need to worry
-  // about high latency audio devices.
-  mAmpleAudioThreshold = mAudioCaptured ? detail::AMPLE_AUDIO_THRESHOLD / 2
-                                        : detail::AMPLE_AUDIO_THRESHOLD;
-
-  mStateObj->HandleAudioCaptured();
-}
-
 uint32_t MediaDecoderStateMachine::GetAmpleVideoFrames() const {
   MOZ_ASSERT(OnTaskQueue());
   return mReader->VideoIsHardwareAccelerated()
@@ -3736,86 +3747,6 @@
   return p.forget();
 }
 
-void MediaDecoderStateMachine::SetOutputStreamPrincipal(
-    nsIPrincipal* aPrincipal) {
-  MOZ_ASSERT(NS_IsMainThread());
-  mOutputStreamPrincipal = aPrincipal;
-  if (mOutputStreamManager) {
-    mOutputStreamManager->SetPrincipal(mOutputStreamPrincipal);
-  }
-}
-
-void MediaDecoderStateMachine::AddOutputStream(DOMMediaStream* aStream) {
-  MOZ_ASSERT(NS_IsMainThread());
-  LOG("AddOutputStream aStream=%p!", aStream);
-  mOutputStreamManager->Add(aStream);
-  nsCOMPtr<nsIRunnable> r =
-      NS_NewRunnableFunction("MediaDecoderStateMachine::SetAudioCaptured",
-                             [self = RefPtr<MediaDecoderStateMachine>(this),
-                              manager = mOutputStreamManager]() {
-                               self->SetAudioCaptured(true, manager);
-                             });
-  nsresult rv = OwnerThread()->Dispatch(r.forget());
-  MOZ_DIAGNOSTIC_ASSERT(NS_SUCCEEDED(rv));
-  Unused << rv;
-}
-
-void MediaDecoderStateMachine::RemoveOutputStream(DOMMediaStream* aStream) {
-  MOZ_ASSERT(NS_IsMainThread());
-  LOG("RemoveOutputStream=%p!", aStream);
-  mOutputStreamManager->Remove(aStream);
-  if (mOutputStreamManager->IsEmpty()) {
-    mOutputStreamManager->Disconnect();
-    mOutputStreamManager = nullptr;
-    nsCOMPtr<nsIRunnable> r = NS_NewRunnableFunction(
-        "MediaDecoderStateMachine::SetAudioCaptured",
-        [self = RefPtr<MediaDecoderStateMachine>(this)]() {
-          self->SetAudioCaptured(false);
-        });
-    nsresult rv = OwnerThread()->Dispatch(r.forget());
-    MOZ_DIAGNOSTIC_ASSERT(NS_SUCCEEDED(rv));
-    Unused << rv;
-  }
-}
-
-void MediaDecoderStateMachine::EnsureOutputStreamManager(
-    SharedDummyTrack* aDummyStream) {
-  MOZ_ASSERT(NS_IsMainThread());
-  if (mOutputStreamManager) {
-    return;
-  }
-  mOutputStreamManager = new OutputStreamManager(
-      aDummyStream, mOutputStreamPrincipal, mAbstractMainThread);
-}
-
-void MediaDecoderStateMachine::EnsureOutputStreamManagerHasTracks(
-    const MediaInfo& aLoadedInfo) {
-  MOZ_ASSERT(NS_IsMainThread());
-  if (!mOutputStreamManager) {
-    return;
-  }
-  if ((!aLoadedInfo.HasAudio() ||
-       mOutputStreamManager->HasTrackType(MediaSegment::AUDIO)) &&
-      (!aLoadedInfo.HasVideo() ||
-       mOutputStreamManager->HasTrackType(MediaSegment::VIDEO))) {
-    return;
-  }
-  if (aLoadedInfo.HasAudio()) {
-    MOZ_ASSERT(!mOutputStreamManager->HasTrackType(MediaSegment::AUDIO));
-    RefPtr<SourceMediaTrack> dummy =
-        mOutputStreamManager->AddTrack(MediaSegment::AUDIO);
-    LOG("Pre-created audio track with underlying track %p", dummy.get());
-    Unused << dummy;
-  }
-  if (aLoadedInfo.HasVideo()) {
-    MOZ_ASSERT(!mOutputStreamManager->HasTrackType(MediaSegment::VIDEO));
-    RefPtr<SourceMediaTrack> dummy =
-        mOutputStreamManager->AddTrack(MediaSegment::VIDEO);
-    LOG("Pre-created video track with underlying track %p", dummy.get());
-    Unused << dummy;
-  }
-}
-
 class VideoQueueMemoryFunctor : public nsDequeFunctor {
  public:
   VideoQueueMemoryFunctor() : mSize(0) {}