# ==============================================================================
# REGRESSOR COMMIT DIFF
# ==============================================================================
# File: gfx/angle/checkout/src/common/PoolAlloc.h
# Commit: 3a91885d47e0
# Full Hash: 3a91885d47e0ef7fba9749562d52300eea67c651
# Author: Miko Mynttinen <mikokm@gmail.com>
# Date: 2019-11-11 21:52:52
# Regressor Bug: 1578576
# File Overlap Count: 4
# Description:
#   Bug 1578576 - Part 2: Update to ANGLE 3865 r=jgilbert
#   
#   Depends on D44561
#   
#   Differential Revision: https://phabricator.services.mozilla.com/D44579
# ==============================================================================

diff -r 77cee77c0307 -r 3a91885d47e0 gfx/angle/checkout/src/common/PoolAlloc.h
--- a/gfx/angle/checkout/src/common/PoolAlloc.h	Fri Nov 08 16:41:42 2019 +0000
+++ b/gfx/angle/checkout/src/common/PoolAlloc.h	Fri Nov 08 17:06:00 2019 +0000
@@ -38,6 +38,7 @@
 #include <vector>
 
 #include "angleutils.h"
+#include "common/debug.h"
 
 namespace angle
 {
@@ -123,6 +124,10 @@
 {
   public:
     static const int kDefaultAlignment = 16;
+    //
+    // Create PoolAllocator. If alignment is be set to 1 byte then fastAllocate()
+    //  function can be used to make allocations with less overhead.
+    //
     PoolAllocator(int growthIncrement = 8 * 1024, int allocationAlignment = kDefaultAlignment);
 
     //
@@ -154,6 +159,33 @@
     void *allocate(size_t numBytes);
 
     //
+    // Call fastAllocate() for a faster allocate function that does minimal bookkeeping
+    // preCondition: Allocator must have been created w/ alignment of 1
+    ANGLE_INLINE uint8_t *fastAllocate(size_t numBytes)
+    {
+#if defined(ANGLE_DISABLE_POOL_ALLOC)
+        return reinterpret_cast<uint8_t *>(allocate(numBytes));
+#else
+        ASSERT(mAlignment == 1);
+        // No multi-page allocations
+        ASSERT(numBytes <= (mPageSize - mHeaderSkip));
+        //
+        // Do the allocation, most likely case inline first, for efficiency.
+        //
+        if (numBytes <= mPageSize - mCurrentPageOffset)
+        {
+            //
+            // Safe to allocate from mCurrentPageOffset.
+            //
+            uint8_t *memory = reinterpret_cast<uint8_t *>(mInUseList) + mCurrentPageOffset;
+            mCurrentPageOffset += numBytes;
+            return memory;
+        }
+        return reinterpret_cast<uint8_t *>(allocateNewPage(numBytes, numBytes));
+#endif
+    }
+
+    //
     // There is no deallocate.  The point of this class is that
     // deallocation can be skipped by the user of it, as the model
     // of use is to simultaneously deallocate everything at once
@@ -205,6 +237,8 @@
     };
     using AllocStack = std::vector<AllocState>;
 
+    // Slow path of allocation when we have to get a new page.
+    void *allocateNewPage(size_t numBytes, size_t allocationSize);
     // Track allocations if and only if we're using guard blocks
     void *initializeAllocation(Header *block, unsigned char *memory, size_t numBytes)
     {