# ==============================================================================
# REGRESSOR COMMIT DIFF
# ==============================================================================
# File: js/src/wasm/WasmFrame.h
# Commit: d6506b5ee07b
# Full Hash: d6506b5ee07b5c65f889ce7c2214b0172f205898
# Author: Dmitry Bezhetskov <dbezhetskov@igalia.com>
# Date: 2021-09-16 09:43:03
# Regressor Bug: 1639153
# File Overlap Count: 1
# Description:
#   Bug 1639153 - Introduce indirect stubs to optimize call_indirect. r=lth
#   
#   This patch introduces indirect stubs.
#   An indirect stub is a stub that takes care of any switching activities needed for call_indirect.
#   Before this patch, we have to conservatively assume that any call_indirect's target can be from a foreign instance,
# ==============================================================================

diff -r 80a164c1054e -r d6506b5ee07b js/src/wasm/WasmFrame.h
--- a/js/src/wasm/WasmFrame.h	Wed Sep 15 11:02:57 2021 +0000
+++ b/js/src/wasm/WasmFrame.h	Wed Sep 15 11:10:15 2021 +0000
@@ -43,6 +43,25 @@
 
 constexpr uintptr_t ExitOrJitEntryFPTag = 0x1;
 
+// Tag for determining whether trampoline frame is on the stack or not.
+constexpr uintptr_t TrampolineFpTag = 0x2;
+
+// In a normal call without an indirect stub SP is 16-byte aligned before
+// the call and, after the call, SP is (16 - 4) bytes aligned because
+// the call instruction pushes the return address. Callee expects SP to be
+// (16 - 4) bytes aligned for the checkedCallEntry and to be (16 - 8) byte
+// aligned for the tailCheckedEntry. When we call indirect stub instead of
+// callee, SP is still 16 bytes aligned, then we push two Frames here - one for
+// the stub and one on callee's behalf. Since each frame is (8) bytes aligned,
+// resulted SP will be also aligned on (16) when we jump into callee, so we
+// will step into the alignment assert. To prevent this we allocate additional
+// (8) bytes to satisfy caller's expectations about SP.
+#if defined(JS_CODEGEN_X86)
+constexpr uint32_t IndirectStubAdditionalAlignment = 8u;
+#else
+constexpr uint32_t IndirectStubAdditionalAlignment = 0u;
+#endif
+
 // wasm::Frame represents the bytes pushed by the call instruction and the
 // fixed prologue generated by wasm::GenerateCallablePrologue.
 //
@@ -89,10 +108,25 @@
     return reinterpret_cast<Frame*>(callerFP_);
   }
 
+  Frame* trampolineCaller() const {
+    MOZ_ASSERT(callerIsTrampolineFP());
+    return reinterpret_cast<Frame*>(reinterpret_cast<uintptr_t>(callerFP_) &
+                                    ~TrampolineFpTag);
+  }
+
   bool callerIsExitOrJitEntryFP() const {
     return isExitOrJitEntryFP(callerFP_);
   }
 
+  bool callerIsTrampolineFP() const { return isTrampolineFP(callerFP_); }
+
+  size_t trampolineSlots() const {
+    return callerIsTrampolineFP()
+               ? ((sizeof(Frame) + IndirectStubAdditionalAlignment) /
+                  sizeof(void*))
+               : 0;
+  }
+
   uint8_t* jitEntryCaller() const { return toJitEntryCaller(callerFP_); }
 
   static const Frame* fromUntaggedWasmExitFP(const void* savedFP) {
@@ -110,6 +144,10 @@
                                       ~ExitOrJitEntryFPTag);
   }
 
+  static bool isTrampolineFP(const void* fp) {
+    return reinterpret_cast<uintptr_t>(fp) & TrampolineFpTag;
+  }
+
   static uint8_t* addExitOrJitEntryFPTag(const Frame* fp) {
     MOZ_ASSERT(!isExitOrJitEntryFP(fp));
     return reinterpret_cast<uint8_t*>(reinterpret_cast<uintptr_t>(fp) |