# ==============================================================================
# REGRESSOR COMMIT DIFF
# ==============================================================================
# File: js/src/gc/Heap.h
# Commit: 43978ebfc7ac
# Full Hash: 43978ebfc7ace2c37aba0b7644ac4e866e0730bd
# Author: Jon Coppeard <jcoppeard@mozilla.com>
# Date: 2021-01-20 16:13:57
# Regressor Bug: 1686219
# File Overlap Count: 1
# Description:
#   Bug 1686219 - Store chunk information at the start rather than the end of the chunk r=sfink
#   
#   This moves the chunk metadata to the start of the chunk and defines the data structures in the public header.  This simplifies accessing this data and removes the need for hardcoded offsets.
#   
#   Requesting review from jandem for JIT updates.
# ==============================================================================

diff -r 496d47ff3fa1 -r 43978ebfc7ac js/src/gc/Heap.h
--- a/js/src/gc/Heap.h	Wed Jan 20 10:04:11 2021 +0000
+++ b/js/src/gc/Heap.h	Wed Jan 20 10:04:29 2021 +0000
@@ -7,7 +7,6 @@
 #ifndef gc_Heap_h
 #define gc_Heap_h
 
-#include "mozilla/BitSet.h"
 #include "mozilla/DebugOnly.h"
 
 #include "ds/BitArray.h"
@@ -41,27 +40,12 @@
  * bitmap contains one bit per CellBytesPerMarkBit bytes (which is equal to
  * CellAlignBytes) and we need two mark bits per cell.
  */
-const size_t MarkBitsPerCell = 2;
 const size_t MinCellSize = CellBytesPerMarkBit * MarkBitsPerCell;
 
-constexpr size_t DivideAndRoundUp(size_t numerator, size_t divisor) {
-  return (numerator + divisor - 1) / divisor;
-}
-
 static_assert(ArenaSize % CellAlignBytes == 0,
               "Arena size must be a multiple of cell alignment");
 
 /*
- * The mark bitmap has one bit per each possible cell start position. This
- * wastes some space for larger GC things but allows us to avoid division by the
- * cell's size when accessing the bitmap.
- */
-const size_t ArenaBitmapBits = ArenaSize / CellBytesPerMarkBit;
-const size_t ArenaBitmapBytes = DivideAndRoundUp(ArenaBitmapBits, 8);
-const size_t ArenaBitmapWords =
-    DivideAndRoundUp(ArenaBitmapBits, JS_BITS_PER_WORD);
-
-/*
  * A FreeSpan represents a contiguous sequence of free cells in an Arena. It
  * can take two forms.
  *
@@ -168,7 +152,7 @@
  * +---------------+---------+----+----+-----+----+
  * <-------------------------> = first thing offset
  */
-class Arena {
+class alignas(ArenaSize) Arena {
   static JS_FRIEND_DATA const uint8_t ThingSizes[];
   static JS_FRIEND_DATA const uint8_t FirstThingOffsets[];
   static JS_FRIEND_DATA const uint8_t ThingsPerArena[];
@@ -501,262 +485,115 @@
 #endif
 }
 
-/*
- * The tail of the chunk info is shared between all chunks in the system, both
- * nursery and tenured. This structure is locatable from any GC pointer by
- * aligning to 1MiB.
- */
-struct ChunkTrailer {
-  // Construct a Nursery ChunkTrailer.
-  ChunkTrailer(JSRuntime* rt, StoreBuffer* sb)
-      : location(ChunkLocation::Nursery), storeBuffer(sb), runtime(rt) {}
-
-  // Construct a Tenured heap ChunkTrailer.
-  explicit ChunkTrailer(JSRuntime* rt)
-      : location(ChunkLocation::TenuredHeap),
-        storeBuffer(nullptr),
-        runtime(rt) {}
-
- public:
-  // The index of the chunk in the nursery, or LocationTenuredHeap.
-  ChunkLocation location;
-  uint32_t : 32;  // padding
-
-  // The store buffer for pointers from tenured things to things in this
-  // chunk. Will be non-null only for nursery chunks.
-  StoreBuffer* storeBuffer;
-
-  // Provide quick access to the runtime from absolutely anywhere.
-  JSRuntime* runtime;
-};
-
-static_assert(sizeof(ChunkTrailer) == ChunkTrailerSize,
-              "ChunkTrailer size must match the API defined size.");
+// Mark bitmap API:
 
-// The chunk header (located at the end of the chunk to preserve arena
-// alignment).
-struct ChunkInfo {
-  void init() { next = prev = nullptr; }
-
- private:
-  friend class ChunkPool;
-  friend class js::NurseryDecommitTask;
-  Chunk* next;
-  Chunk* prev;
-
- public:
-  /* Free arenas are linked together with arena.next. */
-  Arena* freeArenasHead;
+MOZ_ALWAYS_INLINE bool ChunkBitmap::markBit(const TenuredCell* cell,
+                                            ColorBit colorBit) {
+  MarkBitmapWord* word;
+  uintptr_t mask;
+  GetMarkWordAndMask(cell, colorBit, &word, &mask);
+  return *word & mask;
+}
 
-#if JS_BITS_PER_WORD == 32
-  /*
-   * Calculating sizes and offsets is simpler if sizeof(ChunkInfo) is
-   * architecture-independent.
-   */
-  char padding[24];
-#endif
+MOZ_ALWAYS_INLINE bool ChunkBitmap::isMarkedAny(const TenuredCell* cell) {
+  return markBit(cell, ColorBit::BlackBit) ||
+         markBit(cell, ColorBit::GrayOrBlackBit);
+}
 
-  /*
-   * Decommitted arenas are tracked by a bitmap in the chunk header. We use
-   * this offset to start our search iteration close to a decommitted arena
-   * that we can allocate.
-   */
-  uint32_t lastDecommittedArenaOffset;
-
-  /* Number of free arenas, either committed or decommitted. */
-  uint32_t numArenasFree;
-
-  /* Number of free, committed arenas. */
-  uint32_t numArenasFreeCommitted;
-};
+MOZ_ALWAYS_INLINE bool ChunkBitmap::isMarkedBlack(const TenuredCell* cell) {
+  return markBit(cell, ColorBit::BlackBit);
+}
 
-/*
- * Calculating ArenasPerChunk:
- *
- * In order to figure out how many Arenas will fit in a chunk, we need to know
- * how much extra space is available after we allocate the header data. This
- * is a problem because the header size depends on the number of arenas in the
- * chunk. The two dependent fields are bitmap and decommittedArenas.
- *
- * For the mark bitmap, we know that each arena will use a fixed number of full
- * bytes: ArenaBitmapBytes. The full size of the header data is this number
- * multiplied by the eventual number of arenas we have in the header. We,
- * conceptually, distribute this header data among the individual arenas and do
- * not include it in the header. This way we do not have to worry about its
- * variable size: it gets attached to the variable number we are computing.
- *
- * For the decommitted arena bitmap, we only have 1 bit per arena, so this
- * technique will not work. Instead, we observe that we do not have enough
- * header info to fill 8 full arenas: it is currently 4 on 64bit, less on
- * 32bit. Thus, with current numbers, we need 64 bytes for decommittedArenas.
- * This will not become 63 bytes unless we double the data required in the
- * header. Therefore, we just compute the number of bytes required to track
- * every possible arena and do not worry about slop bits, since there are too
- * few to usefully allocate.
- *
- * To actually compute the number of arenas we can allocate in a chunk, we
- * divide the amount of available space less the header info (not including
- * the mark bitmap which is distributed into the arena size) by the size of
- * the arena (with the mark bitmap bytes it uses).
- */
-const size_t BytesPerArenaWithHeader = ArenaSize + ArenaBitmapBytes;
-const size_t ChunkDecommitBitmapBytes = ChunkSize / ArenaSize / CHAR_BIT;
-const size_t ChunkBytesAvailable = ChunkSize - sizeof(ChunkTrailer) -
-                                   sizeof(ChunkInfo) - ChunkDecommitBitmapBytes;
-const size_t ArenasPerChunk = ChunkBytesAvailable / BytesPerArenaWithHeader;
-
-#ifdef JS_GC_SMALL_CHUNK_SIZE
-static_assert(ArenasPerChunk == 62,
-              "Do not accidentally change our heap's density.");
-#else
-static_assert(ArenasPerChunk == 252,
-              "Do not accidentally change our heap's density.");
-#endif
+MOZ_ALWAYS_INLINE bool ChunkBitmap::isMarkedGray(const TenuredCell* cell) {
+  return !markBit(cell, ColorBit::BlackBit) &&
+         markBit(cell, ColorBit::GrayOrBlackBit);
+}
 
-/* A chunk bitmap contains enough mark bits for all the cells in a chunk. */
-struct ChunkBitmap {
-  static constexpr size_t WordCount = ArenaBitmapWords * ArenasPerChunk;
-  MarkBitmapWord bitmap[WordCount];
-
-  MOZ_ALWAYS_INLINE void getMarkWordAndMask(const TenuredCell* cell,
-                                            ColorBit colorBit,
-                                            MarkBitmapWord** wordp,
-                                            uintptr_t* maskp) {
-    MOZ_ASSERT(size_t(colorBit) < MarkBitsPerCell);
-    detail::GetGCThingMarkWordAndMask(uintptr_t(cell), colorBit, wordp, maskp);
-  }
-
- public:
-  ChunkBitmap() = default;
-
-  MOZ_ALWAYS_INLINE bool markBit(const TenuredCell* cell, ColorBit colorBit) {
-    MarkBitmapWord* word;
-    uintptr_t mask;
-    getMarkWordAndMask(cell, colorBit, &word, &mask);
-    return *word & mask;
+// The return value indicates if the cell went from unmarked to marked.
+MOZ_ALWAYS_INLINE bool ChunkBitmap::markIfUnmarked(const TenuredCell* cell,
+                                                   MarkColor color) {
+  MarkBitmapWord* word;
+  uintptr_t mask;
+  GetMarkWordAndMask(cell, ColorBit::BlackBit, &word, &mask);
+  if (*word & mask) {
+    return false;
   }
-
-  MOZ_ALWAYS_INLINE bool isMarkedAny(const TenuredCell* cell) {
-    return markBit(cell, ColorBit::BlackBit) ||
-           markBit(cell, ColorBit::GrayOrBlackBit);
-  }
-
-  MOZ_ALWAYS_INLINE bool isMarkedBlack(const TenuredCell* cell) {
-    return markBit(cell, ColorBit::BlackBit);
-  }
-
-  MOZ_ALWAYS_INLINE bool isMarkedGray(const TenuredCell* cell) {
-    return !markBit(cell, ColorBit::BlackBit) &&
-           markBit(cell, ColorBit::GrayOrBlackBit);
-  }
-
-  // The return value indicates if the cell went from unmarked to marked.
-  MOZ_ALWAYS_INLINE bool markIfUnmarked(const TenuredCell* cell,
-                                        MarkColor color) {
-    MarkBitmapWord* word;
-    uintptr_t mask;
-    getMarkWordAndMask(cell, ColorBit::BlackBit, &word, &mask);
+  if (color == MarkColor::Black) {
+    *word |= mask;
+  } else {
+    /*
+     * We use GetMarkWordAndMask to recalculate both mask and word as
+     * doing just mask << color may overflow the mask.
+     */
+    GetMarkWordAndMask(cell, ColorBit::GrayOrBlackBit, &word, &mask);
     if (*word & mask) {
       return false;
     }
-    if (color == MarkColor::Black) {
-      *word |= mask;
-    } else {
-      /*
-       * We use getMarkWordAndMask to recalculate both mask and word as
-       * doing just mask << color may overflow the mask.
-       */
-      getMarkWordAndMask(cell, ColorBit::GrayOrBlackBit, &word, &mask);
-      if (*word & mask) {
-        return false;
-      }
-      *word |= mask;
-    }
-    return true;
-  }
-
-  MOZ_ALWAYS_INLINE void markBlack(const TenuredCell* cell) {
-    MarkBitmapWord* word;
-    uintptr_t mask;
-    getMarkWordAndMask(cell, ColorBit::BlackBit, &word, &mask);
     *word |= mask;
   }
+  return true;
+}
 
-  MOZ_ALWAYS_INLINE void copyMarkBit(TenuredCell* dst, const TenuredCell* src,
-                                     ColorBit colorBit) {
-    MarkBitmapWord* srcWord;
-    uintptr_t srcMask;
-    getMarkWordAndMask(src, colorBit, &srcWord, &srcMask);
-
-    MarkBitmapWord* dstWord;
-    uintptr_t dstMask;
-    getMarkWordAndMask(dst, colorBit, &dstWord, &dstMask);
+MOZ_ALWAYS_INLINE void ChunkBitmap::markBlack(const TenuredCell* cell) {
+  MarkBitmapWord* word;
+  uintptr_t mask;
+  GetMarkWordAndMask(cell, ColorBit::BlackBit, &word, &mask);
+  *word |= mask;
+}
 
-    *dstWord &= ~dstMask;
-    if (*srcWord & srcMask) {
-      *dstWord |= dstMask;
-    }
-  }
+MOZ_ALWAYS_INLINE void ChunkBitmap::copyMarkBit(TenuredCell* dst,
+                                                const TenuredCell* src,
+                                                ColorBit colorBit) {
+  MarkBitmapWord* srcWord;
+  uintptr_t srcMask;
+  GetMarkWordAndMask(src, colorBit, &srcWord, &srcMask);
 
-  MOZ_ALWAYS_INLINE void unmark(const TenuredCell* cell) {
-    MarkBitmapWord* word;
-    uintptr_t mask;
-    getMarkWordAndMask(cell, ColorBit::BlackBit, &word, &mask);
-    *word &= ~mask;
-    getMarkWordAndMask(cell, ColorBit::GrayOrBlackBit, &word, &mask);
-    *word &= ~mask;
+  MarkBitmapWord* dstWord;
+  uintptr_t dstMask;
+  GetMarkWordAndMask(dst, colorBit, &dstWord, &dstMask);
+
+  *dstWord &= ~dstMask;
+  if (*srcWord & srcMask) {
+    *dstWord |= dstMask;
   }
+}
 
-  void clear() {
-    for (size_t i = 0; i < WordCount; i++) {
-      bitmap[i] = 0;
-    }
-  }
-
-  MarkBitmapWord* arenaBits(Arena* arena) {
-    static_assert(
-        ArenaBitmapBits == ArenaBitmapWords * JS_BITS_PER_WORD,
-        "We assume that the part of the bitmap corresponding to the arena "
-        "has the exact number of words so we do not need to deal with a word "
-        "that covers bits from two arenas.");
+MOZ_ALWAYS_INLINE void ChunkBitmap::unmark(const TenuredCell* cell) {
+  MarkBitmapWord* word;
+  uintptr_t mask;
+  GetMarkWordAndMask(cell, ColorBit::BlackBit, &word, &mask);
+  *word &= ~mask;
+  GetMarkWordAndMask(cell, ColorBit::GrayOrBlackBit, &word, &mask);
+  *word &= ~mask;
+}
 
-    MarkBitmapWord* word;
-    uintptr_t unused;
-    getMarkWordAndMask(reinterpret_cast<TenuredCell*>(arena->address()),
-                       ColorBit::BlackBit, &word, &unused);
-    return word;
+inline void ChunkBitmap::clear() {
+  for (size_t i = 0; i < ChunkBitmap::WordCount; i++) {
+    bitmap[i] = 0;
   }
-};
+}
 
-static_assert(ArenaBitmapBytes * ArenasPerChunk == sizeof(ChunkBitmap),
-              "Ensure our ChunkBitmap actually covers all arenas.");
-static_assert(js::gc::ChunkMarkBitmapBits == ArenaBitmapBits * ArenasPerChunk,
-              "Ensure that the mark bitmap has the right number of bits.");
-
-using PerArenaBitmap = mozilla::BitSet<ArenasPerChunk, uint32_t>;
+inline MarkBitmapWord* ChunkBitmap::arenaBits(Arena* arena) {
+  static_assert(
+      ArenaBitmapBits == ArenaBitmapWords * JS_BITS_PER_WORD,
+      "We assume that the part of the bitmap corresponding to the arena "
+      "has the exact number of words so we do not need to deal with a word "
+      "that covers bits from two arenas.");
 
-const size_t ChunkPadSize = ChunkSize - (sizeof(Arena) * ArenasPerChunk) -
-                            sizeof(ChunkBitmap) - sizeof(PerArenaBitmap) -
-                            sizeof(ChunkInfo) - sizeof(ChunkTrailer);
-static_assert(ChunkPadSize < BytesPerArenaWithHeader,
-              "If the chunk padding is larger than an arena, we should have "
-              "one more arena.");
+  MarkBitmapWord* word;
+  uintptr_t unused;
+  GetMarkWordAndMask(reinterpret_cast<TenuredCell*>(arena->address()),
+                     ColorBit::BlackBit, &word, &unused);
+  return word;
+}
 
 /*
  * Chunks contain arenas and associated data structures (mark bitmap, delayed
  * marking state).
  */
-struct Chunk {
+struct Chunk : public ChunkBase {
   Arena arenas[ArenasPerChunk];
 
-  /* Pad to full size to ensure cache alignment of ChunkInfo. */
-  uint8_t padding[ChunkPadSize];
-
-  ChunkBitmap bitmap;
-  PerArenaBitmap decommittedArenas;
-  ChunkInfo info;
-  ChunkTrailer trailer;
-
   static Chunk* fromAddress(uintptr_t addr) {
     addr &= ~ChunkMask;
     return reinterpret_cast<Chunk*>(addr);
@@ -764,15 +601,17 @@
 
   static bool withinValidRange(uintptr_t addr) {
     uintptr_t offset = addr & ChunkMask;
-    return Chunk::fromAddress(addr)->isNurseryChunk()
-               ? offset < ChunkSize - sizeof(ChunkTrailer)
-               : offset < ArenasPerChunk * ArenaSize;
+    if (Chunk::fromAddress(addr)->isNurseryChunk()) {
+      return offset >= sizeof(ChunkHeader) && offset < ChunkSize;
+    }
+    return offset >= offsetof(Chunk, arenas) && offset < ChunkSize;
   }
 
   static size_t arenaIndex(uintptr_t addr) {
     MOZ_ASSERT(!Chunk::fromAddress(addr)->isNurseryChunk());
     MOZ_ASSERT(withinValidRange(addr));
-    return (addr & ChunkMask) >> ArenaShift;
+    uintptr_t offset = addr & ChunkMask;
+    return (offset - offsetof(Chunk, arenas)) >> ArenaShift;
   }
 
   uintptr_t address() const {
@@ -785,7 +624,7 @@
 
   bool hasAvailableArenas() const { return info.numArenasFree != 0; }
 
-  bool isNurseryChunk() const { return trailer.storeBuffer; }
+  bool isNurseryChunk() const { return header.storeBuffer; }
 
   Arena* allocateArena(GCRuntime* gc, JS::Zone* zone, AllocKind kind,
                        const AutoLockGC& lock);
@@ -819,23 +658,6 @@
   Arena* fetchNextFreeArena(GCRuntime* gc);
 };
 
-static_assert(
-    sizeof(Chunk) == ChunkSize,
-    "Ensure the hardcoded chunk size definition actually matches the struct.");
-static_assert(js::gc::ChunkMarkBitmapOffset == offsetof(Chunk, bitmap),
-              "The hardcoded API bitmap offset must match the actual offset.");
-static_assert(js::gc::ChunkRuntimeOffset ==
-                  offsetof(Chunk, trailer) + offsetof(ChunkTrailer, runtime),
-              "The hardcoded API runtime offset must match the actual offset.");
-static_assert(
-    js::gc::ChunkLocationOffset ==
-        offsetof(Chunk, trailer) + offsetof(ChunkTrailer, location),
-    "The hardcoded API location offset must match the actual offset.");
-static_assert(
-    js::gc::ChunkStoreBufferOffset ==
-        offsetof(Chunk, trailer) + offsetof(ChunkTrailer, storeBuffer),
-    "The hardcoded API storeBuffer offset must match the actual offset.");
-
 inline void Arena::checkAddress() const {
   mozilla::DebugOnly<uintptr_t> addr = uintptr_t(this);
   MOZ_ASSERT(addr);