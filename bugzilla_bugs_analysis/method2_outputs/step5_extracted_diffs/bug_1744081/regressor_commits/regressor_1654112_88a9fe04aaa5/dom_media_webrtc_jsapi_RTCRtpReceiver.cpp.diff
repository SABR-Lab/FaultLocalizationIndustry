# ==============================================================================
# REGRESSOR COMMIT DIFF
# ==============================================================================
# File: dom/media/webrtc/jsapi/RTCRtpReceiver.cpp
# Commit: 88a9fe04aaa5
# Full Hash: 88a9fe04aaa582676a84734d67c9069b68a7f3e1
# Author: Andreas Pehrson <apehrson@mozilla.com>
# Date: 2021-11-01 18:17:33
# Regressor Bug: 1654112
# File Overlap Count: 5
# Description:
#   Bug 1654112 - Update Audio- and VideoConduit stats API and integration. r=ng,bwc
#   
#   For AudioConduit this patch:
#   - Uses correct threads per upstream, pending changes due to the threading model
#     update that's coming
# ==============================================================================

diff -r 3eae9f9279f6 -r 88a9fe04aaa5 dom/media/webrtc/jsapi/RTCRtpReceiver.cpp
--- a/dom/media/webrtc/jsapi/RTCRtpReceiver.cpp	Fri Jan 29 15:38:54 2021 +0100
+++ b/dom/media/webrtc/jsapi/RTCRtpReceiver.cpp	Mon Jan 18 15:28:29 2021 +0100
@@ -161,149 +161,308 @@
   return promise.forget();
 }
 
-static UniquePtr<dom::RTCStatsCollection> GetReceiverStats_s(
-    const RefPtr<MediaPipelineReceive>& aPipeline,
-    const nsString& aRecvTrackId) {
-  UniquePtr<dom::RTCStatsCollection> report(new dom::RTCStatsCollection);
-  auto asVideo = aPipeline->Conduit()->AsVideoSessionConduit();
-
-  nsString kind = asVideo.isNothing() ? u"audio"_ns : u"video"_ns;
-  nsString idstr = kind + u"_"_ns;
-  idstr.AppendInt(static_cast<uint32_t>(aPipeline->Level()));
+nsTArray<RefPtr<RTCStatsPromise>> RTCRtpReceiver::GetStatsInternal() {
+  MOZ_ASSERT(NS_IsMainThread());
+  nsTArray<RefPtr<RTCStatsPromise>> promises(3);
 
-  // Add bandwidth estimation stats
-  aPipeline->Conduit()->GetBandwidthEstimation().apply([&](auto& bw) {
-    bw.mTrackIdentifier = aRecvTrackId;
-    if (!report->mBandwidthEstimations.AppendElement(bw, fallible)) {
-      mozalloc_handle_oom(0);
-    }
-  });
+  if (!mPipeline) {
+    return promises;
+  }
 
-  Maybe<uint32_t> ssrc;
-  unsigned int ssrcval;
-  if (aPipeline->Conduit()->GetRemoteSSRC(&ssrcval)) {
-    ssrc = Some(ssrcval);
+  if (!mHaveStartedReceiving) {
+    return promises;
   }
 
-  // Add frame history
-  asVideo.apply([&](const auto& conduit) {
-    if (conduit->AddFrameHistory(&report->mVideoFrameHistories)) {
-      auto& history = report->mVideoFrameHistories.LastElement();
-      history.mTrackIdentifier = aRecvTrackId;
-    }
-  });
-
-  // TODO(@@NG):ssrcs handle Conduits having multiple stats at the same level
-  // This is pending spec work
-  // Gather pipeline stats.
-  nsString localId = u"inbound_rtp_"_ns + idstr;
-  nsString remoteId;
+  nsString recvTrackId;
+  MOZ_ASSERT(mTrack);
+  if (mTrack) {
+    mTrack->GetId(recvTrackId);
+  }
 
-  // First, fill in remote stat with rtcp sender data, if present.
-  uint32_t packetsSent;
-  uint64_t bytesSent;
-  DOMHighResTimeStamp remoteTimestamp;
-  Maybe<DOMHighResTimeStamp> timestamp =
-      aPipeline->Conduit()->LastRtcpReceived();
-  if (timestamp.isSome() && aPipeline->Conduit()->GetRTCPSenderReport(
-                                &packetsSent, &bytesSent, &remoteTimestamp)) {
-    RTCRemoteOutboundRtpStreamStats s;
-    remoteId = u"inbound_rtcp_"_ns + idstr;
-    s.mTimestamp.Construct(*timestamp);
-    s.mId.Construct(remoteId);
-    s.mType.Construct(RTCStatsType::Remote_outbound_rtp);
-    ssrc.apply([&s](uint32_t aSsrc) { s.mSsrc.Construct(aSsrc); });
-    s.mMediaType.Construct(kind);  // mediaType is the old name for kind.
-    s.mKind.Construct(kind);
-    s.mLocalId.Construct(localId);
-    s.mPacketsSent.Construct(packetsSent);
-    s.mBytesSent.Construct(bytesSent);
-    s.mRemoteTimestamp.Construct(remoteTimestamp);
-    if (!report->mRemoteOutboundRtpStreamStats.AppendElement(s, fallible)) {
-      mozalloc_handle_oom(0);
+  {
+    // Add bandwidth estimation stats
+    auto report = MakeUnique<dom::RTCStatsCollection>();
+    if (dom::RTCBandwidthEstimationInternal* bw =
+            report->mBandwidthEstimations.AppendElement(fallible)) {
+      const auto& stats = mPipeline->Conduit()->GetCallStats();
+      bw->mTrackIdentifier = recvTrackId;
+      bw->mSendBandwidthBps.Construct(stats.send_bandwidth_bps / 8);
+      bw->mMaxPaddingBps.Construct(stats.max_padding_bitrate_bps / 8);
+      bw->mReceiveBandwidthBps.Construct(stats.recv_bandwidth_bps / 8);
+      bw->mPacerDelayMs.Construct(stats.pacer_delay_ms);
+      if (stats.rtt_ms >= 0) {
+        bw->mRttMs.Construct(stats.rtt_ms);
+      }
+      promises.AppendElement(
+          RTCStatsPromise::CreateAndResolve(std::move(report), __func__));
     }
   }
 
-  // Then, fill in local side (with cross-link to remote only if present)
-  RTCInboundRtpStreamStats s;
-  // TODO(bug 1496533): Should we use the time of the most-recently received
-  // RTP packet? If so, what do we use if we haven't received any RTP? Now?
-  s.mTimestamp.Construct(aPipeline->GetNow());
-  s.mId.Construct(localId);
-  s.mType.Construct(RTCStatsType::Inbound_rtp);
-  ssrc.apply([&s](uint32_t aSsrc) { s.mSsrc.Construct(aSsrc); });
-  s.mMediaType.Construct(kind);  // mediaType is the old name for kind.
-  s.mKind.Construct(kind);
-  unsigned int jitterMs, packetsLost;
-  if (aPipeline->Conduit()->GetRTPReceiverStats(&jitterMs, &packetsLost)) {
-    s.mJitter.Construct(double(jitterMs) / 1000);
-    s.mPacketsLost.Construct(packetsLost);
-  }
-  if (remoteId.Length()) {
-    s.mRemoteId.Construct(remoteId);
-  }
-  s.mPacketsReceived.Construct(aPipeline->RtpPacketsReceived());
-  s.mBytesReceived.Construct(aPipeline->RtpBytesReceived());
+  using TimeStampPromise = MozPromise<Maybe<DOMHighResTimeStamp>, bool, true>;
+  promises.AppendElement(
+      InvokeAsync(mStsThread, __func__,
+                  [cond = RefPtr<MediaSessionConduit>(mPipeline->Conduit())] {
+                    return TimeStampPromise::CreateAndResolve(
+                        cond->LastRtcpReceived(), __func__);
+                  })
+          ->Then(
+              mMainThread, __func__,
+              [pipeline = mPipeline,
+               recvTrackId](TimeStampPromise::ResolveOrRejectValue&& aValue) {
+                MOZ_ASSERT(aValue.IsResolve());
+                Maybe<DOMHighResTimeStamp> lastRtcpReceivedTimestamp =
+                    aValue.ResolveValue();
+
+                auto report = MakeUnique<dom::RTCStatsCollection>();
+                auto asAudio = pipeline->Conduit()->AsAudioSessionConduit();
+                auto asVideo = pipeline->Conduit()->AsVideoSessionConduit();
+
+                nsString kind = asVideo.isNothing() ? u"audio"_ns : u"video"_ns;
+                nsString idstr = kind + u"_"_ns;
+                idstr.AppendInt(static_cast<uint32_t>(pipeline->Level()));
+
+                Maybe<uint32_t> ssrc;
+                unsigned int ssrcval;
+                if (pipeline->Conduit()->GetRemoteSSRC(&ssrcval)) {
+                  ssrc = Some(ssrcval);
+                }
+
+                // Add frame history
+                asVideo.apply([&](const auto& conduit) {
+                  if (conduit->AddFrameHistory(&report->mVideoFrameHistories)) {
+                    auto& history = report->mVideoFrameHistories.LastElement();
+                    history.mTrackIdentifier = recvTrackId;
+                  }
+                });
+
+                // TODO(@@NG):ssrcs handle Conduits having multiple stats at
+                // the same level This is pending spec work Gather pipeline
+                // stats.
+                nsString localId = u"inbound_rtp_"_ns + idstr;
+                nsString remoteId;
+
+                auto constructCommonRemoteOutboundRtpStats =
+                    [&](RTCRemoteOutboundRtpStreamStats& aRemote,
+                        const DOMHighResTimeStamp& aTimestamp) {
+                      remoteId = u"inbound_rtcp_"_ns + idstr;
+                      aRemote.mTimestamp.Construct(aTimestamp);
+                      aRemote.mId.Construct(remoteId);
+                      aRemote.mType.Construct(
+                          RTCStatsType::Remote_outbound_rtp);
+                      ssrc.apply([&](uint32_t aSsrc) {
+                        aRemote.mSsrc.Construct(aSsrc);
+                      });
+                      aRemote.mMediaType.Construct(
+                          kind);  // mediaType is the old name for kind.
+                      aRemote.mKind.Construct(kind);
+                      aRemote.mLocalId.Construct(localId);
+                    };
+
+                auto constructCommonInboundRtpStats =
+                    [&](RTCInboundRtpStreamStats& aLocal) {
+                      // TODO(bug 1496533): Should we use the time of the
+                      // most-recently received RTP packet? If so, what do we
+                      // use if we haven't received any RTP? Now?
+                      aLocal.mTimestamp.Construct(pipeline->GetNow());
+                      aLocal.mId.Construct(localId);
+                      aLocal.mType.Construct(RTCStatsType::Inbound_rtp);
+                      ssrc.apply([&](uint32_t aSsrc) {
+                        aLocal.mSsrc.Construct(aSsrc);
+                      });
+                      aLocal.mMediaType.Construct(
+                          kind);  // mediaType is the old name for kind.
+                      aLocal.mKind.Construct(kind);
+                      if (remoteId.Length()) {
+                        aLocal.mRemoteId.Construct(remoteId);
+                      }
+                    };
+
+                asAudio.apply([&](auto& aConduit) {
+                  Maybe<webrtc::AudioReceiveStream::Stats> audioStats =
+                      aConduit->GetReceiverStats();
+                  if (audioStats.isNothing()) {
+                    return;
+                  }
+
+                  // First, fill in remote stat with rtcp sender data, if
+                  // present.
+                  lastRtcpReceivedTimestamp.apply([&](auto& aTimestamp) {
+                    RTCRemoteOutboundRtpStreamStats remote;
+                    constructCommonRemoteOutboundRtpStats(remote, aTimestamp);
+                    remote.mPacketsSent.Construct(
+                        audioStats->rtcp_sender_packets_sent);
+                    remote.mBytesSent.Construct(
+                        audioStats->rtcp_sender_octets_sent);
+                    remote.mRemoteTimestamp.Construct(
+                        audioStats->rtcp_sender_ntp_timestamp_ms);
+                    if (!report->mRemoteOutboundRtpStreamStats.AppendElement(
+                            std::move(remote), fallible)) {
+                      mozalloc_handle_oom(0);
+                    }
+                  });
 
-  // Fill in packet type statistics
-  webrtc::RtcpPacketTypeCounter counters;
-  if (aPipeline->Conduit()->GetRecvPacketTypeStats(&counters)) {
-    s.mNackCount.Construct(counters.nack_packets);
-    // Fill in video only packet type stats
-    if (asVideo) {
-      s.mFirCount.Construct(counters.fir_packets);
-      s.mPliCount.Construct(counters.pli_packets);
-    }
-  }
-  // Lastly, fill in video decoder stats if this is video
-  asVideo.apply([&s](auto conduit) {
-    double framerateMean;
-    double framerateStdDev;
-    double bitrateMean;
-    double bitrateStdDev;
-    uint32_t discardedPackets;
-    uint32_t framesDecoded;
-    if (conduit->GetVideoDecoderStats(&framerateMean, &framerateStdDev,
-                                      &bitrateMean, &bitrateStdDev,
-                                      &discardedPackets, &framesDecoded)) {
-      s.mFramerateMean.Construct(framerateMean);
-      s.mFramerateStdDev.Construct(framerateStdDev);
-      s.mBitrateMean.Construct(bitrateMean);
-      s.mBitrateStdDev.Construct(bitrateStdDev);
-      s.mDiscardedPackets.Construct(discardedPackets);
-      s.mFramesDecoded.Construct(framesDecoded);
-    }
-  });
-  if (!report->mInboundRtpStreamStats.AppendElement(s, fallible)) {
-    mozalloc_handle_oom(0);
+                  // Then, fill in local side (with cross-link to remote only
+                  // if present)
+                  RTCInboundRtpStreamStats local;
+                  constructCommonInboundRtpStats(local);
+                  local.mJitter.Construct(audioStats->jitter_ms / 1000.0);
+                  local.mPacketsLost.Construct(audioStats->packets_lost);
+                  local.mPacketsReceived.Construct(audioStats->packets_rcvd);
+                  local.mBytesReceived.Construct(
+                      audioStats->payload_bytes_rcvd);
+                  /*
+                   * Potential new stats that are now available upstream.
+                  if (audioStats->last_packet_received_timestamp_ms) {
+                    local.mLastPacketReceivedTimestamp.Construct(
+                        *audioStats->last_packet_received_timestamp_ms);
+                  }
+                  local.mHeaderBytesReceived.Construct(audioStats->header_and_padding_bytes_rcvd);
+                  local.mFecPacketsReceived.Construct(audioStats->fec_packets_received);
+                  local.mFecPacketsDiscarded.Construct(audioStats->fec_packets_discarded);
+                  if (audioStats->estimated_playout_ntp_timestamp_ms) {
+                    local.mEstimatedPlayoutTimestamp.Construct(
+                        *audioStats->estimated_playout_ntp_timestamp_ms);
+                  }
+                  local.mJitterBufferDelay.Construct(audioStats->jitter_buffer_delay_seconds);
+                  local.mJitterBufferEmittedCount.Construct(
+                      audioStats->jitter_buffer_emitted_count);
+                  local.mTotalSamplesReceived.Construct(audioStats->total_samples_received);
+                  local.mConcealedSamples.Construct(audioStats->concealed_samples);
+                  local.mSilentConcealedSamples.Construct(audioStats->silent_concealed_samples);
+                  local.mConcealmentEvents.Construct(audioStats->concealment_events);
+                  local.mInsertedSamplesForDeceleration.Construct(
+                      audioStats->inserted_samples_for_deceleration);
+                  local.mRemovedSamplesForAcceleration.Construct(
+                      audioStats->removed_samples_for_acceleration);
+                  if (audioStats->audio_level >= 0 &&
+                      audioStats->audio_level <= 32767) {
+                    local.mAudioLevel.Construct(audioStats->audio_level /
+                  32767.0);
+                  }
+                  local.mTotalAudioEnergy.Construct(audioStats->total_output_energy);
+                  local.mTotalSamplesDuration.Construct(audioStats->total_output_duration);
+                   */
+                  if (!report->mInboundRtpStreamStats.AppendElement(
+                          std::move(local), fallible)) {
+                    mozalloc_handle_oom(0);
+                  }
+                });
+
+                asVideo.apply([&](auto& aConduit) {
+                  Maybe<webrtc::VideoReceiveStream::Stats> videoStats =
+                      aConduit->GetReceiverStats();
+                  if (videoStats.isNothing()) {
+                    return;
+                  }
+
+                  // First, fill in remote stat with rtcp sender data, if
+                  // present.
+                  lastRtcpReceivedTimestamp.apply([&](auto& aTimestamp) {
+                    RTCRemoteOutboundRtpStreamStats remote;
+                    constructCommonRemoteOutboundRtpStats(remote, aTimestamp);
+                    remote.mPacketsSent.Construct(
+                        videoStats->rtcp_sender_packets_sent);
+                    remote.mBytesSent.Construct(
+                        videoStats->rtcp_sender_octets_sent);
+                    remote.mRemoteTimestamp.Construct(
+                        videoStats->rtcp_sender_ntp_timestamp_ms);
+                    if (!report->mRemoteOutboundRtpStreamStats.AppendElement(
+                            std::move(remote), fallible)) {
+                      mozalloc_handle_oom(0);
+                    }
+                  });
+
+                  // Then, fill in local side (with cross-link to remote only
+                  // if present)
+                  RTCInboundRtpStreamStats local;
+                  constructCommonInboundRtpStats(local);
+                  local.mJitter.Construct(
+                      double(videoStats->rtp_stats.jitter) /
+                      (webrtc::kVideoPayloadTypeFrequency / 1000));
+                  local.mPacketsLost.Construct(
+                      videoStats->rtp_stats.packets_lost);
+                  local.mPacketsReceived.Construct(
+                      videoStats->rtp_stats.packet_counter.packets);
+                  local.mBytesReceived.Construct(
+                      videoStats->rtp_stats.packet_counter.payload_bytes);
+
+                  // Fill in packet type statistics
+                  local.mNackCount.Construct(
+                      videoStats->rtcp_packet_type_counts.nack_packets);
+                  local.mFirCount.Construct(
+                      videoStats->rtcp_packet_type_counts.fir_packets);
+                  local.mPliCount.Construct(
+                      videoStats->rtcp_packet_type_counts.pli_packets);
+
+                  // Lastly, fill in video decoder stats
+                  local.mFramesDecoded.Construct(videoStats->frames_decoded);
+
+                  /*
+                   * Potential new stats that are now available upstream.
+                  local.mFrameWidth.Construct(videoStats->width);
+                  local.mFrameheight.Construct(videoStats->height);
+                  local.mFramesPerSecond.Construct(videoStats->decode_frame_rate);
+                  if (videoStats->qp_sum) {
+                    local.mQpSum.Construct(*videoStats->qp_sum.value);
+                  }
+                  local.mTotalDecodeTime.Construct(
+                      double(videoStats->total_decode_time_ms) / 1000);
+                  local.mTotalInterFrameDelay.Construct(videoStats->total_inter_frame_delay);
+                  local.mTotalSquaredInterFrameDelay.Construct(videoStats->total_squared_inter_frame_delay);
+                  if
+                  (videoStats->rtp_stats.last_packet_received_timestamp_ms)
+                  { local.mLastPacketReceiveTimestamp.Construct(
+                        *videoStats->rtp_stats.last_packet_received_timestamp_ms);
+                  }
+                  local.mHeaderBytesReceived.Construct(
+                      videoStats->rtp_stats.packet_counter.header_bytes +
+                      videoStats->rtp_stats.packet_counter.padding_bytes);
+                  if (videoStats->estimated_playout_ntp_timestamp_ms) {
+                    local.mEstimatedPlayoutTimestamp.Construct(
+                        *videoStats->estimated_playout_ntp_timestamp_ms);
+                  }
+                  local.mJitterBufferDelay.Construct(videoStats->jitter_buffer_delay_seconds);
+                  local.mJitterBufferEmittedCount.Construct(
+                      videoStats->jitter_buffer_emitted_count);
+                  local.mFramesReceived.Construct(
+                      videoStats->frame_counts.key_frames +
+                      videoStats->frame_counts.delta_frames);
+                  // Not including frames dropped in the rendering pipe, which
+                  // is not of webrtc's concern anyway?!
+                  local.mFramesDropped.Construct(videoStats->frames_dropped);
+                   */
+                  if (!report->mInboundRtpStreamStats.AppendElement(
+                          std::move(local), fallible)) {
+                    mozalloc_handle_oom(0);
+                  }
+                });
+                return RTCStatsPromise::CreateAndResolve(std::move(report),
+                                                         __func__);
+              })
+          ->Then(
+              mStsThread, __func__,
+              [pipeline = mPipeline](UniquePtr<RTCStatsCollection> aReport) {
+                // Fill in Contributing Source statistics
+                if (!aReport->mInboundRtpStreamStats.IsEmpty() &&
+                    aReport->mInboundRtpStreamStats[0].mId.WasPassed()) {
+                  pipeline->GetContributingSourceStats(
+                      aReport->mInboundRtpStreamStats[0].mId.Value(),
+                      aReport->mRtpContributingSourceStats);
+                }
+                return RTCStatsPromise::CreateAndResolve(std::move(aReport),
+                                                         __func__);
+              },
+              [] {
+                MOZ_CRASH("Unexpected reject");
+                return RTCStatsPromise::CreateAndReject(NS_ERROR_UNEXPECTED,
+                                                        __func__);
+              }));
+
+  if (mJsepTransceiver->mTransport.mComponents) {
+    promises.AppendElement(mTransportHandler->GetIceStats(
+        mJsepTransceiver->mTransport.mTransportId, mPipeline->GetNow()));
   }
 
-  // Fill in Contributing Source statistics
-  aPipeline->GetContributingSourceStats(localId,
-                                        report->mRtpContributingSourceStats);
-
-  return report;
-}
-
-nsTArray<RefPtr<RTCStatsPromise>> RTCRtpReceiver::GetStatsInternal() {
-  nsTArray<RefPtr<RTCStatsPromise>> promises;
-  if (mPipeline && mHaveStartedReceiving) {
-    nsString recvTrackId;
-    MOZ_ASSERT(mTrack);
-    if (mTrack) {
-      mTrack->GetId(recvTrackId);
-    }
-    promises.AppendElement(InvokeAsync(
-        mStsThread, __func__, [pipeline = mPipeline, recvTrackId]() {
-          return RTCStatsPromise::CreateAndResolve(
-              GetReceiverStats_s(pipeline, recvTrackId), __func__);
-        }));
-
-    if (mJsepTransceiver->mTransport.mComponents) {
-      promises.AppendElement(mTransportHandler->GetIceStats(
-          mJsepTransceiver->mTransport.mTransportId, mPipeline->GetNow()));
-    }
-  }
   return promises;
 }
 