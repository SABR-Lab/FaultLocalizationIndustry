# ==============================================================================
# REGRESSOR COMMIT DIFF
# ==============================================================================
# File: dom/media/webrtc/jsapi/RTCRtpReceiver.cpp
# Commit: ceed49af0fad
# Full Hash: ceed49af0fad6ee87f64a89adb84c791a74ced14
# Author: Andreas Pehrson <apehrson@mozilla.com>
# Date: 2021-11-01 18:17:33
# Regressor Bug: 1654112
# File Overlap Count: 2
# Description:
#   Bug 1654112 - Don't register/unregister conduit with the call wrapper in ctor/dtor. r=ng,bwc
#   
#   Doing this outside of the dtor, especially, removes the requirement of the
#   conduit having to be destroyed on the worker thread (main).
#   
# ==============================================================================

diff -r a1c16b86d3a7 -r ceed49af0fad dom/media/webrtc/jsapi/RTCRtpReceiver.cpp
--- a/dom/media/webrtc/jsapi/RTCRtpReceiver.cpp	Mon Jan 18 16:41:26 2021 +0100
+++ b/dom/media/webrtc/jsapi/RTCRtpReceiver.cpp	Mon Jan 18 17:32:49 2021 +0100
@@ -104,11 +104,11 @@
   if (aConduit->type() == MediaSessionConduit::AUDIO) {
     mPipeline = new MediaPipelineReceiveAudio(
         mPCHandle, aTransportHandler, mMainThread.get(), mStsThread.get(),
-        static_cast<AudioSessionConduit*>(aConduit), mTrack, principalHandle);
+        *aConduit->AsAudioSessionConduit(), mTrack, principalHandle);
   } else {
     mPipeline = new MediaPipelineReceiveVideo(
         mPCHandle, aTransportHandler, mMainThread.get(), mStsThread.get(),
-        static_cast<VideoSessionConduit*>(aConduit), mTrack, principalHandle);
+        *aConduit->AsVideoSessionConduit(), mTrack, principalHandle);
   }
 }
 
@@ -178,7 +178,7 @@
     auto report = MakeUnique<dom::RTCStatsCollection>();
     if (dom::RTCBandwidthEstimationInternal* bw =
             report->mBandwidthEstimations.AppendElement(fallible)) {
-      const auto& stats = mPipeline->Conduit()->GetCallStats();
+      const auto& stats = mPipeline->mConduit->GetCallStats();
       bw->mTrackIdentifier = recvTrackId;
       bw->mSendBandwidthBps.Construct(stats.send_bandwidth_bps / 8);
       bw->mMaxPaddingBps.Construct(stats.max_padding_bitrate_bps / 8);
@@ -195,9 +195,9 @@
   using TimeStampPromise = MozPromise<Maybe<DOMHighResTimeStamp>, bool, true>;
   promises.AppendElement(
       InvokeAsync(mStsThread, __func__,
-                  [cond = RefPtr<MediaSessionConduit>(mPipeline->Conduit())] {
+                  [conduit = mPipeline->mConduit] {
                     return TimeStampPromise::CreateAndResolve(
-                        cond->LastRtcpReceived(), __func__);
+                        conduit->LastRtcpReceived(), __func__);
                   })
           ->Then(
               mMainThread, __func__,
@@ -208,8 +208,8 @@
                     aValue.ResolveValue();
 
                 auto report = MakeUnique<dom::RTCStatsCollection>();
-                auto asAudio = pipeline->Conduit()->AsAudioSessionConduit();
-                auto asVideo = pipeline->Conduit()->AsVideoSessionConduit();
+                auto asAudio = pipeline->mConduit->AsAudioSessionConduit();
+                auto asVideo = pipeline->mConduit->AsVideoSessionConduit();
 
                 nsString kind = asVideo.isNothing() ? u"audio"_ns : u"video"_ns;
                 nsString idstr = kind + u"_"_ns;
@@ -217,7 +217,7 @@
 
                 Maybe<uint32_t> ssrc;
                 unsigned int ssrcval;
-                if (pipeline->Conduit()->GetRemoteSSRC(&ssrcval)) {
+                if (pipeline->mConduit->GetRemoteSSRC(&ssrcval)) {
                   ssrc = Some(ssrcval);
                 }
 
@@ -463,9 +463,9 @@
 void RTCRtpReceiver::GetContributingSources(
     nsTArray<RTCRtpContributingSource>& aSources) {
   // Duplicate code...
-  if (mPipeline && mPipeline->Conduit()) {
+  if (mPipeline && mPipeline->mConduit) {
     RefPtr<AudioSessionConduit> conduit(
-        static_cast<AudioSessionConduit*>(mPipeline->Conduit()));
+        *mPipeline->mConduit->AsAudioSessionConduit());
     nsTArray<dom::RTCRtpSourceEntry> sources;
     conduit->GetRtpSources(sources);
     sources.RemoveElementsBy([](const dom::RTCRtpSourceEntry& aEntry) {
@@ -479,9 +479,9 @@
 void RTCRtpReceiver::GetSynchronizationSources(
     nsTArray<dom::RTCRtpSynchronizationSource>& aSources) {
   // Duplicate code...
-  if (mPipeline && mPipeline->Conduit()) {
+  if (mPipeline && mPipeline->mConduit) {
     RefPtr<AudioSessionConduit> conduit(
-        static_cast<AudioSessionConduit*>(mPipeline->Conduit()));
+        *mPipeline->mConduit->AsAudioSessionConduit());
     nsTArray<dom::RTCRtpSourceEntry> sources;
     conduit->GetRtpSources(sources);
     sources.RemoveElementsBy([](const dom::RTCRtpSourceEntry& aEntry) {
@@ -548,7 +548,7 @@
 }
 
 nsresult RTCRtpReceiver::UpdateConduit() {
-  if (mPipeline->Conduit()->type() == MediaSessionConduit::VIDEO) {
+  if (mPipeline->mConduit->type() == MediaSessionConduit::VIDEO) {
     return UpdateVideoConduit();
   }
   return UpdateAudioConduit();
@@ -556,7 +556,7 @@
 
 nsresult RTCRtpReceiver::UpdateVideoConduit() {
   RefPtr<VideoSessionConduit> conduit =
-      static_cast<VideoSessionConduit*>(mPipeline->Conduit());
+      *mPipeline->mConduit->AsVideoSessionConduit();
 
   // NOTE(pkerr) - this is new behavior. Needed because the
   // CreateVideoReceiveStream method of the Call API will assert (in debug)
@@ -622,7 +622,7 @@
 
 nsresult RTCRtpReceiver::UpdateAudioConduit() {
   RefPtr<AudioSessionConduit> conduit =
-      static_cast<AudioSessionConduit*>(mPipeline->Conduit());
+      *mPipeline->mConduit->AsAudioSessionConduit();
 
   if (!mJsepTransceiver->mRecvTrack.GetSsrcs().empty()) {
     MOZ_LOG(gReceiverLog, LogLevel::Debug,
@@ -727,11 +727,11 @@
 void RTCRtpReceiver::MozInsertAudioLevelForContributingSource(
     const uint32_t aSource, const DOMHighResTimeStamp aTimestamp,
     const uint32_t aRtpTimestamp, const bool aHasLevel, const uint8_t aLevel) {
-  if (!mPipeline || mPipeline->IsVideo() || !mPipeline->Conduit()) {
+  if (!mPipeline || mPipeline->IsVideo() || !mPipeline->mConduit) {
     return;
   }
   WebrtcAudioConduit* audio_conduit =
-      static_cast<WebrtcAudioConduit*>(mPipeline->Conduit());
+      static_cast<WebrtcAudioConduit*>(mPipeline->mConduit.get());
   audio_conduit->InsertAudioLevelForContributingSource(
       aSource, aTimestamp, aRtpTimestamp, aHasLevel, aLevel);
 }