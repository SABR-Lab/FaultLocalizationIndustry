# ==============================================================================
# REGRESSOR COMMIT DIFF
# ==============================================================================
# File: gfx/wgpu/wgpu-core/src/command/compute.rs
# Commit: ef5dc3e04e5f
# Full Hash: ef5dc3e04e5f271eea0636ab3a495e95cc912f1d
# Author: Dzmitry Malyshau <dmalyshau@mozilla.com>
# Date: 2021-09-04 09:40:24
# Regressor Bug: 1726626
# File Overlap Count: 3
# Description:
#   Bug 1726626 - Move gfx/wgpu into a 3rd party dependency r=jgilbert,bholley
#   
#   This update makes wgpu a vendored dependency instead of having it in gfx/wgpu.
#   
#   ## Notes
# ==============================================================================

diff --git a/gfx/wgpu/wgpu-core/src/command/compute.rs b/third_party/rust/wgpu-core/src/command/compute.rs
rename from gfx/wgpu/wgpu-core/src/command/compute.rs
rename to third_party/rust/wgpu-core/src/command/compute.rs
--- a/gfx/wgpu/wgpu-core/src/command/compute.rs
+++ b/third_party/rust/wgpu-core/src/command/compute.rs
@@ -1,33 +1,29 @@
-/* This Source Code Form is subject to the terms of the Mozilla Public
- * License, v. 2.0. If a copy of the MPL was not distributed with this
- * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
-
 use crate::{
     binding_model::{BindError, BindGroup, PushConstantUploadError},
     command::{
         bind::Binder, end_pipeline_statistics_query, BasePass, BasePassRef, CommandBuffer,
         CommandEncoderError, CommandEncoderStatus, MapPassErr, PassErrorScope, QueryUseError,
         StateChange,
     },
-    hub::{GfxBackend, Global, GlobalIdentityHandlerFactory, Storage, Token},
+    device::MissingDownlevelFlags,
+    error::{ErrorFormatter, PrettyError},
+    hub::{Global, GlobalIdentityHandlerFactory, HalApi, Storage, Token},
     id,
-    memory_init_tracker::{MemoryInitKind, MemoryInitTrackerAction},
-    resource::{Buffer, BufferUse, Texture},
-    track::{StatefulTrackerSubset, TrackerSet, UsageConflict},
+    init_tracker::MemoryInitKind,
+    resource::{Buffer, Texture},
+    track::{StatefulTrackerSubset, TrackerSet, UsageConflict, UseExtendError},
     validation::{check_buffer_usage, MissingBufferUsageError},
-    Label, DOWNLEVEL_ERROR_WARNING_MESSAGE,
+    Label,
 };
 
-use hal::command::CommandBuffer as _;
+use hal::CommandEncoder as _;
 use thiserror::Error;
-use wgt::{BufferAddress, BufferUsage, ShaderStage};
 
-use crate::track::UseExtendError;
 use std::{fmt, mem, str};
 
 #[doc(hidden)]
 #[derive(Clone, Copy, Debug)]
 #[cfg_attr(
     any(feature = "serial-pass", feature = "trace"),
     derive(serde::Serialize)
 )]
@@ -45,17 +41,17 @@ pub enum ComputeCommand {
     SetPushConstant {
         offset: u32,
         size_bytes: u32,
         values_offset: u32,
     },
     Dispatch([u32; 3]),
     DispatchIndirect {
         buffer_id: id::BufferId,
-        offset: BufferAddress,
+        offset: wgt::BufferAddress,
     },
     PushDebugGroup {
         color: u32,
         len: usize,
     },
     PopDebugGroup,
     InsertDebugMarker {
         color: u32,
@@ -149,39 +145,62 @@ pub enum ComputePassErrorInner {
     #[error("buffer {0:?} is invalid or destroyed")]
     InvalidBuffer(id::BufferId),
     #[error(transparent)]
     ResourceUsageConflict(#[from] UsageConflict),
     #[error(transparent)]
     MissingBufferUsage(#[from] MissingBufferUsageError),
     #[error("cannot pop debug group, because number of pushed debug groups is zero")]
     InvalidPopDebugGroup,
-    #[error(
-        "Compute shaders are not supported by the underlying platform. {}",
-        DOWNLEVEL_ERROR_WARNING_MESSAGE
-    )]
-    ComputeShadersUnsupported,
     #[error(transparent)]
     Dispatch(#[from] DispatchError),
     #[error(transparent)]
     Bind(#[from] BindError),
     #[error(transparent)]
     PushConstants(#[from] PushConstantUploadError),
     #[error(transparent)]
     QueryUse(#[from] QueryUseError),
+    #[error(transparent)]
+    MissingDownlevelFlags(#[from] MissingDownlevelFlags),
+}
+
+impl PrettyError for ComputePassErrorInner {
+    fn fmt_pretty(&self, fmt: &mut ErrorFormatter) {
+        fmt.error(self);
+        match *self {
+            Self::InvalidBindGroup(id) => {
+                fmt.bind_group_label(&id);
+            }
+            Self::InvalidPipeline(id) => {
+                fmt.compute_pipeline_label(&id);
+            }
+            Self::InvalidIndirectBuffer(id) => {
+                fmt.buffer_label(&id);
+            }
+            _ => {}
+        };
+    }
 }
 
 /// Error encountered when performing a compute pass.
 #[derive(Clone, Debug, Error)]
 #[error("{scope}")]
 pub struct ComputePassError {
     pub scope: PassErrorScope,
     #[source]
     inner: ComputePassErrorInner,
 }
+impl PrettyError for ComputePassError {
+    fn fmt_pretty(&self, fmt: &mut ErrorFormatter) {
+        // This error is wrapper for the inner error,
+        // but the scope has useful labels
+        fmt.error(self);
+        self.scope.fmt_pretty(fmt);
+    }
+}
 
 impl<T, E> MapPassErr<T, ComputePassError> for Result<T, E>
 where
     E: Into<ComputePassErrorInner>,
 {
     fn map_pass_err(self, scope: PassErrorScope) -> Result<T, ComputePassError> {
         self.map_err(|inner| ComputePassError {
             scope,
@@ -209,118 +228,111 @@ impl State {
             });
         }
         if self.pipeline.is_unset() {
             return Err(DispatchError::MissingPipeline);
         }
         Ok(())
     }
 
-    fn flush_states<B: GfxBackend>(
+    fn flush_states<A: HalApi>(
         &mut self,
-        raw_cmd_buf: &mut B::CommandBuffer,
+        raw_encoder: &mut A::CommandEncoder,
         base_trackers: &mut TrackerSet,
-        bind_group_guard: &Storage<BindGroup<B>, id::BindGroupId>,
-        buffer_guard: &Storage<Buffer<B>, id::BufferId>,
-        texture_guard: &Storage<Texture<B>, id::TextureId>,
+        bind_group_guard: &Storage<BindGroup<A>, id::BindGroupId>,
+        buffer_guard: &Storage<Buffer<A>, id::BufferId>,
+        texture_guard: &Storage<Texture<A>, id::TextureId>,
     ) -> Result<(), UsageConflict> {
         for id in self.binder.list_active() {
             self.trackers.merge_extend(&bind_group_guard[id].used)?;
-            base_trackers.merge_extend_stateless(&bind_group_guard[id].used);
+            //Note: stateless trackers are not merged: the lifetime reference
+            // is held to the bind group itself.
         }
 
         log::trace!("Encoding dispatch barriers");
 
         CommandBuffer::insert_barriers(
-            raw_cmd_buf,
+            raw_encoder,
             base_trackers,
             &self.trackers.buffers,
             &self.trackers.textures,
             buffer_guard,
             texture_guard,
         );
 
         self.trackers.clear();
         Ok(())
     }
 }
 
 // Common routines between render/compute
 
 impl<G: GlobalIdentityHandlerFactory> Global<G> {
-    pub fn command_encoder_run_compute_pass<B: GfxBackend>(
+    pub fn command_encoder_run_compute_pass<A: HalApi>(
         &self,
         encoder_id: id::CommandEncoderId,
         pass: &ComputePass,
     ) -> Result<(), ComputePassError> {
-        self.command_encoder_run_compute_pass_impl::<B>(encoder_id, pass.base.as_ref())
+        self.command_encoder_run_compute_pass_impl::<A>(encoder_id, pass.base.as_ref())
     }
 
     #[doc(hidden)]
-    pub fn command_encoder_run_compute_pass_impl<B: GfxBackend>(
+    pub fn command_encoder_run_compute_pass_impl<A: HalApi>(
         &self,
         encoder_id: id::CommandEncoderId,
         base: BasePassRef<ComputeCommand>,
     ) -> Result<(), ComputePassError> {
         profiling::scope!("run_compute_pass", "CommandEncoder");
         let scope = PassErrorScope::Pass(encoder_id);
 
-        let hub = B::hub(self);
+        let hub = A::hub(self);
         let mut token = Token::root();
 
+        let (device_guard, mut token) = hub.devices.read(&mut token);
+
         let (mut cmd_buf_guard, mut token) = hub.command_buffers.write(&mut token);
         let cmd_buf =
             CommandBuffer::get_encoder_mut(&mut *cmd_buf_guard, encoder_id).map_pass_err(scope)?;
         // will be reset to true if recording is done without errors
         cmd_buf.status = CommandEncoderStatus::Error;
-        let raw = cmd_buf.raw.last_mut().unwrap();
+        let raw = cmd_buf.encoder.open();
+
+        let device = &device_guard[cmd_buf.device_id.value];
 
         #[cfg(feature = "trace")]
         if let Some(ref mut list) = cmd_buf.commands {
             list.push(crate::device::trace::Command::RunComputePass {
                 base: BasePass::from_ref(base),
             });
         }
 
-        if !cmd_buf
-            .downlevel
-            .flags
-            .contains(wgt::DownlevelFlags::COMPUTE_SHADERS)
-        {
-            return Err(ComputePassError {
-                scope: PassErrorScope::Pass(encoder_id),
-                inner: ComputePassErrorInner::ComputeShadersUnsupported,
-            });
-        }
-
-        if let Some(ref label) = base.label {
-            unsafe {
-                raw.begin_debug_marker(label, 0);
-            }
-        }
-
         let (_, mut token) = hub.render_bundles.read(&mut token);
         let (pipeline_layout_guard, mut token) = hub.pipeline_layouts.read(&mut token);
         let (bind_group_guard, mut token) = hub.bind_groups.read(&mut token);
         let (pipeline_guard, mut token) = hub.compute_pipelines.read(&mut token);
         let (query_set_guard, mut token) = hub.query_sets.read(&mut token);
         let (buffer_guard, mut token) = hub.buffers.read(&mut token);
         let (texture_guard, _) = hub.textures.read(&mut token);
 
         let mut state = State {
             binder: Binder::new(),
             pipeline: StateChange::new(),
-            trackers: StatefulTrackerSubset::new(B::VARIANT),
+            trackers: StatefulTrackerSubset::new(A::VARIANT),
             debug_scope_depth: 0,
         };
         let mut temp_offsets = Vec::new();
         let mut dynamic_offset_count = 0;
         let mut string_offset = 0;
         let mut active_query = None;
 
+        let hal_desc = hal::ComputePassDescriptor { label: base.label };
+        unsafe {
+            raw.begin_compute_pass(&hal_desc);
+        }
+
         for command in base.commands {
             match *command {
                 ComputeCommand::SetBindGroup {
                     index,
                     num_dynamic_offsets,
                     bind_group_id,
                 } => {
                     let scope = PassErrorScope::SetBindGroup(bind_group_id);
@@ -349,52 +361,41 @@ impl<G: GlobalIdentityHandlerFactory> Gl
                         .map_pass_err(scope)?;
                     bind_group
                         .validate_dynamic_bindings(&temp_offsets)
                         .map_pass_err(scope)?;
 
                     cmd_buf.buffer_memory_init_actions.extend(
                         bind_group.used_buffer_ranges.iter().filter_map(
                             |action| match buffer_guard.get(action.id) {
-                                Ok(buffer) => buffer
-                                    .initialization_status
-                                    .check(action.range.clone())
-                                    .map(|range| MemoryInitTrackerAction {
-                                        id: action.id,
-                                        range,
-                                        kind: action.kind,
-                                    }),
+                                Ok(buffer) => buffer.initialization_status.check_action(action),
                                 Err(_) => None,
                             },
                         ),
                     );
-
                     let pipeline_layout_id = state.binder.pipeline_layout_id;
                     let entries = state.binder.assign_group(
                         index as usize,
                         id::Valid(bind_group_id),
                         bind_group,
                         &temp_offsets,
                     );
                     if !entries.is_empty() {
                         let pipeline_layout =
                             &pipeline_layout_guard[pipeline_layout_id.unwrap()].raw;
-                        let desc_sets = entries.iter().map(|e| {
-                            bind_group_guard[e.group_id.as_ref().unwrap().value]
-                                .raw
-                                .raw()
-                        });
-                        let offsets = entries.iter().flat_map(|e| &e.dynamic_offsets).cloned();
-                        unsafe {
-                            raw.bind_compute_descriptor_sets(
-                                pipeline_layout,
-                                index as usize,
-                                desc_sets,
-                                offsets,
-                            );
+                        for (i, e) in entries.iter().enumerate() {
+                            let raw_bg = &bind_group_guard[e.group_id.as_ref().unwrap().value].raw;
+                            unsafe {
+                                raw.set_bind_group(
+                                    pipeline_layout,
+                                    index as u32 + i as u32,
+                                    raw_bg,
+                                    &e.dynamic_offsets,
+                                );
+                            }
                         }
                     }
                 }
                 ComputeCommand::SetPipeline(pipeline_id) => {
                     let scope = PassErrorScope::SetPipelineCompute(pipeline_id);
 
                     if state.pipeline.set_and_check_redundant(pipeline_id) {
                         continue;
@@ -403,57 +404,56 @@ impl<G: GlobalIdentityHandlerFactory> Gl
                     let pipeline = cmd_buf
                         .trackers
                         .compute_pipes
                         .use_extend(&*pipeline_guard, pipeline_id, (), ())
                         .map_err(|_| ComputePassErrorInner::InvalidPipeline(pipeline_id))
                         .map_pass_err(scope)?;
 
                     unsafe {
-                        raw.bind_compute_pipeline(&pipeline.raw);
+                        raw.set_compute_pipeline(&pipeline.raw);
                     }
 
                     // Rebind resources
                     if state.binder.pipeline_layout_id != Some(pipeline.layout_id.value) {
                         let pipeline_layout = &pipeline_layout_guard[pipeline.layout_id.value];
 
                         let (start_index, entries) = state.binder.change_pipeline_layout(
                             &*pipeline_layout_guard,
                             pipeline.layout_id.value,
                         );
                         if !entries.is_empty() {
-                            let desc_sets = entries.iter().map(|e| {
-                                bind_group_guard[e.group_id.as_ref().unwrap().value]
-                                    .raw
-                                    .raw()
-                            });
-                            let offsets = entries.iter().flat_map(|e| &e.dynamic_offsets).cloned();
-                            unsafe {
-                                raw.bind_compute_descriptor_sets(
-                                    &pipeline_layout.raw,
-                                    start_index,
-                                    desc_sets,
-                                    offsets,
-                                );
+                            for (i, e) in entries.iter().enumerate() {
+                                let raw_bg =
+                                    &bind_group_guard[e.group_id.as_ref().unwrap().value].raw;
+                                unsafe {
+                                    raw.set_bind_group(
+                                        &pipeline_layout.raw,
+                                        start_index as u32 + i as u32,
+                                        raw_bg,
+                                        &e.dynamic_offsets,
+                                    );
+                                }
                             }
                         }
 
                         // Clear push constant ranges
                         let non_overlapping = super::bind::compute_nonoverlapping_ranges(
                             &pipeline_layout.push_constant_ranges,
                         );
                         for range in non_overlapping {
                             let offset = range.range.start;
                             let size_bytes = range.range.end - offset;
                             super::push_constant_clear(
                                 offset,
                                 size_bytes,
                                 |clear_offset, clear_data| unsafe {
-                                    raw.push_compute_constants(
+                                    raw.set_push_constants(
                                         &pipeline_layout.raw,
+                                        wgt::ShaderStages::COMPUTE,
                                         clear_offset,
                                         clear_data,
                                     );
                                 },
                             );
                         }
                     }
                 }
@@ -477,23 +477,30 @@ impl<G: GlobalIdentityHandlerFactory> Gl
                         .ok_or(ComputePassErrorInner::Dispatch(
                             DispatchError::MissingPipeline,
                         ))
                         .map_pass_err(scope)?;
                     let pipeline_layout = &pipeline_layout_guard[pipeline_layout_id];
 
                     pipeline_layout
                         .validate_push_constant_ranges(
-                            ShaderStage::COMPUTE,
+                            wgt::ShaderStages::COMPUTE,
                             offset,
                             end_offset_bytes,
                         )
                         .map_pass_err(scope)?;
 
-                    unsafe { raw.push_compute_constants(&pipeline_layout.raw, offset, data_slice) }
+                    unsafe {
+                        raw.set_push_constants(
+                            &pipeline_layout.raw,
+                            wgt::ShaderStages::COMPUTE,
+                            offset,
+                            data_slice,
+                        );
+                    }
                 }
                 ComputeCommand::Dispatch(groups) => {
                     let scope = PassErrorScope::Dispatch {
                         indirect: false,
                         pipeline: state.pipeline.last_state,
                     };
 
                     state.is_ready().map_pass_err(scope)?;
@@ -513,95 +520,96 @@ impl<G: GlobalIdentityHandlerFactory> Gl
                 ComputeCommand::DispatchIndirect { buffer_id, offset } => {
                     let scope = PassErrorScope::Dispatch {
                         indirect: true,
                         pipeline: state.pipeline.last_state,
                     };
 
                     state.is_ready().map_pass_err(scope)?;
 
+                    device
+                        .require_downlevel_flags(wgt::DownlevelFlags::INDIRECT_EXECUTION)
+                        .map_pass_err(scope)?;
+
                     let indirect_buffer = state
                         .trackers
                         .buffers
-                        .use_extend(&*buffer_guard, buffer_id, (), BufferUse::INDIRECT)
+                        .use_extend(&*buffer_guard, buffer_id, (), hal::BufferUses::INDIRECT)
                         .map_err(|_| ComputePassErrorInner::InvalidIndirectBuffer(buffer_id))
                         .map_pass_err(scope)?;
-                    check_buffer_usage(indirect_buffer.usage, BufferUsage::INDIRECT)
+                    check_buffer_usage(indirect_buffer.usage, wgt::BufferUsages::INDIRECT)
                         .map_pass_err(scope)?;
 
                     let end_offset = offset + mem::size_of::<wgt::DispatchIndirectArgs>() as u64;
                     if end_offset > indirect_buffer.size {
                         return Err(ComputePassErrorInner::IndirectBufferOverrun {
                             offset,
                             end_offset,
                             buffer_size: indirect_buffer.size,
                         })
                         .map_pass_err(scope);
                     }
 
-                    let &(ref buf_raw, _) = indirect_buffer
+                    let buf_raw = indirect_buffer
                         .raw
                         .as_ref()
                         .ok_or(ComputePassErrorInner::InvalidIndirectBuffer(buffer_id))
                         .map_pass_err(scope)?;
 
                     let stride = 3 * 4; // 3 integers, x/y/z group size
 
                     cmd_buf.buffer_memory_init_actions.extend(
-                        indirect_buffer
-                            .initialization_status
-                            .check(offset..(offset + stride))
-                            .map(|range| MemoryInitTrackerAction {
-                                id: buffer_id,
-                                range,
-                                kind: MemoryInitKind::NeedsInitializedMemory,
-                            }),
+                        indirect_buffer.initialization_status.create_action(
+                            buffer_id,
+                            offset..(offset + stride),
+                            MemoryInitKind::NeedsInitializedMemory,
+                        ),
                     );
 
                     state
                         .flush_states(
                             raw,
                             &mut cmd_buf.trackers,
                             &*bind_group_guard,
                             &*buffer_guard,
                             &*texture_guard,
                         )
                         .map_pass_err(scope)?;
                     unsafe {
                         raw.dispatch_indirect(buf_raw, offset);
                     }
                 }
-                ComputeCommand::PushDebugGroup { color, len } => {
+                ComputeCommand::PushDebugGroup { color: _, len } => {
                     state.debug_scope_depth += 1;
                     let label =
                         str::from_utf8(&base.string_data[string_offset..string_offset + len])
                             .unwrap();
                     string_offset += len;
                     unsafe {
-                        raw.begin_debug_marker(label, color);
+                        raw.begin_debug_marker(label);
                     }
                 }
                 ComputeCommand::PopDebugGroup => {
                     let scope = PassErrorScope::PopDebugGroup;
 
                     if state.debug_scope_depth == 0 {
                         return Err(ComputePassErrorInner::InvalidPopDebugGroup)
                             .map_pass_err(scope);
                     }
                     state.debug_scope_depth -= 1;
                     unsafe {
                         raw.end_debug_marker();
                     }
                 }
-                ComputeCommand::InsertDebugMarker { color, len } => {
+                ComputeCommand::InsertDebugMarker { color: _, len } => {
                     let label =
                         str::from_utf8(&base.string_data[string_offset..string_offset + len])
                             .unwrap();
                     string_offset += len;
-                    unsafe { raw.insert_debug_marker(label, color) }
+                    unsafe { raw.insert_debug_marker(label) }
                 }
                 ComputeCommand::WriteTimestamp {
                     query_set_id,
                     query_index,
                 } => {
                     let scope = PassErrorScope::WriteTimestamp;
 
                     let query_set = cmd_buf
@@ -652,20 +660,18 @@ impl<G: GlobalIdentityHandlerFactory> Gl
                     let scope = PassErrorScope::EndPipelineStatisticsQuery;
 
                     end_pipeline_statistics_query(raw, &*query_set_guard, &mut active_query)
                         .map_pass_err(scope)?;
                 }
             }
         }
 
-        if let Some(_) = base.label {
-            unsafe {
-                raw.end_debug_marker();
-            }
+        unsafe {
+            raw.end_compute_pass();
         }
         cmd_buf.status = CommandEncoderStatus::Recording;
 
         Ok(())
     }
 }
 
 pub mod compute_ffi {