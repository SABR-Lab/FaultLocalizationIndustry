# ==============================================================================
# REGRESSOR COMMIT DIFF
# ==============================================================================
# File: gfx/wgpu/wgpu-core/src/device/life.rs
# Commit: ef5dc3e04e5f
# Full Hash: ef5dc3e04e5f271eea0636ab3a495e95cc912f1d
# Author: Dzmitry Malyshau <dmalyshau@mozilla.com>
# Date: 2021-09-04 09:40:24
# Regressor Bug: 1726626
# File Overlap Count: 3
# Description:
#   Bug 1726626 - Move gfx/wgpu into a 3rd party dependency r=jgilbert,bholley
#   
#   This update makes wgpu a vendored dependency instead of having it in gfx/wgpu.
#   
#   ## Notes
# ==============================================================================

diff --git a/gfx/wgpu/wgpu-core/src/device/life.rs b/third_party/rust/wgpu-core/src/device/life.rs
rename from gfx/wgpu/wgpu-core/src/device/life.rs
rename to third_party/rust/wgpu-core/src/device/life.rs
--- a/gfx/wgpu/wgpu-core/src/device/life.rs
+++ b/third_party/rust/wgpu-core/src/device/life.rs
@@ -1,35 +1,28 @@
-/* This Source Code Form is subject to the terms of the Mozilla Public
- * License, v. 2.0. If a copy of the MPL was not distributed with this
- * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
-
 #[cfg(feature = "trace")]
 use crate::device::trace;
 use crate::{
     device::{
-        alloc,
-        descriptor::{DescriptorAllocator, DescriptorSet},
-        queue::TempResource,
+        queue::{EncoderInFlight, SubmittedWorkDoneClosure, TempResource},
         DeviceError,
     },
-    hub::{GfxBackend, GlobalIdentityHandlerFactory, Hub, Token},
+    hub::{GlobalIdentityHandlerFactory, HalApi, Hub, Token},
     id, resource,
     track::TrackerSet,
     RefCount, Stored, SubmissionIndex,
 };
+use smallvec::SmallVec;
 
 use copyless::VecHelper as _;
-use hal::device::Device as _;
+use hal::Device as _;
 use parking_lot::Mutex;
 use thiserror::Error;
 
-use std::sync::atomic::Ordering;
-
-const CLEANUP_WAIT_MS: u64 = 5000;
+use std::{mem, sync::atomic::Ordering};
 
 /// A struct that keeps lists of resources that are no longer needed by the user.
 #[derive(Debug, Default)]
 pub(super) struct SuspectedResources {
     pub(crate) buffers: Vec<id::Valid<id::BufferId>>,
     pub(crate) textures: Vec<id::Valid<id::TextureId>>,
     pub(crate) texture_views: Vec<id::Valid<id::TextureViewId>>,
     pub(crate) samplers: Vec<id::Valid<id::SamplerId>>,
@@ -85,123 +78,100 @@ impl SuspectedResources {
         self.render_pipelines.extend(trackers.render_pipes.used());
         self.render_bundles.extend(trackers.bundles.used());
         self.query_sets.extend(trackers.query_sets.used());
     }
 }
 
 /// A struct that keeps lists of resources that are no longer needed.
 #[derive(Debug)]
-struct NonReferencedResources<B: hal::Backend> {
-    buffers: Vec<(B::Buffer, alloc::MemoryBlock<B>)>,
-    images: Vec<(B::Image, alloc::MemoryBlock<B>)>,
+struct NonReferencedResources<A: hal::Api> {
+    buffers: Vec<A::Buffer>,
+    textures: Vec<A::Texture>,
     // Note: we keep the associated ID here in order to be able to check
     // at any point what resources are used in a submission.
-    image_views: Vec<(id::Valid<id::TextureViewId>, B::ImageView)>,
-    samplers: Vec<B::Sampler>,
-    framebuffers: Vec<B::Framebuffer>,
-    desc_sets: Vec<DescriptorSet<B>>,
-    compute_pipes: Vec<B::ComputePipeline>,
-    graphics_pipes: Vec<B::GraphicsPipeline>,
-    descriptor_set_layouts: Vec<B::DescriptorSetLayout>,
-    pipeline_layouts: Vec<B::PipelineLayout>,
-    query_sets: Vec<B::QueryPool>,
+    texture_views: Vec<(id::Valid<id::TextureViewId>, A::TextureView)>,
+    samplers: Vec<A::Sampler>,
+    bind_groups: Vec<A::BindGroup>,
+    compute_pipes: Vec<A::ComputePipeline>,
+    render_pipes: Vec<A::RenderPipeline>,
+    bind_group_layouts: Vec<A::BindGroupLayout>,
+    pipeline_layouts: Vec<A::PipelineLayout>,
+    query_sets: Vec<A::QuerySet>,
 }
 
-impl<B: hal::Backend> NonReferencedResources<B> {
+impl<A: hal::Api> NonReferencedResources<A> {
     fn new() -> Self {
         Self {
             buffers: Vec::new(),
-            images: Vec::new(),
-            image_views: Vec::new(),
+            textures: Vec::new(),
+            texture_views: Vec::new(),
             samplers: Vec::new(),
-            framebuffers: Vec::new(),
-            desc_sets: Vec::new(),
+            bind_groups: Vec::new(),
             compute_pipes: Vec::new(),
-            graphics_pipes: Vec::new(),
-            descriptor_set_layouts: Vec::new(),
+            render_pipes: Vec::new(),
+            bind_group_layouts: Vec::new(),
             pipeline_layouts: Vec::new(),
             query_sets: Vec::new(),
         }
     }
 
     fn extend(&mut self, other: Self) {
         self.buffers.extend(other.buffers);
-        self.images.extend(other.images);
-        self.image_views.extend(other.image_views);
+        self.textures.extend(other.textures);
+        self.texture_views.extend(other.texture_views);
         self.samplers.extend(other.samplers);
-        self.framebuffers.extend(other.framebuffers);
-        self.desc_sets.extend(other.desc_sets);
+        self.bind_groups.extend(other.bind_groups);
         self.compute_pipes.extend(other.compute_pipes);
-        self.graphics_pipes.extend(other.graphics_pipes);
+        self.render_pipes.extend(other.render_pipes);
         self.query_sets.extend(other.query_sets);
-        assert!(other.descriptor_set_layouts.is_empty());
+        assert!(other.bind_group_layouts.is_empty());
         assert!(other.pipeline_layouts.is_empty());
     }
 
-    unsafe fn clean(
-        &mut self,
-        device: &B::Device,
-        memory_allocator_mutex: &Mutex<alloc::MemoryAllocator<B>>,
-        descriptor_allocator_mutex: &Mutex<DescriptorAllocator<B>>,
-    ) {
-        if !self.buffers.is_empty() || !self.images.is_empty() {
-            let mut allocator = memory_allocator_mutex.lock();
-            for (raw, memory) in self.buffers.drain(..) {
-                log::trace!("Buffer {:?} is destroyed with memory {:?}", raw, memory);
-                device.destroy_buffer(raw);
-                allocator.free(device, memory);
-            }
-            for (raw, memory) in self.images.drain(..) {
-                log::trace!("Image {:?} is destroyed with memory {:?}", raw, memory);
-                device.destroy_image(raw);
-                allocator.free(device, memory);
-            }
+    unsafe fn clean(&mut self, device: &A::Device) {
+        for raw in self.buffers.drain(..) {
+            device.destroy_buffer(raw);
         }
-
-        for (_, raw) in self.image_views.drain(..) {
-            device.destroy_image_view(raw);
+        for raw in self.textures.drain(..) {
+            device.destroy_texture(raw);
+        }
+        for (_, raw) in self.texture_views.drain(..) {
+            device.destroy_texture_view(raw);
         }
         for raw in self.samplers.drain(..) {
             device.destroy_sampler(raw);
         }
-        for raw in self.framebuffers.drain(..) {
-            device.destroy_framebuffer(raw);
+        for raw in self.bind_groups.drain(..) {
+            device.destroy_bind_group(raw);
         }
-
-        if !self.desc_sets.is_empty() {
-            descriptor_allocator_mutex
-                .lock()
-                .free(device, self.desc_sets.drain(..));
-        }
-
         for raw in self.compute_pipes.drain(..) {
             device.destroy_compute_pipeline(raw);
         }
-        for raw in self.graphics_pipes.drain(..) {
-            device.destroy_graphics_pipeline(raw);
+        for raw in self.render_pipes.drain(..) {
+            device.destroy_render_pipeline(raw);
         }
-        for raw in self.descriptor_set_layouts.drain(..) {
-            device.destroy_descriptor_set_layout(raw);
+        for raw in self.bind_group_layouts.drain(..) {
+            device.destroy_bind_group_layout(raw);
         }
         for raw in self.pipeline_layouts.drain(..) {
             device.destroy_pipeline_layout(raw);
         }
         for raw in self.query_sets.drain(..) {
-            device.destroy_query_pool(raw);
+            device.destroy_query_set(raw);
         }
     }
 }
 
-#[derive(Debug)]
-struct ActiveSubmission<B: hal::Backend> {
+struct ActiveSubmission<A: hal::Api> {
     index: SubmissionIndex,
-    fence: B::Fence,
-    last_resources: NonReferencedResources<B>,
+    last_resources: NonReferencedResources<A>,
     mapped: Vec<id::Valid<id::BufferId>>,
+    encoders: Vec<EncoderInFlight<A>>,
+    work_done_closures: SmallVec<[SubmittedWorkDoneClosure; 1]>,
 }
 
 #[derive(Clone, Debug, Error)]
 pub enum WaitIdleError {
     #[error(transparent)]
     Device(#[from] DeviceError),
     #[error("GPU got stuck :(")]
     StuckGpu,
@@ -210,182 +180,163 @@ pub enum WaitIdleError {
 /// A struct responsible for tracking resource lifetimes.
 ///
 /// Here is how host mapping is handled:
 ///   1. When mapping is requested we add the buffer to the life_tracker list of `mapped` buffers.
 ///   2. When `triage_suspected` is called, it checks the last submission index associated with each of the mapped buffer,
 /// and register the buffer with either a submission in flight, or straight into `ready_to_map` vector.
 ///   3. When `ActiveSubmission` is retired, the mapped buffers associated with it are moved to `ready_to_map` vector.
 ///   4. Finally, `handle_mapping` issues all the callbacks.
-#[derive(Debug)]
-pub(super) struct LifetimeTracker<B: hal::Backend> {
+pub(super) struct LifetimeTracker<A: hal::Api> {
     /// Resources that the user has requested be mapped, but are still in use.
     mapped: Vec<Stored<id::BufferId>>,
     /// Buffers can be used in a submission that is yet to be made, by the
     /// means of `write_buffer()`, so we have a special place for them.
     pub future_suspected_buffers: Vec<Stored<id::BufferId>>,
     /// Textures can be used in the upcoming submission by `write_texture`.
     pub future_suspected_textures: Vec<Stored<id::TextureId>>,
     /// Resources that are suspected for destruction.
     pub suspected_resources: SuspectedResources,
     /// Resources that are not referenced any more but still used by GPU.
     /// Grouped by submissions associated with a fence and a submission index.
     /// The active submissions have to be stored in FIFO order: oldest come first.
-    active: Vec<ActiveSubmission<B>>,
+    active: Vec<ActiveSubmission<A>>,
     /// Resources that are neither referenced or used, just life_tracker
     /// actual deletion.
-    free_resources: NonReferencedResources<B>,
+    free_resources: NonReferencedResources<A>,
     ready_to_map: Vec<id::Valid<id::BufferId>>,
 }
 
-impl<B: hal::Backend> LifetimeTracker<B> {
+impl<A: hal::Api> LifetimeTracker<A> {
     pub fn new() -> Self {
         Self {
             mapped: Vec::new(),
             future_suspected_buffers: Vec::new(),
             future_suspected_textures: Vec::new(),
             suspected_resources: SuspectedResources::default(),
             active: Vec::new(),
             free_resources: NonReferencedResources::new(),
             ready_to_map: Vec::new(),
         }
     }
 
     pub fn track_submission(
         &mut self,
         index: SubmissionIndex,
-        fence: B::Fence,
-        temp_resources: impl Iterator<Item = (TempResource<B>, alloc::MemoryBlock<B>)>,
+        temp_resources: impl Iterator<Item = TempResource<A>>,
+        encoders: Vec<EncoderInFlight<A>>,
     ) {
         let mut last_resources = NonReferencedResources::new();
-        for (res, memory) in temp_resources {
+        for res in temp_resources {
             match res {
-                TempResource::Buffer(raw) => last_resources.buffers.push((raw, memory)),
-                TempResource::Image(raw) => last_resources.images.push((raw, memory)),
+                TempResource::Buffer(raw) => last_resources.buffers.push(raw),
+                TempResource::Texture(raw) => last_resources.textures.push(raw),
             }
         }
 
+        self.active.alloc().init(ActiveSubmission {
+            index,
+            last_resources,
+            mapped: Vec::new(),
+            encoders,
+            work_done_closures: SmallVec::new(),
+        });
+    }
+
+    pub fn post_submit(&mut self) {
         self.suspected_resources.buffers.extend(
             self.future_suspected_buffers
                 .drain(..)
                 .map(|stored| stored.value),
         );
         self.suspected_resources.textures.extend(
             self.future_suspected_textures
                 .drain(..)
                 .map(|stored| stored.value),
         );
-
-        self.active.alloc().init(ActiveSubmission {
-            index,
-            fence,
-            last_resources,
-            mapped: Vec::new(),
-        });
     }
 
     pub(crate) fn map(&mut self, value: id::Valid<id::BufferId>, ref_count: RefCount) {
         self.mapped.push(Stored { value, ref_count });
     }
 
-    fn wait_idle(&self, device: &B::Device) -> Result<(), WaitIdleError> {
-        if !self.active.is_empty() {
-            log::debug!("Waiting for IDLE...");
-            let status = unsafe {
-                device
-                    .wait_for_fences(
-                        self.active.iter().map(|a| &a.fence),
-                        hal::device::WaitFor::All,
-                        CLEANUP_WAIT_MS * 1_000_000,
-                    )
-                    .map_err(DeviceError::from)?
-            };
-            log::debug!("...Done");
-
-            if !status {
-                // We timed out while waiting for the fences
-                return Err(WaitIdleError::StuckGpu);
-            }
-        }
-        Ok(())
-    }
-
     /// Returns the last submission index that is done.
+    #[must_use]
     pub fn triage_submissions(
         &mut self,
-        device: &B::Device,
-        force_wait: bool,
-    ) -> Result<SubmissionIndex, WaitIdleError> {
+        last_done: SubmissionIndex,
+        command_allocator: &Mutex<super::CommandAllocator<A>>,
+    ) -> SmallVec<[SubmittedWorkDoneClosure; 1]> {
         profiling::scope!("triage_submissions");
-        if force_wait {
-            self.wait_idle(device)?;
-        }
+
         //TODO: enable when `is_sorted_by_key` is stable
         //debug_assert!(self.active.is_sorted_by_key(|a| a.index));
         let done_count = self
             .active
             .iter()
-            .position(|a| unsafe { !device.get_fence_status(&a.fence).unwrap_or(false) })
+            .position(|a| a.index > last_done)
             .unwrap_or_else(|| self.active.len());
-        let last_done = match done_count.checked_sub(1) {
-            Some(i) => self.active[i].index,
-            None => return Ok(0),
-        };
 
+        let mut work_done_closures = SmallVec::new();
         for a in self.active.drain(..done_count) {
             log::trace!("Active submission {} is done", a.index);
             self.free_resources.extend(a.last_resources);
             self.ready_to_map.extend(a.mapped);
-            unsafe {
-                device.destroy_fence(a.fence);
+            for encoder in a.encoders {
+                let raw = unsafe { encoder.land() };
+                command_allocator.lock().release_encoder(raw);
             }
+            work_done_closures.extend(a.work_done_closures);
         }
-
-        Ok(last_done)
+        work_done_closures
     }
 
-    pub fn cleanup(
-        &mut self,
-        device: &B::Device,
-        memory_allocator_mutex: &Mutex<alloc::MemoryAllocator<B>>,
-        descriptor_allocator_mutex: &Mutex<DescriptorAllocator<B>>,
-    ) {
+    pub fn cleanup(&mut self, device: &A::Device) {
         profiling::scope!("cleanup");
         unsafe {
-            self.free_resources
-                .clean(device, memory_allocator_mutex, descriptor_allocator_mutex);
-            descriptor_allocator_mutex.lock().cleanup(device);
+            self.free_resources.clean(device);
         }
     }
 
     pub fn schedule_resource_destruction(
         &mut self,
-        temp_resource: TempResource<B>,
-        memory: alloc::MemoryBlock<B>,
+        temp_resource: TempResource<A>,
         last_submit_index: SubmissionIndex,
     ) {
         let resources = self
             .active
             .iter_mut()
             .find(|a| a.index == last_submit_index)
             .map_or(&mut self.free_resources, |a| &mut a.last_resources);
         match temp_resource {
-            TempResource::Buffer(raw) => resources.buffers.push((raw, memory)),
-            TempResource::Image(raw) => resources.images.push((raw, memory)),
+            TempResource::Buffer(raw) => resources.buffers.push(raw),
+            TempResource::Texture(raw) => resources.textures.push(raw),
+        }
+    }
+
+    pub fn add_work_done_closure(&mut self, closure: SubmittedWorkDoneClosure) -> bool {
+        match self.active.last_mut() {
+            Some(active) => {
+                active.work_done_closures.push(closure);
+                true
+            }
+            // Note: we can't immediately invoke the closure, since it assumes
+            // nothing is currently locked in the hubs.
+            None => false,
         }
     }
 }
 
-impl<B: GfxBackend> LifetimeTracker<B> {
+impl<A: HalApi> LifetimeTracker<A> {
     pub(super) fn triage_suspected<G: GlobalIdentityHandlerFactory>(
         &mut self,
-        hub: &Hub<B, G>,
+        hub: &Hub<A, G>,
         trackers: &Mutex<TrackerSet>,
         #[cfg(feature = "trace")] trace: Option<&Mutex<trace::Trace>>,
-        token: &mut Token<super::Device<B>>,
+        token: &mut Token<super::Device<A>>,
     ) {
         profiling::scope!("triage_suspected");
 
         if !self.suspected_resources.render_bundles.is_empty() {
             let (mut guard, _) = hub.render_bundles.write(token);
             let mut trackers = trackers.lock();
 
             while let Some(id) = self.suspected_resources.render_bundles.pop() {
@@ -416,74 +367,73 @@ impl<B: GfxBackend> LifetimeTracker<B> {
                     if let Some(res) = hub.bind_groups.unregister_locked(id.0, &mut *guard) {
                         self.suspected_resources.add_trackers(&res.used);
 
                         let submit_index = res.life_guard.submission_index.load(Ordering::Acquire);
                         self.active
                             .iter_mut()
                             .find(|a| a.index == submit_index)
                             .map_or(&mut self.free_resources, |a| &mut a.last_resources)
-                            .desc_sets
+                            .bind_groups
                             .push(res.raw);
                     }
                 }
             }
         }
 
         if !self.suspected_resources.texture_views.is_empty() {
             let (mut guard, _) = hub.texture_views.write(token);
             let mut trackers = trackers.lock();
 
-            for id in self.suspected_resources.texture_views.drain(..) {
+            let mut list = mem::take(&mut self.suspected_resources.texture_views);
+            for id in list.drain(..) {
                 if trackers.views.remove_abandoned(id) {
                     #[cfg(feature = "trace")]
                     if let Some(t) = trace {
                         t.lock().add(trace::Action::DestroyTextureView(id.0));
                     }
 
                     if let Some(res) = hub.texture_views.unregister_locked(id.0, &mut *guard) {
-                        let raw = match res.inner {
-                            resource::TextureViewInner::Native { raw, source_id } => {
-                                self.suspected_resources.textures.push(source_id.value);
-                                raw
-                            }
-                            resource::TextureViewInner::SwapChain { .. } => unreachable!(),
-                        };
-
+                        self.suspected_resources.textures.push(res.parent_id.value);
                         let submit_index = res.life_guard.submission_index.load(Ordering::Acquire);
                         self.active
                             .iter_mut()
                             .find(|a| a.index == submit_index)
                             .map_or(&mut self.free_resources, |a| &mut a.last_resources)
-                            .image_views
-                            .push((id, raw));
+                            .texture_views
+                            .push((id, res.raw));
                     }
                 }
             }
+            self.suspected_resources.texture_views = list;
         }
 
         if !self.suspected_resources.textures.is_empty() {
             let (mut guard, _) = hub.textures.write(token);
             let mut trackers = trackers.lock();
 
             for id in self.suspected_resources.textures.drain(..) {
                 if trackers.textures.remove_abandoned(id) {
                     #[cfg(feature = "trace")]
                     if let Some(t) = trace {
                         t.lock().add(trace::Action::DestroyTexture(id.0));
                     }
 
                     if let Some(res) = hub.textures.unregister_locked(id.0, &mut *guard) {
                         let submit_index = res.life_guard.submission_index.load(Ordering::Acquire);
+                        let raw = match res.inner {
+                            resource::TextureInner::Native { raw: Some(raw) } => raw,
+                            _ => continue,
+                        };
                         self.active
                             .iter_mut()
                             .find(|a| a.index == submit_index)
                             .map_or(&mut self.free_resources, |a| &mut a.last_resources)
-                            .images
-                            .extend(res.raw);
+                            .textures
+                            .push(raw);
                     }
                 }
             }
         }
 
         if !self.suspected_resources.samplers.is_empty() {
             let (mut guard, _) = hub.samplers.write(token);
             let mut trackers = trackers.lock();
@@ -517,25 +467,18 @@ impl<B: GfxBackend> LifetimeTracker<B> {
                     #[cfg(feature = "trace")]
                     if let Some(t) = trace {
                         t.lock().add(trace::Action::DestroyBuffer(id.0));
                     }
                     log::debug!("Buffer {:?} is detached", id);
 
                     if let Some(res) = hub.buffers.unregister_locked(id.0, &mut *guard) {
                         let submit_index = res.life_guard.submission_index.load(Ordering::Acquire);
-                        if let resource::BufferMapState::Init {
-                            stage_buffer,
-                            stage_memory,
-                            ..
-                        } = res.map_state
-                        {
-                            self.free_resources
-                                .buffers
-                                .push((stage_buffer, stage_memory));
+                        if let resource::BufferMapState::Init { stage_buffer, .. } = res.map_state {
+                            self.free_resources.buffers.push(stage_buffer);
                         }
                         self.active
                             .iter_mut()
                             .find(|a| a.index == submit_index)
                             .map_or(&mut self.free_resources, |a| &mut a.last_resources)
                             .buffers
                             .extend(res.raw);
                     }
@@ -579,17 +522,17 @@ impl<B: GfxBackend> LifetimeTracker<B> {
                     }
 
                     if let Some(res) = hub.render_pipelines.unregister_locked(id.0, &mut *guard) {
                         let submit_index = res.life_guard.submission_index.load(Ordering::Acquire);
                         self.active
                             .iter_mut()
                             .find(|a| a.index == submit_index)
                             .map_or(&mut self.free_resources, |a| &mut a.last_resources)
-                            .graphics_pipes
+                            .render_pipes
                             .push(res.raw);
                     }
                 }
             }
         }
 
         if !self.suspected_resources.pipeline_layouts.is_empty() {
             let (mut guard, _) = hub.pipeline_layouts.write(token);
@@ -625,17 +568,17 @@ impl<B: GfxBackend> LifetimeTracker<B> {
                 //Note: same BGL can appear multiple times in the list, but only the last
                 // encounter could drop the refcount to 0.
                 if guard[id].multi_ref_count.dec_and_check_empty() {
                     #[cfg(feature = "trace")]
                     if let Some(t) = trace {
                         t.lock().add(trace::Action::DestroyBindGroupLayout(id.0));
                     }
                     if let Some(lay) = hub.bind_group_layouts.unregister_locked(id.0, &mut *guard) {
-                        self.free_resources.descriptor_set_layouts.push(lay.raw);
+                        self.free_resources.bind_group_layouts.push(lay.raw);
                     }
                 }
             }
         }
 
         if !self.suspected_resources.query_sets.is_empty() {
             let (mut guard, _) = hub.query_sets.write(token);
             let mut trackers = trackers.lock();
@@ -655,18 +598,18 @@ impl<B: GfxBackend> LifetimeTracker<B> {
                     }
                 }
             }
         }
     }
 
     pub(super) fn triage_mapped<G: GlobalIdentityHandlerFactory>(
         &mut self,
-        hub: &Hub<B, G>,
-        token: &mut Token<super::Device<B>>,
+        hub: &Hub<A, G>,
+        token: &mut Token<super::Device<A>>,
     ) {
         if self.mapped.is_empty() {
             return;
         }
         let (buffer_guard, _) = hub.buffers.read(token);
 
         for stored in self.mapped.drain(..) {
             let resource_id = stored.value;
@@ -683,28 +626,29 @@ impl<B: GfxBackend> LifetimeTracker<B> {
             self.active
                 .iter_mut()
                 .find(|a| a.index == submit_index)
                 .map_or(&mut self.ready_to_map, |a| &mut a.mapped)
                 .push(resource_id);
         }
     }
 
+    #[must_use]
     pub(super) fn handle_mapping<G: GlobalIdentityHandlerFactory>(
         &mut self,
-        hub: &Hub<B, G>,
-        raw: &B::Device,
+        hub: &Hub<A, G>,
+        raw: &A::Device,
         trackers: &Mutex<TrackerSet>,
-        token: &mut Token<super::Device<B>>,
-    ) -> Vec<super::BufferMapPendingCallback> {
+        token: &mut Token<super::Device<A>>,
+    ) -> Vec<super::BufferMapPendingClosure> {
         if self.ready_to_map.is_empty() {
             return Vec::new();
         }
         let (mut buffer_guard, _) = hub.buffers.write(token);
-        let mut pending_callbacks: Vec<super::BufferMapPendingCallback> =
+        let mut pending_callbacks: Vec<super::BufferMapPendingClosure> =
             Vec::with_capacity(self.ready_to_map.len());
         let mut trackers = trackers.lock();
         for buffer_id in self.ready_to_map.drain(..) {
             let buffer = &mut buffer_guard[buffer_id];
             if buffer.life_guard.ref_count.is_none() && trackers.buffers.remove_abandoned(buffer_id)
             {
                 buffer.map_state = resource::BufferMapState::Idle;
                 log::debug!("Mapping request is dropped because the buffer is destroyed.");
@@ -733,20 +677,17 @@ impl<B: GfxBackend> LifetimeTracker<B> {
                 let status = if mapping.range.start != mapping.range.end {
                     log::debug!("Buffer {:?} map state -> Active", buffer_id);
                     let host = mapping.op.host;
                     let size = mapping.range.end - mapping.range.start;
                     match super::map_buffer(raw, buffer, mapping.range.start, size, host) {
                         Ok(ptr) => {
                             buffer.map_state = resource::BufferMapState::Active {
                                 ptr,
-                                sub_range: hal::buffer::SubRange {
-                                    offset: mapping.range.start,
-                                    size: Some(size),
-                                },
+                                range: mapping.range.start..mapping.range.start + size,
                                 host,
                             };
                             resource::BufferMapAsyncStatus::Success
                         }
                         Err(e) => {
                             log::error!("Mapping failed {:?}", e);
                             resource::BufferMapAsyncStatus::Error
                         }