# ==============================================================================
# REGRESSOR COMMIT DIFF
# ==============================================================================
# File: third_party/rust/gpu-descriptor/src/allocator.rs
# Commit: ef5dc3e04e5f
# Full Hash: ef5dc3e04e5f271eea0636ab3a495e95cc912f1d
# Author: Dzmitry Malyshau <dmalyshau@mozilla.com>
# Date: 2021-09-04 09:40:24
# Regressor Bug: 1726626
# File Overlap Count: 3
# Description:
#   Bug 1726626 - Move gfx/wgpu into a 3rd party dependency r=jgilbert,bholley
#   
#   This update makes wgpu a vendored dependency instead of having it in gfx/wgpu.
#   
#   ## Notes
# ==============================================================================

diff --git a/third_party/rust/gpu-descriptor/src/allocator.rs b/third_party/rust/gpu-descriptor/src/allocator.rs
--- a/third_party/rust/gpu-descriptor/src/allocator.rs
+++ b/third_party/rust/gpu-descriptor/src/allocator.rs
@@ -108,28 +108,43 @@ struct DescriptorBucket<P> {
     offset: u64,
     pools: VecDeque<DescriptorPool<P>>,
     total: u64,
     update_after_bind: bool,
     size: DescriptorTotalCount,
 }
 
 impl<P> Drop for DescriptorBucket<P> {
+    #[cfg(feature = "tracing")]
     fn drop(&mut self) {
         #[cfg(feature = "std")]
-        if !std::thread::panicking() {
-            assert_eq!(
-                self.total, 0,
-                "Allocator dropped before all sets were deallocated"
-            );
+        {
+            if std::thread::panicking() {
+                return;
+            }
+        }
+        if self.total > 0 {
+            tracing::error!("Descriptor sets were not deallocated");
+        }
+    }
 
-            assert!(
-                self.pools.is_empty(),
-                "All sets deallocated but pools were not. Make sure to call `Allocator::cleanup`"
-            );
+    #[cfg(all(not(feature = "tracing"), feature = "std"))]
+    fn drop(&mut self) {
+        if std::thread::panicking() {
+            return;
+        }
+        if self.total > 0 {
+            eprintln!("Descriptor sets were not deallocated")
+        }
+    }
+
+    #[cfg(all(not(feature = "tracing"), not(feature = "std")))]
+    fn drop(&mut self) {
+        if self.total > 0 {
+            panic!("Descriptor sets were not deallocated")
         }
     }
 }
 
 impl<P> DescriptorBucket<P> {
     fn new(update_after_bind: bool, size: DescriptorTotalCount) -> Self {
         DescriptorBucket {
             offset: 0,
@@ -157,34 +172,38 @@ impl<P> DescriptorBucket<P> {
         max_sets = (u32::MAX / self.size.storage_buffer.max(1)).min(max_sets);
         max_sets = (u32::MAX / self.size.uniform_buffer_dynamic.max(1)).min(max_sets);
         max_sets = (u32::MAX / self.size.storage_buffer_dynamic.max(1)).min(max_sets);
         max_sets = (u32::MAX / self.size.input_attachment.max(1)).min(max_sets);
         max_sets = (u32::MAX / self.size.acceleration_structure.max(1)).min(max_sets);
         max_sets = (u32::MAX / self.size.inline_uniform_block_bytes.max(1)).min(max_sets);
         max_sets = (u32::MAX / self.size.inline_uniform_block_bindings.max(1)).min(max_sets);
 
-        let size = DescriptorTotalCount {
+        let mut pool_size = DescriptorTotalCount {
             sampler: self.size.sampler * max_sets,
             combined_image_sampler: self.size.combined_image_sampler * max_sets,
             sampled_image: self.size.sampled_image * max_sets,
             storage_image: self.size.storage_image * max_sets,
             uniform_texel_buffer: self.size.uniform_texel_buffer * max_sets,
             storage_texel_buffer: self.size.storage_texel_buffer * max_sets,
             uniform_buffer: self.size.uniform_buffer * max_sets,
             storage_buffer: self.size.storage_buffer * max_sets,
             uniform_buffer_dynamic: self.size.uniform_buffer_dynamic * max_sets,
             storage_buffer_dynamic: self.size.storage_buffer_dynamic * max_sets,
             input_attachment: self.size.input_attachment * max_sets,
             acceleration_structure: self.size.acceleration_structure * max_sets,
             inline_uniform_block_bytes: self.size.inline_uniform_block_bytes * max_sets,
             inline_uniform_block_bindings: self.size.inline_uniform_block_bindings * max_sets,
         };
 
-        (size, max_sets)
+        if pool_size == Default::default() {
+            pool_size.sampler = 1;
+        }
+
+        (pool_size, max_sets)
     }
 
     unsafe fn allocate<L, S>(
         &mut self,
         device: &impl DescriptorDevice<L, P, S>,
         layout: &L,
         mut count: u32,
         allocated_sets: &mut Vec<DescriptorSet<S>>,
@@ -408,26 +427,28 @@ impl<P, S> DescriptorAllocator<P, S> {
     /// Allocate descriptor set with specified layout.
     ///
     /// # Safety
     ///
     /// * Same `device` instance must be passed to all method calls of
     /// one `DescriptorAllocator` instance.
     /// * `flags` must match flags that were used to create the layout.
     /// * `layout_descriptor_count` must match descriptor numbers in the layout.
-    pub unsafe fn allocate<L: Debug>(
+    pub unsafe fn allocate<L, D>(
         &mut self,
-        device: &impl DescriptorDevice<L, P, S>,
+        device: &D,
         layout: &L,
         flags: DescriptorSetLayoutCreateFlags,
         layout_descriptor_count: &DescriptorTotalCount,
         count: u32,
     ) -> Result<Vec<DescriptorSet<S>>, AllocationError>
     where
         S: Debug,
+        L: Debug,
+        D: DescriptorDevice<L, P, S>,
     {
         if count == 0 {
             return Ok(Vec::new());
         }
 
         let update_after_bind = flags.contains(DescriptorSetLayoutCreateFlags::UPDATE_AFTER_BIND);
 
         #[cfg(feature = "tracing")]
@@ -474,21 +495,21 @@ impl<P, S> DescriptorAllocator<P, S> {
     ///
     /// # Safety
     ///
     /// * Same `device` instance must be passed to all method calls of
     ///   one `DescriptorAllocator` instance.
     /// * None of descriptor sets can be referenced in any pending command buffers.
     /// * All command buffers where at least one of descriptor sets referenced
     /// move to invalid state.
-    pub unsafe fn free<L>(
-        &mut self,
-        device: &impl DescriptorDevice<L, P, S>,
-        sets: impl IntoIterator<Item = DescriptorSet<S>>,
-    ) {
+    pub unsafe fn free<L, D, I>(&mut self, device: &D, sets: I)
+    where
+        D: DescriptorDevice<L, P, S>,
+        I: IntoIterator<Item = DescriptorSet<S>>,
+    {
         debug_assert!(self.raw_sets_cache.is_empty());
 
         let mut last_key = (EMPTY_COUNT, false);
         let mut last_pool_id = None;
 
         for set in sets {
             if last_key != (set.size, set.update_after_bind) || last_pool_id != Some(set.pool_id) {
                 if let Some(pool_id) = last_pool_id {