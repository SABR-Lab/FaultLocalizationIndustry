# ==============================================================================
# REGRESSOR COMMIT DIFF
# ==============================================================================
# File: dom/media/mp4/SampleIterator.cpp
# Commit: aa102eb9990d
# Full Hash: aa102eb9990d6edbd5cf7473c5017082340764ff
# Author: Paul Adenot <paul@paul.cx>
# Date: 2023-05-24 21:42:08
# Regressor Bug: 1817997
# File Overlap Count: 3
# Description:
#   Bug 1817997 - Update the MP4 demuxer to use TimeUnit based on the internal MP4 time base. r=alwu
#   
#   This still gets the initial time value from mp4parse-rust, that is in
#   microseconds. mp4parse-rust has been updated to expose real time, and will be
#   updated later.
# ==============================================================================

diff -r 5c1b6ce71ca1 -r aa102eb9990d dom/media/mp4/SampleIterator.cpp
--- a/dom/media/mp4/SampleIterator.cpp	Wed May 24 13:18:40 2023 +0000
+++ b/dom/media/mp4/SampleIterator.cpp	Wed May 24 13:18:40 2023 +0000
@@ -27,14 +27,14 @@
     // Ranges must be normalised for this to work
   }
 
-  bool Contains(MediaByteRange aByteRange);
+  bool Contains(const MediaByteRange& aByteRange);
 
  private:
   const MediaByteRangeSet& mRanges;
   size_t mIndex;
 };
 
-bool RangeFinder::Contains(MediaByteRange aByteRange) {
+bool RangeFinder::Contains(const MediaByteRange& aByteRange) {
   if (mRanges.IsEmpty()) {
     return false;
   }
@@ -94,9 +94,9 @@
   }
 
   RefPtr<MediaRawData> sample = new MediaRawData();
-  sample->mTimecode = TimeUnit::FromMicroseconds(s->mDecodeTime);
-  sample->mTime = TimeUnit::FromMicroseconds(s->mCompositionRange.start);
-  sample->mDuration = TimeUnit::FromMicroseconds(s->mCompositionRange.Length());
+  sample->mTimecode = s->mDecodeTime;
+  sample->mTime = s->mCompositionRange.start;
+  sample->mDuration = s->mCompositionRange.Length();
   sample->mOffset = s->mByteRange.mStart;
   sample->mKeyframe = s->mSync;
 
@@ -380,7 +380,7 @@
 
 void SampleIterator::Next() { ++mCurrentSample; }
 
-void SampleIterator::Seek(Microseconds aTime) {
+void SampleIterator::Seek(const TimeUnit& aTime) {
   size_t syncMoof = 0;
   size_t syncSample = 0;
   mCurrentMoof = 0;
@@ -403,7 +403,7 @@
   mCurrentSample = syncSample;
 }
 
-Microseconds SampleIterator::GetNextKeyframeTime() {
+TimeUnit SampleIterator::GetNextKeyframeTime() {
   SampleIterator itr(*this);
   Sample* sample;
   while (!!(sample = itr.Get())) {
@@ -412,7 +412,7 @@
     }
     itr.Next();
   }
-  return -1;
+  return TimeUnit::Invalid();
 }
 
 MP4SampleIndex::MP4SampleIndex(const IndiceWrapper& aIndices,
@@ -427,13 +427,13 @@
       // OOM.
       return;
     }
-    media::IntervalSet<int64_t> intervalTime;
+    media::IntervalSet<TimeUnit> intervalTime;
     MediaByteRange intervalRange;
     bool haveSync = false;
     bool progressive = true;
     int64_t lastOffset = 0;
     for (size_t i = 0; i < aIndices.Length(); i++) {
-      Indice indice;
+      Indice indice{};
       if (!aIndices.GetIndice(i, indice)) {
         // Out of index?
         return;
@@ -447,9 +447,10 @@
       Sample sample;
       sample.mByteRange =
           MediaByteRange(indice.start_offset, indice.end_offset);
-      sample.mCompositionRange = MP4Interval<Microseconds>(
-          indice.start_composition, indice.end_composition);
-      sample.mDecodeTime = indice.start_decode;
+      sample.mCompositionRange = MP4Interval<media::TimeUnit>(
+          TimeUnit::FromMicroseconds(indice.start_composition),
+          TimeUnit::FromMicroseconds(indice.end_composition));
+      sample.mDecodeTime = TimeUnit::FromMicroseconds(indice.start_decode);
       sample.mSync = indice.sync || mIsAudio;
       // FIXME: Make this infallible after bug 968520 is done.
       MOZ_ALWAYS_TRUE(mIndex.AppendElement(sample, fallible));
@@ -475,11 +476,11 @@
           // OOM.
           return;
         }
-        intervalTime = media::IntervalSet<int64_t>();
+        intervalTime = media::IntervalSet<TimeUnit>();
         intervalRange = MediaByteRange();
       }
-      intervalTime += media::Interval<int64_t>(sample.mCompositionRange.start,
-                                               sample.mCompositionRange.end);
+      intervalTime += media::Interval<TimeUnit>(sample.mCompositionRange.start,
+                                                sample.mCompositionRange.end);
       intervalRange = intervalRange.Span(sample.mByteRange);
     }
 
@@ -491,7 +492,7 @@
       auto& last = mDataOffset.LastElement();
       last.mEndOffset = indice.end_offset;
       last.mTime =
-          MP4Interval<int64_t>(intervalTime.GetStart(), intervalTime.GetEnd());
+          MP4Interval<TimeUnit>(intervalTime.GetStart(), intervalTime.GetEnd());
     } else {
       mDataOffset.Clear();
     }
@@ -532,31 +533,33 @@
   }
 }
 
-Microseconds MP4SampleIndex::GetEndCompositionIfBuffered(
+TimeUnit MP4SampleIndex::GetEndCompositionIfBuffered(
     const MediaByteRangeSet& aByteRanges) {
   FallibleTArray<Sample>* index;
   if (mMoofParser) {
+    int64_t base = mMoofParser->mMdhd.mTimescale;
     if (!mMoofParser->ReachedEnd() || mMoofParser->Moofs().IsEmpty()) {
-      return 0;
+      return TimeUnit::Zero(base);
     }
     index = &mMoofParser->Moofs().LastElement().mIndex;
   } else {
     index = &mIndex;
   }
 
-  Microseconds lastComposition = 0;
+  int64_t base = mMoofParser->mMdhd.mTimescale;
+  media::TimeUnit lastComposition = TimeUnit::Zero(base);
   RangeFinder rangeFinder(aByteRanges);
   for (size_t i = index->Length(); i--;) {
     const Sample& sample = (*index)[i];
     if (!rangeFinder.Contains(sample.mByteRange)) {
-      return 0;
+      return TimeUnit::Zero(base);
     }
     lastComposition = std::max(lastComposition, sample.mCompositionRange.end);
     if (sample.mSync) {
       return lastComposition;
     }
   }
-  return 0;
+  return TimeUnit::Zero(base);
 }
 
 TimeIntervals MP4SampleIndex::ConvertByteRangesToTimeRanges(
@@ -585,17 +588,15 @@
         for (size_t i = mDataOffset[start - 1].mIndex; i < mIndex.Length();
              i++) {
           if (range.ContainsStrict(mIndex[i].mByteRange)) {
-            timeRanges += TimeInterval(
-                TimeUnit::FromMicroseconds(mIndex[i].mCompositionRange.start),
-                TimeUnit::FromMicroseconds(mIndex[i].mCompositionRange.end));
+            timeRanges += TimeInterval(mIndex[i].mCompositionRange.start,
+                                       mIndex[i].mCompositionRange.end);
           }
         }
       }
       if (end > start) {
         for (uint32_t i = start; i < end; i++) {
-          timeRanges += TimeInterval(
-              TimeUnit::FromMicroseconds(mDataOffset[i].mTime.start),
-              TimeUnit::FromMicroseconds(mDataOffset[i].mTime.end));
+          timeRanges += TimeInterval(mDataOffset[i].mTime.start,
+                                     mDataOffset[i].mTime.end);
         }
       }
       if (end < mDataOffset.Length()) {
@@ -603,9 +604,8 @@
         for (size_t i = mDataOffset[end].mIndex;
              i < mIndex.Length() && range.ContainsStrict(mIndex[i].mByteRange);
              i++) {
-          timeRanges += TimeInterval(
-              TimeUnit::FromMicroseconds(mIndex[i].mCompositionRange.start),
-              TimeUnit::FromMicroseconds(mIndex[i].mCompositionRange.end));
+          timeRanges += TimeInterval(mIndex[i].mCompositionRange.start,
+                                     mIndex[i].mCompositionRange.end);
         }
       }
     }
@@ -614,7 +614,7 @@
   }
 
   RangeFinder rangeFinder(aByteRanges);
-  nsTArray<MP4Interval<Microseconds>> timeRanges;
+  nsTArray<MP4Interval<media::TimeUnit>> timeRanges;
   nsTArray<FallibleTArray<Sample>*> indexes;
   if (mMoofParser) {
     // We take the index out of the moof parser and move it into a local
@@ -626,8 +626,8 @@
       // We need the entire moof in order to play anything
       if (rangeFinder.Contains(moof.mRange)) {
         if (rangeFinder.Contains(moof.mMdatRange)) {
-          MP4Interval<Microseconds>::SemiNormalAppend(timeRanges,
-                                                      moof.mTimeRange);
+          MP4Interval<media::TimeUnit>::SemiNormalAppend(timeRanges,
+                                                         moof.mTimeRange);
         } else {
           indexes.AppendElement(&moof.mIndex);
         }
@@ -654,26 +654,25 @@
         continue;
       }
 
-      MP4Interval<Microseconds>::SemiNormalAppend(timeRanges,
+      MP4Interval<media::TimeUnit>::SemiNormalAppend(timeRanges,
                                                   sample.mCompositionRange);
     }
   }
 
   // This fixes up when the compositon order differs from the byte range order
-  nsTArray<MP4Interval<Microseconds>> timeRangesNormalized;
-  MP4Interval<Microseconds>::Normalize(timeRanges, &timeRangesNormalized);
+  nsTArray<MP4Interval<TimeUnit>> timeRangesNormalized;
+  MP4Interval<media::TimeUnit>::Normalize(timeRanges, &timeRangesNormalized);
   // convert timeRanges.
   media::TimeIntervals ranges;
   for (size_t i = 0; i < timeRangesNormalized.Length(); i++) {
-    ranges += media::TimeInterval(
-        media::TimeUnit::FromMicroseconds(timeRangesNormalized[i].start),
-        media::TimeUnit::FromMicroseconds(timeRangesNormalized[i].end));
+    ranges += media::TimeInterval(timeRangesNormalized[i].start,
+                                  timeRangesNormalized[i].end);
   }
   mLastBufferedRanges = ranges;
   return ranges;
 }
 
-uint64_t MP4SampleIndex::GetEvictionOffset(Microseconds aTime) {
+uint64_t MP4SampleIndex::GetEvictionOffset(const TimeUnit& aTime) {
   uint64_t offset = std::numeric_limits<uint64_t>::max();
   if (mMoofParser) {
     // We need to keep the whole moof if we're keeping any of it because the
@@ -681,7 +680,7 @@
     for (int i = 0; i < mMoofParser->Moofs().Length(); i++) {
       Moof& moof = mMoofParser->Moofs()[i];
 
-      if (moof.mTimeRange.Length() && moof.mTimeRange.end > aTime) {
+      if (!moof.mTimeRange.Length().IsZero() && moof.mTimeRange.end > aTime) {
         offset = std::min(offset, uint64_t(std::min(moof.mRange.mStart,
                                                     moof.mMdatRange.mStart)));
       }