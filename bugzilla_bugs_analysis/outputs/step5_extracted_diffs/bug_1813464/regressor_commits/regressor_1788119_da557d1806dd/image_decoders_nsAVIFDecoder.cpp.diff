# ==============================================================================
# REGRESSOR COMMIT DIFF
# ==============================================================================
# File: image/decoders/nsAVIFDecoder.cpp
# Commit: da557d1806dd
# Full Hash: da557d1806dd9e1e519e00a4481b2e075f722ae8
# Author: Butkovits Atila <abutkovits@mozilla.com>
# Date: 2023-01-27 22:54 +0200
# Regressor Bug: 1788119
# File Overlap Count: 1
# Overlapping Files: Cargo.lock
# Description:
#   Backed out 5 changesets (bug 1788119) for causing bustages complaining about AVIFDecodedData. CLOSED TREE
# ==============================================================================

diff -r d980bebc6d26 -r da557d1806dd image/decoders/nsAVIFDecoder.cpp
--- a/image/decoders/nsAVIFDecoder.cpp	Fri Jan 27 20:35:34 2023 +0000
+++ b/image/decoders/nsAVIFDecoder.cpp	Fri Jan 27 22:54:08 2023 +0200
@@ -12,6 +12,7 @@
 
 #include "DAV1DDecoder.h"
 #include "gfxPlatform.h"
+#include "mozilla/gfx/Types.h"
 #include "YCbCrUtils.h"
 #include "libyuv.h"
 
@@ -58,9 +59,9 @@
     LABELS_AVIF_YUV_COLOR_SPACE::BT601, LABELS_AVIF_YUV_COLOR_SPACE::BT709,
     LABELS_AVIF_YUV_COLOR_SPACE::BT2020, LABELS_AVIF_YUV_COLOR_SPACE::identity};
 
-static MaybeIntSize GetImageSize(const Mp4parseAvifInfo& aInfo) {
+static MaybeIntSize GetImageSize(const Mp4parseAvifImage& image) {
   // Note this does not take cropping via CleanAperture (clap) into account
-  const struct Mp4parseImageSpatialExtents* ispe = aInfo.spatial_extents;
+  const struct Mp4parseImageSpatialExtents* ispe = image.spatial_extents;
 
   if (ispe) {
     // Decoder::PostSize takes int32_t, but ispe contains uint32_t
@@ -75,18 +76,53 @@
   return Nothing();
 }
 
+// Translate the number of bits per channel into a single ColorDepth.
+// Return Nothing if the number of bits per channel is not uniform.
+static Maybe<uint8_t> BitsPerChannelToBitDepth(
+    const Mp4parseByteData& bits_per_channel) {
+  if (bits_per_channel.length == 0) {
+    return Nothing();
+  }
+
+  for (uintptr_t i = 1; i < bits_per_channel.length; ++i) {
+    if (bits_per_channel.data[i] != bits_per_channel.data[0]) {
+      // log mismatch
+      return Nothing();
+    }
+  }
+
+  return Some(bits_per_channel.data[0]);
+}
+
+static void RecordPixiTelemetry(Maybe<uint8_t>& pixiBitDepth,
+                                uint8_t aBitstreamBitDepth,
+                                const char* aItemName) {
+  if (pixiBitDepth.isNothing()) {
+    AccumulateCategorical(LABELS_AVIF_PIXI::absent);
+  } else if (pixiBitDepth == Some(aBitstreamBitDepth)) {
+    AccumulateCategorical(LABELS_AVIF_PIXI::valid);
+  } else {
+    MOZ_ASSERT(pixiBitDepth.isSome());
+    MOZ_LOG(sAVIFLog, LogLevel::Error,
+            ("%s item pixi bit depth (%hhu) doesn't match "
+             "bitstream (%hhu)",
+             aItemName, *pixiBitDepth, aBitstreamBitDepth));
+    AccumulateCategorical(LABELS_AVIF_PIXI::bitstream_mismatch);
+  }
+}
+
 // Translate the MIAF/HEIF-based orientation transforms (imir, irot) into
 // ImageLib's representation. Note that the interpretation of imir was reversed
 // Between HEIF (ISO 23008-12:2017) and ISO/IEC 23008-12:2017/DAmd 2. This is
 // handled by mp4parse. See mp4parse::read_imir for details.
-Orientation GetImageOrientation(const Mp4parseAvifInfo& aInfo) {
+Orientation GetImageOrientation(const Mp4parseAvifImage& image) {
   // Per MIAF (ISO/IEC 23000-22:2019) § 7.3.6.7
   //   These properties, if used, shall be indicated to be applied in the
   //   following order: clean aperture first, then rotation, then mirror.
   // The Orientation type does the same order, but opposite rotation direction
 
-  const Mp4parseIrot heifRot = aInfo.image_rotation;
-  const Mp4parseImir* heifMir = aInfo.image_mirror;
+  const Mp4parseIrot heifRot = image.image_rotation;
+  const Mp4parseImir* heifMir = image.image_mirror;
   Angle mozRot;
   Flip mozFlip;
 
@@ -167,203 +203,147 @@
            static_cast<int>(mozRot), static_cast<int>(mozFlip)));
   return Orientation{mozRot, mozFlip};
 }
-bool AVIFDecoderStream::ReadAt(int64_t offset, void* data, size_t size,
-                               size_t* bytes_read) {
-  size = std::min(size, size_t(mBuffer->length() - offset));
+
+class AVIFParser {
+ public:
+  static Mp4parseStatus Create(const Mp4parseIo* aIo,
+                               UniquePtr<AVIFParser>& aParserOut) {
+    MOZ_ASSERT(aIo);
+    MOZ_ASSERT(!aParserOut);
 
-  if (size <= 0) {
-    return false;
+    UniquePtr<AVIFParser> p(new AVIFParser(aIo));
+    Mp4parseStatus status = p->Init();
+
+    if (status == MP4PARSE_STATUS_OK) {
+      MOZ_ASSERT(p->mParser);
+      aParserOut = std::move(p);
+    }
+
+    return status;
   }
 
-  memcpy(data, mBuffer->begin() + offset, size);
-  *bytes_read = size;
-  return true;
-}
-
-bool AVIFDecoderStream::Length(int64_t* size) {
-  *size =
-      static_cast<int64_t>(std::min<uint64_t>(mBuffer->length(), INT64_MAX));
-  return true;
-}
-
-const uint8_t* AVIFDecoderStream::GetContiguousAccess(int64_t aOffset,
-                                                      size_t aSize) {
-  if (aOffset + aSize >= mBuffer->length()) {
-    return nullptr;
-  }
-
-  return mBuffer->begin() + aOffset;
-}
-
-AVIFParser::~AVIFParser() {
-  MOZ_LOG(sAVIFLog, LogLevel::Debug, ("Destroy AVIFParser=%p", this));
-}
-
-Mp4parseStatus AVIFParser::Create(const Mp4parseIo* aIo, ByteStream* aBuffer,
-                                  UniquePtr<AVIFParser>& aParserOut) {
-  MOZ_ASSERT(aIo);
-  MOZ_ASSERT(!aParserOut);
-
-  UniquePtr<AVIFParser> p(new AVIFParser(aIo));
-  Mp4parseStatus status = p->Init(aBuffer);
-
-  if (status == MP4PARSE_STATUS_OK) {
-    MOZ_ASSERT(p->mParser);
-    aParserOut = std::move(p);
+  ~AVIFParser() {
+    MOZ_LOG(sAVIFLog, LogLevel::Debug, ("Destroy AVIFParser=%p", this));
   }
 
-  return status;
-}
-
-nsAVIFDecoder::DecodeResult AVIFParser::GetImage(AVIFImage& aImage) {
-  MOZ_ASSERT(mParser);
-
-  // If the AVIF is animated, get next frame and yield if sequence is not done.
-  if (IsAnimated()) {
-    aImage.mColorImage = mColorSampleIter->GetNext();
-
-    if (!aImage.mColorImage) {
-      if (mFrameNum == 0) {
-        return AsVariant(nsAVIFDecoder::NonDecoderResult::NoSamples);
-      }
-      return AsVariant(nsAVIFDecoder::NonDecoderResult::Complete);
-    }
+  Mp4parseAvifImage* GetImage() {
+    MOZ_ASSERT(mParser);
 
-    aImage.mFrameNum = mFrameNum++;
-    int64_t durationMs =
-        aImage.mColorImage->mDuration.ToMicroseconds() / USECS_PER_MS;
-    aImage.mDuration = FrameTimeout::FromRawMilliseconds(
-        static_cast<int32_t>(std::min(durationMs, INT64_MAX)));
-
-    if (mAlphaSampleIter) {
-      aImage.mAlphaImage = mAlphaSampleIter->GetNext();
+    if (mAvifImage.isNothing()) {
+      mAvifImage.emplace();
+      Mp4parseStatus status =
+          mp4parse_avif_get_image(mParser.get(), mAvifImage.ptr());
+      MOZ_LOG(sAVIFLog, LogLevel::Debug,
+              ("[this=%p] mp4parse_avif_get_image -> %d; primary_item length: "
+               "%zu, alpha_item length: %zu",
+               this, status, mAvifImage->primary_image.coded_data.length,
+               mAvifImage->alpha_image.coded_data.length));
+      if (status != MP4PARSE_STATUS_OK) {
+        mAvifImage.reset();
+        return nullptr;
+      }
     }
-
-    bool hasNext = mColorSampleIter->HasNext();
-    MOZ_ASSERT_IF(mAlphaSampleIter, hasNext == mAlphaSampleIter->HasNext());
-    if (!hasNext) {
-      return AsVariant(nsAVIFDecoder::NonDecoderResult::Complete);
-    }
-    return AsVariant(nsAVIFDecoder::NonDecoderResult::OutputAvailable);
+    return mAvifImage.ptr();
   }
 
-  if (!mInfo.has_primary_item) {
-    return AsVariant(nsAVIFDecoder::NonDecoderResult::NoSamples);
+ private:
+  explicit AVIFParser(const Mp4parseIo* aIo) : mIo(aIo) {
+    MOZ_ASSERT(mIo);
+    MOZ_LOG(sAVIFLog, LogLevel::Debug,
+            ("Create AVIFParser=%p, image.avif.compliance_strictness: %d", this,
+             StaticPrefs::image_avif_compliance_strictness()));
   }
 
-  // If the AVIF is not animated, get the pitm image and return Complete.
-  Mp4parseAvifImage image = {};
-  Mp4parseStatus status = mp4parse_avif_get_image(mParser.get(), &image);
-  MOZ_LOG(sAVIFLog, LogLevel::Debug,
-          ("[this=%p] mp4parse_avif_get_image -> %d; primary_item length: "
-           "%zu, alpha_item length: %zu",
-           this, status, image.primary_image.length, image.alpha_image.length));
-  if (status != MP4PARSE_STATUS_OK) {
-    return AsVariant(status);
+  Mp4parseStatus Init() {
+    MOZ_ASSERT(!mParser);
+
+    Mp4parseAvifParser* parser = nullptr;
+    Mp4parseStatus status =
+        mp4parse_avif_new(mIo,
+                          static_cast<enum Mp4parseStrictness>(
+                              StaticPrefs::image_avif_compliance_strictness()),
+                          &parser);
+    MOZ_LOG(sAVIFLog, LogLevel::Debug,
+            ("[this=%p] mp4parse_avif_new status: %d", this, status));
+    if (status == MP4PARSE_STATUS_OK) {
+      mParser.reset(parser);
+    }
+    return status;
   }
 
-  MOZ_ASSERT(image.primary_image.data);
-  RefPtr<MediaRawData> colorImage =
-      new MediaRawData(image.primary_image.data, image.primary_image.length);
-  RefPtr<MediaRawData> alphaImage = nullptr;
-
-  if (image.alpha_image.length) {
-    alphaImage =
-        new MediaRawData(image.alpha_image.data, image.alpha_image.length);
-  }
-
-  aImage.mFrameNum = 0;
-  aImage.mDuration = FrameTimeout::Forever();
-  aImage.mColorImage = colorImage;
-  aImage.mAlphaImage = alphaImage;
-  return AsVariant(nsAVIFDecoder::NonDecoderResult::Complete);
-}
-
-AVIFParser::AVIFParser(const Mp4parseIo* aIo) : mIo(aIo) {
-  MOZ_ASSERT(mIo);
-  MOZ_LOG(sAVIFLog, LogLevel::Debug,
-          ("Create AVIFParser=%p, image.avif.compliance_strictness: %d", this,
-           StaticPrefs::image_avif_compliance_strictness()));
-}
+  struct FreeAvifParser {
+    void operator()(Mp4parseAvifParser* aPtr) { mp4parse_avif_free(aPtr); }
+  };
 
-static Mp4parseStatus CreateSampleIterator(
-    Mp4parseAvifParser* aParser, ByteStream* aBuffer, uint32_t trackID,
-    UniquePtr<SampleIterator>& aIteratorOut) {
-  Mp4parseByteData data;
-  Mp4parseStatus rv = mp4parse_avif_get_indice_table(aParser, trackID, &data);
-  if (rv != MP4PARSE_STATUS_OK) {
-    return rv;
-  }
-
-  UniquePtr<IndiceWrapper> wrapper = MakeUnique<IndiceWrapper>(data);
-  RefPtr<MP4SampleIndex> index =
-      new MP4SampleIndex(*wrapper, aBuffer, trackID, false);
-  aIteratorOut = MakeUnique<SampleIterator>(index);
-  return MP4PARSE_STATUS_OK;
-}
-
-Mp4parseStatus AVIFParser::Init(ByteStream* aBuffer) {
-#define CHECK_MP4PARSE_STATUS(v)     \
-  do {                               \
-    if ((v) != MP4PARSE_STATUS_OK) { \
-      return v;                      \
-    }                                \
-  } while (false)
-
-  MOZ_ASSERT(!mParser);
+  const Mp4parseIo* mIo;
+  UniquePtr<Mp4parseAvifParser, FreeAvifParser> mParser;
+  Maybe<Mp4parseAvifImage> mAvifImage;
+};
 
-  Mp4parseAvifParser* parser = nullptr;
-  Mp4parseStatus status =
-      mp4parse_avif_new(mIo,
-                        static_cast<enum Mp4parseStrictness>(
-                            StaticPrefs::image_avif_compliance_strictness()),
-                        &parser);
-  MOZ_LOG(sAVIFLog, LogLevel::Debug,
-          ("[this=%p] mp4parse_avif_new status: %d", this, status));
-  CHECK_MP4PARSE_STATUS(status);
-  MOZ_ASSERT(parser);
-  mParser.reset(parser);
-
-  status = mp4parse_avif_get_info(mParser.get(), &mInfo);
-  CHECK_MP4PARSE_STATUS(status);
-
-  bool shouldAnimate = mInfo.has_sequence;
+// CICP values (either from the BMFF container or the AV1 sequence header) are
+// used to create the colorspace transform. CICP::MatrixCoefficients is only
+// stored for the sake of telemetry, since the relevant information for YUV ->
+// RGB conversion is stored in mYUVColorSpace.
+//
+// There are three potential sources of color information for an AVIF:
+// 1. ICC profile via a ColourInformationBox (colr) defined in [ISOBMFF]
+//    § 12.1.5 "Colour information" and [MIAF] § 7.3.6.4 "Colour information
+//    property"
+// 2. NCLX (AKA CICP see [ITU-T H.273]) values in the same ColourInformationBox
+//    which can have an ICC profile or NCLX values, not both).
+// 3. NCLX values in the AV1 bitstream
+//
+// The 'colr' box is optional, but there are always CICP values in the AV1
+// bitstream, so it is possible to have both. Per ISOBMFF § 12.1.5.1
+// > If colour information is supplied in both this box, and also in the
+// > video bitstream, this box takes precedence, and over-rides the
+// > information in the bitstream.
+//
+// If present, the ICC profile takes precedence over CICP values, but only
+// specifies the color space, not the matrix coefficients necessary to convert
+// YCbCr data (as most AVIF are encoded) to RGB. The matrix coefficients are
+// always derived from the CICP values for matrix_coefficients (and potentially
+// colour_primaries, but in that case only the CICP values for colour_primaries
+// will be used, not anything harvested from the ICC profile).
+//
+// If there is no ICC profile, the color space transform will be based on the
+// CICP values either from the 'colr' box, or if absent/unspecified, the
+// decoded AV1 sequence header.
+//
+// For values that are 2 (meaning unspecified) after trying both, the
+// fallback values are:
+// - CP:  1 (BT.709/sRGB)
+// - TC: 13 (sRGB)
+// - MC:  6 (BT.601)
+// - Range: Full
+//
+// Additional details here:
+// <https://github.com/AOMediaCodec/libavif/wiki/CICP#unspecified>. Note
+// that this contradicts the current version of [MIAF] § 7.3.6.4 which
+// specifies MC=1 (BT.709). This is revised in [MIAF DAMD2] and confirmed by
+// <https://github.com/AOMediaCodec/av1-avif/issues/77#issuecomment-676526097>
+//
+// The precedence for applying the various values and defaults in the event
+// no valid values are found are managed by the following functions.
+//
+// References:
+// [ISOBMFF]: ISO/IEC 14496-12:2020 <https://www.iso.org/standard/74428.html>
+// [MIAF]: ISO/IEC 23000-22:2019 <https://www.iso.org/standard/74417.html>
+// [MIAF DAMD2]: ISO/IEC 23000-22:2019/FDAmd 2
+// <https://www.iso.org/standard/81634.html>
+// [ITU-T H.273]: Rec. ITU-T H.273 (12/2016)
+//     <https://www.itu.int/rec/T-REC-H.273-201612-I/en>
+struct AVIFDecodedData : layers::PlanarYCbCrData {
+  CICP::ColourPrimaries mColourPrimaries = CICP::CP_UNSPECIFIED;
+  CICP::TransferCharacteristics mTransferCharacteristics = CICP::TC_UNSPECIFIED;
+  CICP::MatrixCoefficients mMatrixCoefficients = CICP::MC_UNSPECIFIED;
 
-  // Disable animation if the specified major brand is avif or avis is preffed
-  // off.
-  if (shouldAnimate) {
-    if (!StaticPrefs::image_avif_sequence_enabled()) {
-      shouldAnimate = false;
-      MOZ_LOG(sAVIFLog, LogLevel::Debug,
-              ("[this=%p] AVIF sequences disabled", this));
-    } else if (shouldAnimate &&
-               !StaticPrefs::
-                   image_avif_sequence_animate_avif_major_branded_images() &&
-               !memcmp(mInfo.major_brand, "avif", sizeof(mInfo.major_brand))) {
-      shouldAnimate = false;
-      MOZ_LOG(sAVIFLog, LogLevel::Debug,
-              ("[this=%p] AVIF prefers still image", this));
-    }
-  }
-
-  if (shouldAnimate) {
-    status = CreateSampleIterator(parser, aBuffer, mInfo.color_track_id,
-                                  mColorSampleIter);
-    CHECK_MP4PARSE_STATUS(status);
-    MOZ_ASSERT(mColorSampleIter);
-
-    if (mInfo.alpha_track_id) {
-      status = CreateSampleIterator(parser, aBuffer, mInfo.alpha_track_id,
-                                    mAlphaSampleIter);
-      CHECK_MP4PARSE_STATUS(status);
-      MOZ_ASSERT(mAlphaSampleIter);
-    }
-  }
-
-  return status;
-}
-
-bool AVIFParser::IsAnimated() const { return !!mColorSampleIter; }
+  void SetCicpValues(
+      const Mp4parseNclxColourInformation* aNclx,
+      const CICP::ColourPrimaries aAv1ColourPrimaries,
+      const CICP::TransferCharacteristics aAv1TransferCharacteristics,
+      const CICP::MatrixCoefficients aAv1MatrixCoefficients);
+};
 
 // The gfx::YUVColorSpace value is only used in the conversion from YUV -> RGB.
 // Typically this comes directly from the CICP matrix_coefficients value, but
@@ -400,239 +380,186 @@
       .valueOr(av1ColorRange);
 }
 
-struct Dav1dPictureUnref {
-  void operator()(Dav1dPicture* aPtr) {
-    dav1d_picture_unref(aPtr);
-    delete aPtr;
-  }
-};
-
-using OwnedDav1dPicture = UniquePtr<Dav1dPicture, Dav1dPictureUnref>;
+void AVIFDecodedData::SetCicpValues(
+    const Mp4parseNclxColourInformation* aNclx,
+    const CICP::ColourPrimaries aAv1ColourPrimaries,
+    const CICP::TransferCharacteristics aAv1TransferCharacteristics,
+    const CICP::MatrixCoefficients aAv1MatrixCoefficients) {
+  auto cp = CICP::ColourPrimaries::CP_UNSPECIFIED;
+  auto tc = CICP::TransferCharacteristics::TC_UNSPECIFIED;
+  auto mc = CICP::MatrixCoefficients::MC_UNSPECIFIED;
 
-class OwnedAOMImage {
- public:
-  ~OwnedAOMImage();
-
-  static OwnedAOMImage* CopyFrom(aom_image_t* aImage, bool aIsAlpha);
-
-  aom_image_t* GetImage() { return mImage.isSome() ? mImage.ptr() : nullptr; }
-
- private:
-  OwnedAOMImage();
+  if (aNclx) {
+    cp = static_cast<CICP::ColourPrimaries>(aNclx->colour_primaries);
+    tc = static_cast<CICP::TransferCharacteristics>(
+        aNclx->transfer_characteristics);
+    mc = static_cast<CICP::MatrixCoefficients>(aNclx->matrix_coefficients);
+  }
 
-  bool CloneFrom(aom_image_t* aImage, bool aIsAlpha);
-
-  // The mImage's planes are referenced to mBuffer
-  Maybe<aom_image_t> mImage;
-  UniquePtr<uint8_t[]> mBuffer;
-};
+  if (cp == CICP::ColourPrimaries::CP_UNSPECIFIED) {
+    if (aAv1ColourPrimaries != CICP::ColourPrimaries::CP_UNSPECIFIED) {
+      cp = aAv1ColourPrimaries;
+      MOZ_LOG(sAVIFLog, LogLevel::Info,
+              ("Unspecified colour_primaries value specified in colr box, "
+               "using AV1 sequence header (%hhu)",
+               cp));
+    } else {
+      cp = CICP::ColourPrimaries::CP_BT709;
+      MOZ_LOG(sAVIFLog, LogLevel::Warning,
+              ("Unspecified colour_primaries value specified in colr box "
+               "or AV1 sequence header, using fallback value (%hhu)",
+               cp));
+    }
+  } else if (cp != aAv1ColourPrimaries) {
+    MOZ_LOG(sAVIFLog, LogLevel::Warning,
+            ("colour_primaries mismatch: colr box = %hhu, AV1 "
+             "sequence header = %hhu, using colr box",
+             cp, aAv1ColourPrimaries));
+  }
 
-struct AVIFDecodedData : layers::PlanarYCbCrData {
- public:
-  OrientedIntRect mRenderRect = {};
-  gfx::CICP::ColourPrimaries mColourPrimaries = gfx::CICP::CP_UNSPECIFIED;
-  gfx::CICP::TransferCharacteristics mTransferCharacteristics =
-      gfx::CICP::TC_UNSPECIFIED;
-  gfx::CICP::MatrixCoefficients mMatrixCoefficients = gfx::CICP::MC_UNSPECIFIED;
-
-  OwnedDav1dPicture mColorDav1d;
-  OwnedDav1dPicture mAlphaDav1d;
-  UniquePtr<OwnedAOMImage> mColorAOM;
-  UniquePtr<OwnedAOMImage> mAlphaAOM;
+  if (tc == CICP::TransferCharacteristics::TC_UNSPECIFIED) {
+    if (aAv1TransferCharacteristics !=
+        CICP::TransferCharacteristics::TC_UNSPECIFIED) {
+      tc = aAv1TransferCharacteristics;
+      MOZ_LOG(sAVIFLog, LogLevel::Info,
+              ("Unspecified transfer_characteristics value specified in "
+               "colr box, using AV1 sequence header (%hhu)",
+               tc));
+    } else {
+      tc = CICP::TransferCharacteristics::TC_SRGB;
+      MOZ_LOG(sAVIFLog, LogLevel::Warning,
+              ("Unspecified transfer_characteristics value specified in "
+               "colr box or AV1 sequence header, using fallback value (%hhu)",
+               tc));
+    }
+  } else if (tc != aAv1TransferCharacteristics) {
+    MOZ_LOG(sAVIFLog, LogLevel::Warning,
+            ("transfer_characteristics mismatch: colr box = %hhu, "
+             "AV1 sequence header = %hhu, using colr box",
+             tc, aAv1TransferCharacteristics));
+  }
 
-  // CICP values (either from the BMFF container or the AV1 sequence header) are
-  // used to create the colorspace transform. CICP::MatrixCoefficients is only
-  // stored for the sake of telemetry, since the relevant information for YUV ->
-  // RGB conversion is stored in mYUVColorSpace.
-  //
-  // There are three potential sources of color information for an AVIF:
-  // 1. ICC profile via a ColourInformationBox (colr) defined in [ISOBMFF]
-  //    § 12.1.5 "Colour information" and [MIAF] § 7.3.6.4 "Colour information
-  //    property"
-  // 2. NCLX (AKA CICP see [ITU-T H.273]) values in the same
-  // ColourInformationBox
-  //    which can have an ICC profile or NCLX values, not both).
-  // 3. NCLX values in the AV1 bitstream
-  //
-  // The 'colr' box is optional, but there are always CICP values in the AV1
-  // bitstream, so it is possible to have both. Per ISOBMFF § 12.1.5.1
-  // > If colour information is supplied in both this box, and also in the
-  // > video bitstream, this box takes precedence, and over-rides the
-  // > information in the bitstream.
-  //
-  // If present, the ICC profile takes precedence over CICP values, but only
-  // specifies the color space, not the matrix coefficients necessary to convert
-  // YCbCr data (as most AVIF are encoded) to RGB. The matrix coefficients are
-  // always derived from the CICP values for matrix_coefficients (and
-  // potentially colour_primaries, but in that case only the CICP values for
-  // colour_primaries will be used, not anything harvested from the ICC
-  // profile).
-  //
-  // If there is no ICC profile, the color space transform will be based on the
-  // CICP values either from the 'colr' box, or if absent/unspecified, the
-  // decoded AV1 sequence header.
-  //
-  // For values that are 2 (meaning unspecified) after trying both, the
-  // fallback values are:
-  // - CP:  1 (BT.709/sRGB)
-  // - TC: 13 (sRGB)
-  // - MC:  6 (BT.601)
-  // - Range: Full
-  //
-  // Additional details here:
-  // <https://github.com/AOMediaCodec/libavif/wiki/CICP#unspecified>. Note
-  // that this contradicts the current version of [MIAF] § 7.3.6.4 which
-  // specifies MC=1 (BT.709). This is revised in [MIAF DAMD2] and confirmed by
-  // <https://github.com/AOMediaCodec/av1-avif/issues/77#issuecomment-676526097>
-  //
-  // The precedence for applying the various values and defaults in the event
-  // no valid values are found are managed by the following functions.
-  //
-  // References:
-  // [ISOBMFF]: ISO/IEC 14496-12:2020 <https://www.iso.org/standard/74428.html>
-  // [MIAF]: ISO/IEC 23000-22:2019 <https://www.iso.org/standard/74417.html>
-  // [MIAF DAMD2]: ISO/IEC 23000-22:2019/FDAmd 2
-  // <https://www.iso.org/standard/81634.html>
-  // [ITU-T H.273]: Rec. ITU-T H.273 (12/2016)
-  //     <https://www.itu.int/rec/T-REC-H.273-201612-I/en>
-  void SetCicpValues(
-      const Mp4parseNclxColourInformation* aNclx,
-      const gfx::CICP::ColourPrimaries aAv1ColourPrimaries,
-      const gfx::CICP::TransferCharacteristics aAv1TransferCharacteristics,
-      const gfx::CICP::MatrixCoefficients aAv1MatrixCoefficients) {
-    auto cp = CICP::ColourPrimaries::CP_UNSPECIFIED;
-    auto tc = CICP::TransferCharacteristics::TC_UNSPECIFIED;
-    auto mc = CICP::MatrixCoefficients::MC_UNSPECIFIED;
+  if (mc == CICP::MatrixCoefficients::MC_UNSPECIFIED) {
+    if (aAv1MatrixCoefficients != CICP::MatrixCoefficients::MC_UNSPECIFIED) {
+      mc = aAv1MatrixCoefficients;
+      MOZ_LOG(sAVIFLog, LogLevel::Info,
+              ("Unspecified matrix_coefficients value specified in "
+               "colr box, using AV1 sequence header (%hhu)",
+               mc));
+    } else {
+      mc = CICP::MatrixCoefficients::MC_BT601;
+      MOZ_LOG(sAVIFLog, LogLevel::Warning,
+              ("Unspecified matrix_coefficients value specified in "
+               "colr box or AV1 sequence header, using fallback value (%hhu)",
+               mc));
+    }
+  } else if (mc != aAv1MatrixCoefficients) {
+    MOZ_LOG(sAVIFLog, LogLevel::Warning,
+            ("matrix_coefficients mismatch: colr box = %hhu, "
+             "AV1 sequence header = %hhu, using colr box",
+             mc, aAv1TransferCharacteristics));
+  }
 
-    if (aNclx) {
-      cp = static_cast<CICP::ColourPrimaries>(aNclx->colour_primaries);
-      tc = static_cast<CICP::TransferCharacteristics>(
-          aNclx->transfer_characteristics);
-      mc = static_cast<CICP::MatrixCoefficients>(aNclx->matrix_coefficients);
-    }
+  mColourPrimaries = cp;
+  mTransferCharacteristics = tc;
+  mMatrixCoefficients = mc;
+}
 
-    if (cp == CICP::ColourPrimaries::CP_UNSPECIFIED) {
-      if (aAv1ColourPrimaries != CICP::ColourPrimaries::CP_UNSPECIFIED) {
-        cp = aAv1ColourPrimaries;
-        MOZ_LOG(sAVIFLog, LogLevel::Info,
-                ("Unspecified colour_primaries value specified in colr box, "
-                 "using AV1 sequence header (%hhu)",
-                 cp));
-      } else {
-        cp = CICP::ColourPrimaries::CP_BT709;
-        MOZ_LOG(sAVIFLog, LogLevel::Warning,
-                ("Unspecified colour_primaries value specified in colr box "
-                 "or AV1 sequence header, using fallback value (%hhu)",
-                 cp));
-      }
-    } else if (cp != aAv1ColourPrimaries) {
-      MOZ_LOG(sAVIFLog, LogLevel::Warning,
-              ("colour_primaries mismatch: colr box = %hhu, AV1 "
-               "sequence header = %hhu, using colr box",
-               cp, aAv1ColourPrimaries));
-    }
+// An interface to do decode and get the decoded data
+class AVIFDecoderInterface {
+ public:
+  using Dav1dResult = nsAVIFDecoder::Dav1dResult;
+  using NonAOMCodecError = nsAVIFDecoder::NonAOMCodecError;
+  using AOMResult = nsAVIFDecoder::AOMResult;
+  using NonDecoderResult = nsAVIFDecoder::NonDecoderResult;
+  using DecodeResult = nsAVIFDecoder::DecodeResult;
+
+  virtual ~AVIFDecoderInterface() = default;
 
-    if (tc == CICP::TransferCharacteristics::TC_UNSPECIFIED) {
-      if (aAv1TransferCharacteristics !=
-          CICP::TransferCharacteristics::TC_UNSPECIFIED) {
-        tc = aAv1TransferCharacteristics;
-        MOZ_LOG(sAVIFLog, LogLevel::Info,
-                ("Unspecified transfer_characteristics value specified in "
-                 "colr box, using AV1 sequence header (%hhu)",
-                 tc));
-      } else {
-        tc = CICP::TransferCharacteristics::TC_SRGB;
-        MOZ_LOG(sAVIFLog, LogLevel::Warning,
-                ("Unspecified transfer_characteristics value specified in "
-                 "colr box or AV1 sequence header, using fallback value (%hhu)",
-                 tc));
-      }
-    } else if (tc != aAv1TransferCharacteristics) {
-      MOZ_LOG(sAVIFLog, LogLevel::Warning,
-              ("transfer_characteristics mismatch: colr box = %hhu, "
-               "AV1 sequence header = %hhu, using colr box",
-               tc, aAv1TransferCharacteristics));
-    }
+  // Set the mDecodedData if Decode() succeeds
+  virtual DecodeResult Decode(bool aIsMetadataDecode,
+                              const Mp4parseAvifImage& parsedImg) = 0;
+  // Must be called after Decode() succeeds
+  AVIFDecodedData& GetDecodedData() {
+    MOZ_ASSERT(mDecodedData.isSome());
+    return mDecodedData.ref();
+  }
 
-    if (mc == CICP::MatrixCoefficients::MC_UNSPECIFIED) {
-      if (aAv1MatrixCoefficients != CICP::MatrixCoefficients::MC_UNSPECIFIED) {
-        mc = aAv1MatrixCoefficients;
-        MOZ_LOG(sAVIFLog, LogLevel::Info,
-                ("Unspecified matrix_coefficients value specified in "
-                 "colr box, using AV1 sequence header (%hhu)",
-                 mc));
-      } else {
-        mc = CICP::MatrixCoefficients::MC_BT601;
-        MOZ_LOG(sAVIFLog, LogLevel::Warning,
-                ("Unspecified matrix_coefficients value specified in "
-                 "colr box or AV1 sequence header, using fallback value (%hhu)",
-                 mc));
-      }
-    } else if (mc != aAv1MatrixCoefficients) {
-      MOZ_LOG(sAVIFLog, LogLevel::Warning,
-              ("matrix_coefficients mismatch: colr box = %hhu, "
-               "AV1 sequence header = %hhu, using colr box",
-               mc, aAv1TransferCharacteristics));
-    }
+ protected:
+  explicit AVIFDecoderInterface(UniquePtr<AVIFParser>&& aParser)
+      : mParser(std::move(aParser)) {
+    MOZ_ASSERT(mParser);
+  }
 
-    mColourPrimaries = cp;
-    mTransferCharacteristics = tc;
-    mMatrixCoefficients = mc;
+  inline static bool IsDecodeSuccess(const DecodeResult& aResult) {
+    return nsAVIFDecoder::IsDecodeSuccess(aResult);
   }
-};
+
+  UniquePtr<AVIFParser> mParser;
 
-AVIFDecoderInterface::~AVIFDecoderInterface() = default;
+  // The mDecodedData is valid after Decode() succeeds
+  Maybe<AVIFDecodedData> mDecodedData;
+};
 
 class Dav1dDecoder final : AVIFDecoderInterface {
  public:
   ~Dav1dDecoder() {
     MOZ_LOG(sAVIFLog, LogLevel::Verbose, ("Destroy Dav1dDecoder=%p", this));
 
-    if (mColorContext) {
-      dav1d_close(&mColorContext);
-      MOZ_ASSERT(!mColorContext);
+    if (mPicture) {
+      dav1d_picture_unref(mPicture.take().ptr());
     }
 
-    if (mAlphaContext) {
-      dav1d_close(&mAlphaContext);
-      MOZ_ASSERT(!mAlphaContext);
+    if (mAlphaPlane) {
+      dav1d_picture_unref(mAlphaPlane.take().ptr());
+    }
+
+    if (mContext) {
+      dav1d_close(&mContext);
+      MOZ_ASSERT(!mContext);
     }
   }
 
-  static DecodeResult Create(UniquePtr<AVIFDecoderInterface>& aDecoder,
-                             bool aHasAlpha) {
-    UniquePtr<Dav1dDecoder> d(new Dav1dDecoder());
-    Dav1dResult r = d->Init(aHasAlpha);
+  static DecodeResult Create(UniquePtr<AVIFParser>&& aParser,
+                             UniquePtr<AVIFDecoderInterface>& aDecoder) {
+    UniquePtr<Dav1dDecoder> d(new Dav1dDecoder(std::move(aParser)));
+    Dav1dResult r = d->Init();
     if (r == 0) {
+      MOZ_ASSERT(d->mContext);
       aDecoder.reset(d.release());
     }
     return AsVariant(r);
   }
 
-  DecodeResult Decode(bool aIsMetadataDecode, const Mp4parseAvifInfo& aAVIFInfo,
-                      const AVIFImage& aSamples) override {
-    MOZ_ASSERT(mColorContext);
-    MOZ_ASSERT(!mDecodedData);
-    MOZ_ASSERT(aSamples.mColorImage);
+  DecodeResult Decode(bool aIsMetadataDecode,
+                      const Mp4parseAvifImage& parsedImg) override {
+    MOZ_ASSERT(mParser);
+    MOZ_ASSERT(mContext);
+    MOZ_ASSERT(mPicture.isNothing());
+    MOZ_ASSERT(mDecodedData.isNothing());
+
+    MOZ_LOG(sAVIFLog, LogLevel::Verbose, ("[this=%p] Beginning Decode", this));
 
-    MOZ_LOG(sAVIFLog, LogLevel::Verbose, ("[this=%p] Decoding color", this));
+    if (!parsedImg.primary_image.coded_data.data ||
+        !parsedImg.primary_image.coded_data.length) {
+      return AsVariant(NonDecoderResult::NoPrimaryItem);
+    }
 
-    OwnedDav1dPicture colorPic = OwnedDav1dPicture(new Dav1dPicture());
-    OwnedDav1dPicture alphaPic = nullptr;
-    Dav1dResult r = GetPicture(*mColorContext, *aSamples.mColorImage,
-                               colorPic.get(), aIsMetadataDecode);
+    mPicture.emplace();
+    Dav1dResult r = GetPicture(parsedImg.primary_image.coded_data,
+                               mPicture.ptr(), aIsMetadataDecode);
     if (r != 0) {
+      mPicture.reset();
       return AsVariant(r);
     }
 
-    if (aSamples.mAlphaImage) {
-      MOZ_ASSERT(mAlphaContext);
-      MOZ_LOG(sAVIFLog, LogLevel::Verbose, ("[this=%p] Decoding alpha", this));
-
-      alphaPic = OwnedDav1dPicture(new Dav1dPicture());
-      Dav1dResult r = GetPicture(*mAlphaContext, *aSamples.mAlphaImage,
-                                 alphaPic.get(), aIsMetadataDecode);
+    if (parsedImg.alpha_image.coded_data.data &&
+        parsedImg.alpha_image.coded_data.length) {
+      mAlphaPlane.emplace();
+      Dav1dResult r = GetPicture(parsedImg.alpha_image.coded_data,
+                                 mAlphaPlane.ptr(), aIsMetadataDecode);
       if (r != 0) {
+        mAlphaPlane.reset();
         return AsVariant(r);
       }
 
@@ -640,27 +567,27 @@
       // https://aomediacodec.github.io/av1-avif/#auxiliary-images: An AV1
       // Alpha Image Item […] shall be encoded with the same bit depth as the
       // associated master AV1 Image Item
-      if (colorPic->p.bpc != alphaPic->p.bpc) {
+      if (mPicture->p.bpc != mAlphaPlane->p.bpc) {
         return AsVariant(NonDecoderResult::AlphaYColorDepthMismatch);
       }
     }
 
-    MOZ_ASSERT_IF(!alphaPic, !aAVIFInfo.premultiplied_alpha);
-    mDecodedData = Dav1dPictureToDecodedData(
-        aAVIFInfo.nclx_colour_information, std::move(colorPic),
-        std::move(alphaPic), aAVIFInfo.premultiplied_alpha);
+    MOZ_ASSERT_IF(mAlphaPlane.isNothing(), !parsedImg.premultiplied_alpha);
+    mDecodedData.emplace(Dav1dPictureToDecodedData(
+        parsedImg.nclx_colour_information, mPicture.ptr(),
+        mAlphaPlane.ptrOr(nullptr), parsedImg.premultiplied_alpha));
 
     return AsVariant(r);
   }
 
  private:
-  explicit Dav1dDecoder() {
+  explicit Dav1dDecoder(UniquePtr<AVIFParser>&& aParser)
+      : AVIFDecoderInterface(std::move(aParser)) {
     MOZ_LOG(sAVIFLog, LogLevel::Verbose, ("Create Dav1dDecoder=%p", this));
   }
 
-  Dav1dResult Init(bool aHasAlpha) {
-    MOZ_ASSERT(!mColorContext);
-    MOZ_ASSERT(!mAlphaContext);
+  Dav1dResult Init() {
+    MOZ_ASSERT(!mContext);
 
     Dav1dSettings settings;
     dav1d_default_settings(&settings);
@@ -668,54 +595,39 @@
     settings.max_frame_delay = 1;
     // TODO: tune settings a la DAV1DDecoder for AV1 (Bug 1681816)
 
-    Dav1dResult r = dav1d_open(&mColorContext, &settings);
-    if (r != 0) {
-      return r;
-    }
-    MOZ_ASSERT(mColorContext);
-
-    if (aHasAlpha) {
-      r = dav1d_open(&mAlphaContext, &settings);
-      if (r != 0) {
-        return r;
-      }
-      MOZ_ASSERT(mAlphaContext);
-    }
-
-    return 0;
+    return dav1d_open(&mContext, &settings);
   }
 
-  static Dav1dResult GetPicture(Dav1dContext& aContext,
-                                const MediaRawData& aBytes,
-                                Dav1dPicture* aPicture,
-                                bool aIsMetadataDecode) {
+  Dav1dResult GetPicture(const Mp4parseByteData& aBytes, Dav1dPicture* aPicture,
+                         bool aIsMetadataDecode) {
+    MOZ_ASSERT(mContext);
     MOZ_ASSERT(aPicture);
 
     Dav1dData dav1dData;
-    Dav1dResult r = dav1d_data_wrap(&dav1dData, aBytes.Data(), aBytes.Size(),
+    Dav1dResult r = dav1d_data_wrap(&dav1dData, aBytes.data, aBytes.length,
                                     Dav1dFreeCallback_s, nullptr);
 
-    MOZ_LOG(
-        sAVIFLog, r == 0 ? LogLevel::Verbose : LogLevel::Error,
-        ("dav1d_data_wrap(%p, %zu) -> %d", dav1dData.data, dav1dData.sz, r));
+    MOZ_LOG(sAVIFLog, r == 0 ? LogLevel::Verbose : LogLevel::Error,
+            ("[this=%p] dav1d_data_wrap(%p, %zu) -> %d", this, dav1dData.data,
+             dav1dData.sz, r));
 
     if (r != 0) {
       return r;
     }
 
-    r = dav1d_send_data(&aContext, &dav1dData);
+    r = dav1d_send_data(mContext, &dav1dData);
 
     MOZ_LOG(sAVIFLog, r == 0 ? LogLevel::Debug : LogLevel::Error,
-            ("dav1d_send_data -> %d", r));
+            ("[this=%p] dav1d_send_data -> %d", this, r));
 
     if (r != 0) {
       return r;
     }
 
-    r = dav1d_get_picture(&aContext, aPicture);
+    r = dav1d_get_picture(mContext, aPicture);
 
     MOZ_LOG(sAVIFLog, r == 0 ? LogLevel::Debug : LogLevel::Error,
-            ("dav1d_get_picture -> %d", r));
+            ("[this=%p] dav1d_get_picture -> %d", this, r));
 
     // When bug 1682662 is fixed, revise this assert and subsequent condition
     MOZ_ASSERT(aIsMetadataDecode || r == 0);
@@ -743,123 +655,54 @@
     // nothing here.
   }
 
-  static UniquePtr<AVIFDecodedData> Dav1dPictureToDecodedData(
-      const Mp4parseNclxColourInformation* aNclx, OwnedDav1dPicture aPicture,
-      OwnedDav1dPicture aAlphaPlane, bool aPremultipliedAlpha);
-
-  Dav1dContext* mColorContext = nullptr;
-  Dav1dContext* mAlphaContext = nullptr;
-};
-
-OwnedAOMImage::OwnedAOMImage() {
-  MOZ_LOG(sAVIFLog, LogLevel::Verbose, ("Create OwnedAOMImage=%p", this));
-}
-
-OwnedAOMImage::~OwnedAOMImage() {
-  MOZ_LOG(sAVIFLog, LogLevel::Verbose, ("Destroy OwnedAOMImage=%p", this));
-}
+  static AVIFDecodedData Dav1dPictureToDecodedData(
+      const Mp4parseNclxColourInformation* aNclx, Dav1dPicture* aPicture,
+      Dav1dPicture* aAlphaPlane, bool aPremultipliedAlpha);
 
-bool OwnedAOMImage::CloneFrom(aom_image_t* aImage, bool aIsAlpha) {
-  MOZ_ASSERT(aImage);
-  MOZ_ASSERT(!mImage);
-  MOZ_ASSERT(!mBuffer);
-
-  uint8_t* srcY = aImage->planes[AOM_PLANE_Y];
-  int yStride = aImage->stride[AOM_PLANE_Y];
-  int yHeight = aom_img_plane_height(aImage, AOM_PLANE_Y);
-  size_t yBufSize = yStride * yHeight;
-
-  // If aImage is alpha plane. The data is located in Y channel.
-  if (aIsAlpha) {
-    mBuffer = MakeUnique<uint8_t[]>(yBufSize);
-    if (!mBuffer) {
-      return false;
-    }
-    uint8_t* destY = mBuffer.get();
-    memcpy(destY, srcY, yBufSize);
-    mImage.emplace(*aImage);
-    mImage->planes[AOM_PLANE_Y] = destY;
-
-    return true;
-  }
+  Dav1dContext* mContext = nullptr;
 
-  uint8_t* srcCb = aImage->planes[AOM_PLANE_U];
-  int cbStride = aImage->stride[AOM_PLANE_U];
-  int cbHeight = aom_img_plane_height(aImage, AOM_PLANE_U);
-  size_t cbBufSize = cbStride * cbHeight;
-
-  uint8_t* srcCr = aImage->planes[AOM_PLANE_V];
-  int crStride = aImage->stride[AOM_PLANE_V];
-  int crHeight = aom_img_plane_height(aImage, AOM_PLANE_V);
-  size_t crBufSize = crStride * crHeight;
-
-  mBuffer = MakeUnique<uint8_t[]>(yBufSize + cbBufSize + crBufSize);
-  if (!mBuffer) {
-    return false;
-  }
-
-  uint8_t* destY = mBuffer.get();
-  uint8_t* destCb = destY + yBufSize;
-  uint8_t* destCr = destCb + cbBufSize;
-
-  memcpy(destY, srcY, yBufSize);
-  memcpy(destCb, srcCb, cbBufSize);
-  memcpy(destCr, srcCr, crBufSize);
-
-  mImage.emplace(*aImage);
-  mImage->planes[AOM_PLANE_Y] = destY;
-  mImage->planes[AOM_PLANE_U] = destCb;
-  mImage->planes[AOM_PLANE_V] = destCr;
-
-  return true;
-}
-
-/* static */
-OwnedAOMImage* OwnedAOMImage::CopyFrom(aom_image_t* aImage, bool aIsAlpha) {
-  MOZ_ASSERT(aImage);
-  UniquePtr<OwnedAOMImage> img(new OwnedAOMImage());
-  if (!img->CloneFrom(aImage, aIsAlpha)) {
-    return nullptr;
-  }
-  return img.release();
-}
+  // The pictures are allocated once Decode() succeeds and will be deallocated
+  // when Dav1dDecoder is destroyed
+  Maybe<Dav1dPicture> mPicture;
+  Maybe<Dav1dPicture> mAlphaPlane;
+};
 
 class AOMDecoder final : AVIFDecoderInterface {
  public:
   ~AOMDecoder() {
     MOZ_LOG(sAVIFLog, LogLevel::Verbose, ("Destroy AOMDecoder=%p", this));
 
-    if (mColorContext.isSome()) {
-      aom_codec_err_t r = aom_codec_destroy(mColorContext.ptr());
-      MOZ_LOG(sAVIFLog, LogLevel::Debug,
-              ("[this=%p] aom_codec_destroy -> %d", this, r));
-    }
-
-    if (mAlphaContext.isSome()) {
-      aom_codec_err_t r = aom_codec_destroy(mAlphaContext.ptr());
+    if (mContext.isSome()) {
+      aom_codec_err_t r = aom_codec_destroy(mContext.ptr());
       MOZ_LOG(sAVIFLog, LogLevel::Debug,
               ("[this=%p] aom_codec_destroy -> %d", this, r));
     }
   }
 
-  static DecodeResult Create(UniquePtr<AVIFDecoderInterface>& aDecoder,
-                             bool aHasAlpha) {
-    UniquePtr<AOMDecoder> d(new AOMDecoder());
-    aom_codec_err_t e = d->Init(aHasAlpha);
+  static DecodeResult Create(UniquePtr<AVIFParser>&& aParser,
+                             UniquePtr<AVIFDecoderInterface>& aDecoder) {
+    UniquePtr<AOMDecoder> d(new AOMDecoder(std::move(aParser)));
+    aom_codec_err_t e = d->Init();
     if (e == AOM_CODEC_OK) {
+      MOZ_ASSERT(d->mContext);
       aDecoder.reset(d.release());
     }
     return AsVariant(AOMResult(e));
   }
 
-  DecodeResult Decode(bool aIsMetadataDecode, const Mp4parseAvifInfo& aAVIFInfo,
-                      const AVIFImage& aSamples) override {
-    MOZ_ASSERT(mColorContext.isSome());
-    MOZ_ASSERT(!mDecodedData);
-    MOZ_ASSERT(aSamples.mColorImage);
+  DecodeResult Decode(bool aIsMetadataDecode,
+                      const Mp4parseAvifImage& parsedImg) override {
+    MOZ_ASSERT(mParser);
+    MOZ_ASSERT(mContext.isSome());
+    MOZ_ASSERT(mDecodedData.isNothing());
+
+    if (!parsedImg.primary_image.coded_data.data ||
+        !parsedImg.primary_image.coded_data.length) {
+      return AsVariant(NonDecoderResult::NoPrimaryItem);
+    }
 
     aom_image_t* aomImg = nullptr;
-    DecodeResult r = GetImage(*mColorContext, *aSamples.mColorImage, &aomImg,
+    DecodeResult r = GetImage(parsedImg.primary_image.coded_data, &aomImg,
                               aIsMetadataDecode);
     if (!IsDecodeSuccess(r)) {
       return r;
@@ -876,12 +719,11 @@
     }
     mOwnedImage.reset(clonedImg);
 
-    if (aSamples.mAlphaImage) {
-      MOZ_ASSERT(mAlphaContext.isSome());
-
+    if (parsedImg.alpha_image.coded_data.data &&
+        parsedImg.alpha_image.coded_data.length) {
       aom_image_t* alphaImg = nullptr;
-      DecodeResult r = GetImage(*mAlphaContext, *aSamples.mAlphaImage,
-                                &alphaImg, aIsMetadataDecode);
+      DecodeResult r = GetImage(parsedImg.alpha_image.coded_data, &alphaImg,
+                                aIsMetadataDecode);
       if (!IsDecodeSuccess(r)) {
         return r;
       }
@@ -904,65 +746,49 @@
       }
     }
 
-    MOZ_ASSERT_IF(!mOwnedAlphaPlane, !aAVIFInfo.premultiplied_alpha);
-    mDecodedData = AOMImageToToDecodedData(
-        aAVIFInfo.nclx_colour_information, std::move(mOwnedImage),
-        std::move(mOwnedAlphaPlane), aAVIFInfo.premultiplied_alpha);
+    MOZ_ASSERT_IF(!mOwnedAlphaPlane, !parsedImg.premultiplied_alpha);
+    mDecodedData.emplace(AOMImageToToDecodedData(
+        parsedImg.nclx_colour_information, mOwnedImage->GetImage(),
+        mOwnedAlphaPlane ? mOwnedAlphaPlane->GetImage() : nullptr,
+        parsedImg.premultiplied_alpha));
 
     return r;
   }
 
  private:
-  explicit AOMDecoder() {
+  explicit AOMDecoder(UniquePtr<AVIFParser>&& aParser)
+      : AVIFDecoderInterface(std::move(aParser)) {
     MOZ_LOG(sAVIFLog, LogLevel::Verbose, ("Create AOMDecoder=%p", this));
   }
 
-  aom_codec_err_t Init(bool aHasAlpha) {
-    MOZ_ASSERT(mColorContext.isNothing());
-    MOZ_ASSERT(mAlphaContext.isNothing());
+  aom_codec_err_t Init() {
+    MOZ_ASSERT(mContext.isNothing());
 
     aom_codec_iface_t* iface = aom_codec_av1_dx();
-
-    // Init color decoder context
-    mColorContext.emplace();
+    mContext.emplace();
     aom_codec_err_t r = aom_codec_dec_init(
-        mColorContext.ptr(), iface, /* cfg = */ nullptr, /* flags = */ 0);
+        mContext.ptr(), iface, /* cfg = */ nullptr, /* flags = */ 0);
 
     MOZ_LOG(sAVIFLog, r == AOM_CODEC_OK ? LogLevel::Verbose : LogLevel::Error,
-            ("[this=%p] color decoder: aom_codec_dec_init -> %d, name = %s",
-             this, r, mColorContext->name));
+            ("[this=%p] aom_codec_dec_init -> %d, name = %s", this, r,
+             mContext->name));
 
     if (r != AOM_CODEC_OK) {
-      mColorContext.reset();
-      return r;
-    }
-
-    if (aHasAlpha) {
-      // Init alpha decoder context
-      mAlphaContext.emplace();
-      aom_codec_err_t r = aom_codec_dec_init(
-          mAlphaContext.ptr(), iface, /* cfg = */ nullptr, /* flags = */ 0);
-
-      MOZ_LOG(sAVIFLog, r == AOM_CODEC_OK ? LogLevel::Verbose : LogLevel::Error,
-              ("[this=%p] color decoder: aom_codec_dec_init -> %d, name = %s",
-               this, r, mAlphaContext->name));
-
-      if (r != AOM_CODEC_OK) {
-        mAlphaContext.reset();
-      }
+      mContext.reset();
     }
 
     return r;
   }
 
-  static DecodeResult GetImage(aom_codec_ctx_t& aContext,
-                               const MediaRawData& aData, aom_image_t** aImage,
-                               bool aIsMetadataDecode) {
+  DecodeResult GetImage(const Mp4parseByteData& aData, aom_image_t** aImage,
+                        bool aIsMetadataDecode) {
+    MOZ_ASSERT(mContext.isSome());
+
     aom_codec_err_t r =
-        aom_codec_decode(&aContext, aData.Data(), aData.Size(), nullptr);
+        aom_codec_decode(mContext.ptr(), aData.data, aData.length, nullptr);
 
     MOZ_LOG(sAVIFLog, r == AOM_CODEC_OK ? LogLevel::Verbose : LogLevel::Error,
-            ("aom_codec_decode -> %d", r));
+            ("[this=%p] aom_codec_decode -> %d", this, r));
 
     if (aIsMetadataDecode) {
       switch (r) {
@@ -1004,10 +830,10 @@
     }
 
     aom_codec_iter_t iter = nullptr;
-    aom_image_t* img = aom_codec_get_frame(&aContext, &iter);
+    aom_image_t* img = aom_codec_get_frame(mContext.ptr(), &iter);
 
     MOZ_LOG(sAVIFLog, img == nullptr ? LogLevel::Error : LogLevel::Verbose,
-            ("aom_codec_get_frame -> %p", img));
+            ("[this=%p] aom_codec_get_frame -> %p", this, img));
 
     if (img == nullptr) {
       return AsVariant(AOMResult(NonAOMCodecError::NoFrame));
@@ -1018,9 +844,9 @@
 
     if (!decoded_height.isValid() || !decoded_width.isValid()) {
       MOZ_LOG(sAVIFLog, LogLevel::Debug,
-              ("image dimensions can't be stored in int: d_w: %u, "
+              ("[this=%p] image dimensions can't be stored in int: d_w: %u, "
                "d_h: %u",
-               img->d_w, img->d_h));
+               this, img->d_w, img->d_h));
       return AsVariant(AOMResult(NonAOMCodecError::SizeOverflow));
     }
 
@@ -1028,46 +854,123 @@
     return AsVariant(AOMResult(r));
   }
 
-  static UniquePtr<AVIFDecodedData> AOMImageToToDecodedData(
-      const Mp4parseNclxColourInformation* aNclx,
-      UniquePtr<OwnedAOMImage> aImage, UniquePtr<OwnedAOMImage> aAlphaPlane,
-      bool aPremultipliedAlpha);
+  class OwnedAOMImage {
+   public:
+    ~OwnedAOMImage() {
+      MOZ_LOG(sAVIFLog, LogLevel::Verbose, ("Destroy OwnedAOMImage=%p", this));
+    };
+
+    static OwnedAOMImage* CopyFrom(aom_image_t* aImage, bool aIsAlpha) {
+      MOZ_ASSERT(aImage);
+      UniquePtr<OwnedAOMImage> img(new OwnedAOMImage());
+      if (!img->CloneFrom(aImage, aIsAlpha)) {
+        return nullptr;
+      }
+      return img.release();
+    }
+
+    aom_image_t* GetImage() { return mImage.isSome() ? mImage.ptr() : nullptr; }
+
+   private:
+    OwnedAOMImage() {
+      MOZ_LOG(sAVIFLog, LogLevel::Verbose, ("Create OwnedAOMImage=%p", this));
+    };
+
+    bool CloneFrom(aom_image_t* aImage, bool aIsAlpha) {
+      MOZ_ASSERT(aImage);
+      MOZ_ASSERT(!mImage);
+      MOZ_ASSERT(!mBuffer);
+
+      uint8_t* srcY = aImage->planes[AOM_PLANE_Y];
+      int yStride = aImage->stride[AOM_PLANE_Y];
+      int yHeight = aom_img_plane_height(aImage, AOM_PLANE_Y);
+      size_t yBufSize = yStride * yHeight;
+
+      // If aImage is alpha plane. The data is located in Y channel.
+      if (aIsAlpha) {
+        mBuffer = MakeUnique<uint8_t[]>(yBufSize);
+        if (!mBuffer) {
+          return false;
+        }
+        uint8_t* destY = mBuffer.get();
+        memcpy(destY, srcY, yBufSize);
+        mImage.emplace(*aImage);
+        mImage->planes[AOM_PLANE_Y] = destY;
 
-  Maybe<aom_codec_ctx_t> mColorContext;
-  Maybe<aom_codec_ctx_t> mAlphaContext;
+        return true;
+      }
+
+      uint8_t* srcCb = aImage->planes[AOM_PLANE_U];
+      int cbStride = aImage->stride[AOM_PLANE_U];
+      int cbHeight = aom_img_plane_height(aImage, AOM_PLANE_U);
+      size_t cbBufSize = cbStride * cbHeight;
+
+      uint8_t* srcCr = aImage->planes[AOM_PLANE_V];
+      int crStride = aImage->stride[AOM_PLANE_V];
+      int crHeight = aom_img_plane_height(aImage, AOM_PLANE_V);
+      size_t crBufSize = crStride * crHeight;
+
+      mBuffer = MakeUnique<uint8_t[]>(yBufSize + cbBufSize + crBufSize);
+      if (!mBuffer) {
+        return false;
+      }
+
+      uint8_t* destY = mBuffer.get();
+      uint8_t* destCb = destY + yBufSize;
+      uint8_t* destCr = destCb + cbBufSize;
+
+      memcpy(destY, srcY, yBufSize);
+      memcpy(destCb, srcCb, cbBufSize);
+      memcpy(destCr, srcCr, crBufSize);
+
+      mImage.emplace(*aImage);
+      mImage->planes[AOM_PLANE_Y] = destY;
+      mImage->planes[AOM_PLANE_U] = destCb;
+      mImage->planes[AOM_PLANE_V] = destCr;
+
+      return true;
+    }
+
+    // The mImage's planes are referenced to mBuffer
+    Maybe<aom_image_t> mImage;
+    UniquePtr<uint8_t[]> mBuffer;
+  };
+
+  static AVIFDecodedData AOMImageToToDecodedData(
+      const Mp4parseNclxColourInformation* aNclx, aom_image_t* aImage,
+      aom_image_t* aAlphaPlane, bool aPremultipliedAlpha);
+
+  Maybe<aom_codec_ctx_t> mContext;
   UniquePtr<OwnedAOMImage> mOwnedImage;
   UniquePtr<OwnedAOMImage> mOwnedAlphaPlane;
 };
 
 /* static */
-UniquePtr<AVIFDecodedData> Dav1dDecoder::Dav1dPictureToDecodedData(
-    const Mp4parseNclxColourInformation* aNclx, OwnedDav1dPicture aPicture,
-    OwnedDav1dPicture aAlphaPlane, bool aPremultipliedAlpha) {
+AVIFDecodedData Dav1dDecoder::Dav1dPictureToDecodedData(
+    const Mp4parseNclxColourInformation* aNclx, Dav1dPicture* aPicture,
+    Dav1dPicture* aAlphaPlane, bool aPremultipliedAlpha) {
   MOZ_ASSERT(aPicture);
 
   static_assert(std::is_same<int, decltype(aPicture->p.w)>::value);
   static_assert(std::is_same<int, decltype(aPicture->p.h)>::value);
 
-  UniquePtr<AVIFDecodedData> data = MakeUnique<AVIFDecodedData>();
-
-  data->mRenderRect = {0, 0, aPicture->frame_hdr->render_width,
-                       aPicture->frame_hdr->render_height};
+  AVIFDecodedData data;
 
-  data->mYChannel = static_cast<uint8_t*>(aPicture->data[0]);
-  data->mYStride = aPicture->stride[0];
-  data->mYSkip = aPicture->stride[0] - aPicture->p.w;
-  data->mCbChannel = static_cast<uint8_t*>(aPicture->data[1]);
-  data->mCrChannel = static_cast<uint8_t*>(aPicture->data[2]);
-  data->mCbCrStride = aPicture->stride[1];
+  data.mYChannel = static_cast<uint8_t*>(aPicture->data[0]);
+  data.mYStride = aPicture->stride[0];
+  data.mYSkip = aPicture->stride[0] - aPicture->p.w;
+  data.mCbChannel = static_cast<uint8_t*>(aPicture->data[1]);
+  data.mCrChannel = static_cast<uint8_t*>(aPicture->data[2]);
+  data.mCbCrStride = aPicture->stride[1];
 
   switch (aPicture->p.layout) {
     case DAV1D_PIXEL_LAYOUT_I400:  // Monochrome, so no Cb or Cr channels
       break;
     case DAV1D_PIXEL_LAYOUT_I420:
-      data->mChromaSubsampling = ChromaSubsampling::HALF_WIDTH_AND_HEIGHT;
+      data.mChromaSubsampling = ChromaSubsampling::HALF_WIDTH_AND_HEIGHT;
       break;
     case DAV1D_PIXEL_LAYOUT_I422:
-      data->mChromaSubsampling = ChromaSubsampling::HALF_WIDTH;
+      data.mChromaSubsampling = ChromaSubsampling::HALF_WIDTH;
       break;
     case DAV1D_PIXEL_LAYOUT_I444:
       break;
@@ -1075,15 +978,15 @@
       MOZ_ASSERT_UNREACHABLE("Unknown pixel layout");
   }
 
-  data->mCbSkip = aPicture->stride[1] - aPicture->p.w;
-  data->mCrSkip = aPicture->stride[1] - aPicture->p.w;
-  data->mPictureRect = IntRect(0, 0, aPicture->p.w, aPicture->p.h);
-  data->mStereoMode = StereoMode::MONO;
-  data->mColorDepth = ColorDepthForBitDepth(aPicture->p.bpc);
+  data.mCbSkip = aPicture->stride[1] - aPicture->p.w;
+  data.mCrSkip = aPicture->stride[1] - aPicture->p.w;
+  data.mPictureRect = IntRect(0, 0, aPicture->p.w, aPicture->p.h);
+  data.mStereoMode = StereoMode::MONO;
+  data.mColorDepth = ColorDepthForBitDepth(aPicture->p.bpc);
 
-  MOZ_ASSERT(aPicture->p.bpc == BitDepthForColorDepth(data->mColorDepth));
+  MOZ_ASSERT(aPicture->p.bpc == BitDepthForColorDepth(data.mColorDepth));
 
-  data->mYUVColorSpace = GetAVIFColorSpace(aNclx, [&]() {
+  data.mYUVColorSpace = GetAVIFColorSpace(aNclx, [=]() {
     MOZ_LOG(sAVIFLog, LogLevel::Info,
             ("YUVColorSpace cannot be determined from colr box, using AV1 "
              "sequence header"));
@@ -1108,94 +1011,82 @@
     av1MatrixCoefficients = static_cast<CICP::MatrixCoefficients>(seq_hdr.mtrx);
   }
 
-  data->SetCicpValues(aNclx, av1ColourPrimaries, av1TransferCharacteristics,
-                      av1MatrixCoefficients);
+  data.SetCicpValues(aNclx, av1ColourPrimaries, av1TransferCharacteristics,
+                     av1MatrixCoefficients);
 
   gfx::ColorRange av1ColorRange =
       seq_hdr.color_range ? gfx::ColorRange::FULL : gfx::ColorRange::LIMITED;
-  data->mColorRange = GetAVIFColorRange(aNclx, av1ColorRange);
+  data.mColorRange = GetAVIFColorRange(aNclx, av1ColorRange);
 
   auto colorPrimaries =
-      gfxUtils::CicpToColorPrimaries(data->mColourPrimaries, sAVIFLog);
+      gfxUtils::CicpToColorPrimaries(data.mColourPrimaries, sAVIFLog);
   if (colorPrimaries.isSome()) {
-    data->mColorPrimaries = *colorPrimaries;
+    data.mColorPrimaries = *colorPrimaries;
   }
 
   if (aAlphaPlane) {
-    MOZ_ASSERT(aAlphaPlane->stride[0] == data->mYStride);
-    data->mAlpha.emplace();
-    data->mAlpha->mChannel = static_cast<uint8_t*>(aAlphaPlane->data[0]);
-    data->mAlpha->mSize = gfx::IntSize(aAlphaPlane->p.w, aAlphaPlane->p.h);
-    data->mAlpha->mPremultiplied = aPremultipliedAlpha;
+    MOZ_ASSERT(aAlphaPlane->stride[0] == data.mYStride);
+    data.mAlpha.emplace();
+    data.mAlpha->mChannel = static_cast<uint8_t*>(aAlphaPlane->data[0]);
+    data.mAlpha->mSize = gfx::IntSize(aAlphaPlane->p.w, aAlphaPlane->p.h);
+    data.mAlpha->mPremultiplied = aPremultipliedAlpha;
   }
 
-  data->mColorDav1d = std::move(aPicture);
-  data->mAlphaDav1d = std::move(aAlphaPlane);
-
   return data;
 }
 
 /* static */
-UniquePtr<AVIFDecodedData> AOMDecoder::AOMImageToToDecodedData(
-    const Mp4parseNclxColourInformation* aNclx, UniquePtr<OwnedAOMImage> aImage,
-    UniquePtr<OwnedAOMImage> aAlphaPlane, bool aPremultipliedAlpha) {
-  aom_image_t* colorImage = aImage->GetImage();
-  aom_image_t* alphaImage = aAlphaPlane ? aAlphaPlane->GetImage() : nullptr;
+AVIFDecodedData AOMDecoder::AOMImageToToDecodedData(
+    const Mp4parseNclxColourInformation* aNclx, aom_image_t* aImage,
+    aom_image_t* aAlphaPlane, bool aPremultipliedAlpha) {
+  MOZ_ASSERT(aImage);
+  MOZ_ASSERT(aImage->stride[AOM_PLANE_Y] == aImage->stride[AOM_PLANE_ALPHA]);
+  MOZ_ASSERT(aImage->stride[AOM_PLANE_Y] >=
+             aom_img_plane_width(aImage, AOM_PLANE_Y));
+  MOZ_ASSERT(aImage->stride[AOM_PLANE_U] == aImage->stride[AOM_PLANE_V]);
+  MOZ_ASSERT(aImage->stride[AOM_PLANE_U] >=
+             aom_img_plane_width(aImage, AOM_PLANE_U));
+  MOZ_ASSERT(aImage->stride[AOM_PLANE_V] >=
+             aom_img_plane_width(aImage, AOM_PLANE_V));
+  MOZ_ASSERT(aom_img_plane_width(aImage, AOM_PLANE_U) ==
+             aom_img_plane_width(aImage, AOM_PLANE_V));
+  MOZ_ASSERT(aom_img_plane_height(aImage, AOM_PLANE_U) ==
+             aom_img_plane_height(aImage, AOM_PLANE_V));
 
-  MOZ_ASSERT(colorImage);
-  MOZ_ASSERT(colorImage->stride[AOM_PLANE_Y] ==
-             colorImage->stride[AOM_PLANE_ALPHA]);
-  MOZ_ASSERT(colorImage->stride[AOM_PLANE_Y] >=
-             aom_img_plane_width(colorImage, AOM_PLANE_Y));
-  MOZ_ASSERT(colorImage->stride[AOM_PLANE_U] ==
-             colorImage->stride[AOM_PLANE_V]);
-  MOZ_ASSERT(colorImage->stride[AOM_PLANE_U] >=
-             aom_img_plane_width(colorImage, AOM_PLANE_U));
-  MOZ_ASSERT(colorImage->stride[AOM_PLANE_V] >=
-             aom_img_plane_width(colorImage, AOM_PLANE_V));
-  MOZ_ASSERT(aom_img_plane_width(colorImage, AOM_PLANE_U) ==
-             aom_img_plane_width(colorImage, AOM_PLANE_V));
-  MOZ_ASSERT(aom_img_plane_height(colorImage, AOM_PLANE_U) ==
-             aom_img_plane_height(colorImage, AOM_PLANE_V));
-
-  UniquePtr<AVIFDecodedData> data = MakeUnique<AVIFDecodedData>();
+  AVIFDecodedData data;
 
-  data->mRenderRect = {0, 0, colorImage->r_w, colorImage->r_h};
+  data.mYChannel = aImage->planes[AOM_PLANE_Y];
+  data.mYStride = aImage->stride[AOM_PLANE_Y];
+  data.mYSkip =
+      aImage->stride[AOM_PLANE_Y] - aom_img_plane_width(aImage, AOM_PLANE_Y);
+  data.mCbChannel = aImage->planes[AOM_PLANE_U];
+  data.mCrChannel = aImage->planes[AOM_PLANE_V];
+  data.mCbCrStride = aImage->stride[AOM_PLANE_U];
+  data.mCbSkip =
+      aImage->stride[AOM_PLANE_U] - aom_img_plane_width(aImage, AOM_PLANE_U);
+  data.mCrSkip =
+      aImage->stride[AOM_PLANE_V] - aom_img_plane_width(aImage, AOM_PLANE_V);
+  data.mPictureRect = gfx::IntRect(0, 0, aImage->d_w, aImage->d_h);
+  data.mStereoMode = StereoMode::MONO;
+  data.mColorDepth = ColorDepthForBitDepth(aImage->bit_depth);
 
-  data->mYChannel = colorImage->planes[AOM_PLANE_Y];
-  data->mYStride = colorImage->stride[AOM_PLANE_Y];
-  data->mYSkip = colorImage->stride[AOM_PLANE_Y] -
-                 aom_img_plane_width(colorImage, AOM_PLANE_Y);
-  data->mCbChannel = colorImage->planes[AOM_PLANE_U];
-  data->mCrChannel = colorImage->planes[AOM_PLANE_V];
-  data->mCbCrStride = colorImage->stride[AOM_PLANE_U];
-  data->mCbSkip = colorImage->stride[AOM_PLANE_U] -
-                  aom_img_plane_width(colorImage, AOM_PLANE_U);
-  data->mCrSkip = colorImage->stride[AOM_PLANE_V] -
-                  aom_img_plane_width(colorImage, AOM_PLANE_V);
-  data->mPictureRect = gfx::IntRect(0, 0, colorImage->d_w, colorImage->d_h);
-  data->mStereoMode = StereoMode::MONO;
-  data->mColorDepth = ColorDepthForBitDepth(colorImage->bit_depth);
-
-  if (colorImage->x_chroma_shift == 1 && colorImage->y_chroma_shift == 1) {
-    data->mChromaSubsampling = gfx::ChromaSubsampling::HALF_WIDTH_AND_HEIGHT;
-  } else if (colorImage->x_chroma_shift == 1 &&
-             colorImage->y_chroma_shift == 0) {
-    data->mChromaSubsampling = gfx::ChromaSubsampling::HALF_WIDTH;
-  } else if (colorImage->x_chroma_shift != 0 ||
-             colorImage->y_chroma_shift != 0) {
+  if (aImage->x_chroma_shift == 1 && aImage->y_chroma_shift == 1) {
+    data.mChromaSubsampling = gfx::ChromaSubsampling::HALF_WIDTH_AND_HEIGHT;
+  } else if (aImage->x_chroma_shift == 1 && aImage->y_chroma_shift == 0) {
+    data.mChromaSubsampling = gfx::ChromaSubsampling::HALF_WIDTH;
+  } else if (aImage->x_chroma_shift != 0 || aImage->y_chroma_shift != 0) {
     MOZ_ASSERT_UNREACHABLE("unexpected chroma shifts");
   }
 
-  MOZ_ASSERT(colorImage->bit_depth == BitDepthForColorDepth(data->mColorDepth));
+  MOZ_ASSERT(aImage->bit_depth == BitDepthForColorDepth(data.mColorDepth));
 
-  auto av1ColourPrimaries = static_cast<CICP::ColourPrimaries>(colorImage->cp);
+  auto av1ColourPrimaries = static_cast<CICP::ColourPrimaries>(aImage->cp);
   auto av1TransferCharacteristics =
-      static_cast<CICP::TransferCharacteristics>(colorImage->tc);
+      static_cast<CICP::TransferCharacteristics>(aImage->tc);
   auto av1MatrixCoefficients =
-      static_cast<CICP::MatrixCoefficients>(colorImage->mc);
+      static_cast<CICP::MatrixCoefficients>(aImage->mc);
 
-  data->mYUVColorSpace = GetAVIFColorSpace(aNclx, [=]() {
+  data.mYUVColorSpace = GetAVIFColorSpace(aNclx, [=]() {
     MOZ_LOG(sAVIFLog, LogLevel::Info,
             ("YUVColorSpace cannot be determined from colr box, using AV1 "
              "sequence header"));
@@ -1204,34 +1095,31 @@
   });
 
   gfx::ColorRange av1ColorRange;
-  if (colorImage->range == AOM_CR_STUDIO_RANGE) {
+  if (aImage->range == AOM_CR_STUDIO_RANGE) {
     av1ColorRange = gfx::ColorRange::LIMITED;
   } else {
-    MOZ_ASSERT(colorImage->range == AOM_CR_FULL_RANGE);
+    MOZ_ASSERT(aImage->range == AOM_CR_FULL_RANGE);
     av1ColorRange = gfx::ColorRange::FULL;
   }
-  data->mColorRange = GetAVIFColorRange(aNclx, av1ColorRange);
+  data.mColorRange = GetAVIFColorRange(aNclx, av1ColorRange);
 
-  data->SetCicpValues(aNclx, av1ColourPrimaries, av1TransferCharacteristics,
-                      av1MatrixCoefficients);
+  data.SetCicpValues(aNclx, av1ColourPrimaries, av1TransferCharacteristics,
+                     av1MatrixCoefficients);
 
   auto colorPrimaries =
-      gfxUtils::CicpToColorPrimaries(data->mColourPrimaries, sAVIFLog);
+      gfxUtils::CicpToColorPrimaries(data.mColourPrimaries, sAVIFLog);
   if (colorPrimaries.isSome()) {
-    data->mColorPrimaries = *colorPrimaries;
+    data.mColorPrimaries = *colorPrimaries;
   }
 
-  if (alphaImage) {
-    MOZ_ASSERT(alphaImage->stride[AOM_PLANE_Y] == data->mYStride);
-    data->mAlpha.emplace();
-    data->mAlpha->mChannel = alphaImage->planes[AOM_PLANE_Y];
-    data->mAlpha->mSize = gfx::IntSize(alphaImage->d_w, alphaImage->d_h);
-    data->mAlpha->mPremultiplied = aPremultipliedAlpha;
+  if (aAlphaPlane) {
+    MOZ_ASSERT(aAlphaPlane->stride[AOM_PLANE_Y] == data.mYStride);
+    data.mAlpha.emplace();
+    data.mAlpha->mChannel = aAlphaPlane->planes[AOM_PLANE_Y];
+    data.mAlpha->mSize = gfx::IntSize(aAlphaPlane->d_w, aAlphaPlane->d_h);
+    data.mAlpha->mPremultiplied = aPremultipliedAlpha;
   }
 
-  data->mColorAOM = std::move(aImage);
-  data->mAlphaAOM = std::move(aAlphaPlane);
-
   return data;
 }
 
@@ -1285,10 +1173,7 @@
     if (r == NonDecoderResult::NeedMoreData) {
       return LexerResult(Yield::NEED_MORE_DATA);
     }
-    if (r == NonDecoderResult::OutputAvailable) {
-      return LexerResult(Yield::OUTPUT_AVAILABLE);
-    }
-    return r == NonDecoderResult::Complete
+    return r == NonDecoderResult::MetadataOk
                ? LexerResult(TerminalState::SUCCESS)
                : LexerResult(TerminalState::FAILURE);
   }
@@ -1306,158 +1191,6 @@
   return rv;
 }
 
-Mp4parseStatus nsAVIFDecoder::CreateParser() {
-  if (!mParser) {
-    Mp4parseIo io = {nsAVIFDecoder::ReadSource, this};
-    mBufferStream = MakeUnique<AVIFDecoderStream>(&mBufferedData);
-    Mp4parseStatus status =
-        AVIFParser::Create(&io, mBufferStream.get(), mParser);
-
-    if (status != MP4PARSE_STATUS_OK) {
-      return status;
-    }
-
-    const Mp4parseAvifInfo& info = mParser->GetInfo();
-    mIsAnimated = mParser->IsAnimated();
-    mHasAlpha = mIsAnimated ? !!info.alpha_track_id : info.has_alpha_item;
-  }
-
-  return MP4PARSE_STATUS_OK;
-}
-
-nsAVIFDecoder::DecodeResult nsAVIFDecoder::CreateDecoder() {
-  if (!mDecoder) {
-    DecodeResult r = StaticPrefs::image_avif_use_dav1d()
-                         ? Dav1dDecoder::Create(mDecoder, mHasAlpha)
-                         : AOMDecoder::Create(mDecoder, mHasAlpha);
-
-    MOZ_LOG(sAVIFLog, LogLevel::Debug,
-            ("[this=%p] Create %sDecoder %ssuccessfully", this,
-             StaticPrefs::image_avif_use_dav1d() ? "Dav1d" : "AOM",
-             IsDecodeSuccess(r) ? "" : "un"));
-
-    if (!IsDecodeSuccess(r)) {
-      return r;
-    }
-  }
-
-  return DecodeResult(NonDecoderResult::Complete);
-}
-
-// Records all telemetry available in the AVIF metadata, called only once during
-// the metadata decode to avoid multiple counts.
-static void RecordMetadataTelem(const Mp4parseAvifInfo& aInfo) {
-  if (aInfo.pixel_aspect_ratio) {
-    const uint32_t& h_spacing = aInfo.pixel_aspect_ratio->h_spacing;
-    const uint32_t& v_spacing = aInfo.pixel_aspect_ratio->v_spacing;
-
-    if (h_spacing == 0 || v_spacing == 0) {
-      AccumulateCategorical(LABELS_AVIF_PASP::invalid);
-    } else if (h_spacing == v_spacing) {
-      AccumulateCategorical(LABELS_AVIF_PASP::square);
-    } else {
-      AccumulateCategorical(LABELS_AVIF_PASP::nonsquare);
-    }
-  } else {
-    AccumulateCategorical(LABELS_AVIF_PASP::absent);
-  }
-
-  const auto& major_brand = aInfo.major_brand;
-  if (!memcmp(major_brand, "avif", sizeof(major_brand))) {
-    AccumulateCategorical(LABELS_AVIF_MAJOR_BRAND::avif);
-  } else if (!memcmp(major_brand, "avis", sizeof(major_brand))) {
-    AccumulateCategorical(LABELS_AVIF_MAJOR_BRAND::avis);
-  } else {
-    AccumulateCategorical(LABELS_AVIF_MAJOR_BRAND::other);
-  }
-
-  AccumulateCategorical(aInfo.has_sequence ? LABELS_AVIF_SEQUENCE::present
-                                           : LABELS_AVIF_SEQUENCE::absent);
-
-#define FEATURE_TELEMETRY(fourcc)                                              \
-  AccumulateCategorical(                                                       \
-      (aInfo.unsupported_features_bitfield & (1 << MP4PARSE_FEATURE_##fourcc)) \
-          ? LABELS_AVIF_##fourcc::present                                      \
-          : LABELS_AVIF_##fourcc::absent)
-  FEATURE_TELEMETRY(A1LX);
-  FEATURE_TELEMETRY(A1OP);
-  FEATURE_TELEMETRY(CLAP);
-  FEATURE_TELEMETRY(GRID);
-  FEATURE_TELEMETRY(IPRO);
-  FEATURE_TELEMETRY(LSEL);
-
-  if (aInfo.nclx_colour_information && aInfo.icc_colour_information.data) {
-    AccumulateCategorical(LABELS_AVIF_COLR::both);
-  } else if (aInfo.nclx_colour_information) {
-    AccumulateCategorical(LABELS_AVIF_COLR::nclx);
-  } else if (aInfo.icc_colour_information.data) {
-    AccumulateCategorical(LABELS_AVIF_COLR::icc);
-  } else {
-    AccumulateCategorical(LABELS_AVIF_COLR::absent);
-  }
-}
-
-static void RecordPixiTelemetry(uint8_t aPixiBitDepth,
-                                uint8_t aBitstreamBitDepth,
-                                const char* aItemName) {
-  if (aPixiBitDepth == 0) {
-    AccumulateCategorical(LABELS_AVIF_PIXI::absent);
-  } else if (aPixiBitDepth == aBitstreamBitDepth) {
-    AccumulateCategorical(LABELS_AVIF_PIXI::valid);
-  } else {
-    MOZ_LOG(sAVIFLog, LogLevel::Error,
-            ("%s item pixi bit depth (%hhu) doesn't match "
-             "bitstream (%hhu)",
-             aItemName, aPixiBitDepth, aBitstreamBitDepth));
-    AccumulateCategorical(LABELS_AVIF_PIXI::bitstream_mismatch);
-  }
-}
-
-// This telemetry depends on the results of decoding.
-// These data must be recorded only on the first frame decoded after metadata
-// decode finishes.
-static void RecordFrameTelem(bool aAnimated, const Mp4parseAvifInfo& aInfo,
-                             const AVIFDecodedData& aData) {
-  AccumulateCategorical(
-      gColorSpaceLabel[static_cast<size_t>(aData.mYUVColorSpace)]);
-  AccumulateCategorical(
-      gColorDepthLabel[static_cast<size_t>(aData.mColorDepth)]);
-
-  RecordPixiTelemetry(
-      aAnimated ? aInfo.color_track_bit_depth : aInfo.primary_item_bit_depth,
-      BitDepthForColorDepth(aData.mColorDepth), "color");
-
-  if (aData.mAlpha) {
-    AccumulateCategorical(LABELS_AVIF_ALPHA::present);
-    RecordPixiTelemetry(
-        aAnimated ? aInfo.alpha_track_bit_depth : aInfo.alpha_item_bit_depth,
-        BitDepthForColorDepth(aData.mColorDepth), "alpha");
-  } else {
-    AccumulateCategorical(LABELS_AVIF_ALPHA::absent);
-  }
-
-  if (CICP::IsReserved(aData.mColourPrimaries)) {
-    AccumulateCategorical(LABELS_AVIF_CICP_CP::RESERVED_REST);
-  } else {
-    AccumulateCategorical(
-        static_cast<LABELS_AVIF_CICP_CP>(aData.mColourPrimaries));
-  }
-
-  if (CICP::IsReserved(aData.mTransferCharacteristics)) {
-    AccumulateCategorical(LABELS_AVIF_CICP_TC::RESERVED);
-  } else {
-    AccumulateCategorical(
-        static_cast<LABELS_AVIF_CICP_TC>(aData.mTransferCharacteristics));
-  }
-
-  if (CICP::IsReserved(aData.mMatrixCoefficients)) {
-    AccumulateCategorical(LABELS_AVIF_CICP_MC::RESERVED);
-  } else {
-    AccumulateCategorical(
-        static_cast<LABELS_AVIF_CICP_MC>(aData.mMatrixCoefficients));
-  }
-}
-
 nsAVIFDecoder::DecodeResult nsAVIFDecoder::Decode(
     SourceBufferIterator& aIterator, IResumable* aOnResume) {
   MOZ_LOG(sAVIFLog, LogLevel::Debug,
@@ -1505,27 +1238,74 @@
     }
   }
 
-  Mp4parseStatus parserStatus = CreateParser();
+  Mp4parseIo io = {nsAVIFDecoder::ReadSource, this};
+  UniquePtr<AVIFParser> parser;
+  Mp4parseStatus create_parser_status = AVIFParser::Create(&io, parser);
 
-  if (parserStatus != MP4PARSE_STATUS_OK) {
-    return AsVariant(parserStatus);
+  if (!parser) {
+    return AsVariant(create_parser_status);
   }
 
-  const Mp4parseAvifInfo& parsedInfo = mParser->GetInfo();
+  const Mp4parseAvifImage* parsedImagePtr = parser->GetImage();
+  if (!parsedImagePtr) {
+    return AsVariant(NonDecoderResult::NoPrimaryItem);
+  }
+  const Mp4parseAvifImage& parsedImg = *parsedImagePtr;
 
-  if (parsedInfo.icc_colour_information.data) {
-    const auto& icc = parsedInfo.icc_colour_information;
+  if (parsedImg.icc_colour_information.data) {
+    const auto& icc = parsedImg.icc_colour_information;
     MOZ_LOG(
         sAVIFLog, LogLevel::Debug,
         ("[this=%p] colr type ICC: %zu bytes %p", this, icc.length, icc.data));
   }
 
   if (IsMetadataDecode()) {
-    RecordMetadataTelem(parsedInfo);
+    // Only record metadata telemetry on the metadata decode call, or else it
+    // would be double-counted
+
+    if (parsedImg.pixel_aspect_ratio) {
+      const uint32_t& h_spacing = parsedImg.pixel_aspect_ratio->h_spacing;
+      const uint32_t& v_spacing = parsedImg.pixel_aspect_ratio->v_spacing;
+
+      if (h_spacing == 0 || v_spacing == 0) {
+        AccumulateCategorical(LABELS_AVIF_PASP::invalid);
+      } else if (h_spacing == v_spacing) {
+        AccumulateCategorical(LABELS_AVIF_PASP::square);
+      } else {
+        AccumulateCategorical(LABELS_AVIF_PASP::nonsquare);
+      }
+    } else {
+      AccumulateCategorical(LABELS_AVIF_PASP::absent);
+    }
+
+    const auto& major_brand = parsedImg.major_brand;
+    if (!memcmp(major_brand, "avif", sizeof(major_brand))) {
+      AccumulateCategorical(LABELS_AVIF_MAJOR_BRAND::avif);
+    } else if (!memcmp(major_brand, "avis", sizeof(major_brand))) {
+      AccumulateCategorical(LABELS_AVIF_MAJOR_BRAND::avis);
+    } else {
+      AccumulateCategorical(LABELS_AVIF_MAJOR_BRAND::other);
+    }
+
+    AccumulateCategorical(parsedImg.has_sequence
+                              ? LABELS_AVIF_SEQUENCE::present
+                              : LABELS_AVIF_SEQUENCE::absent);
+
+#define FEATURE_TELEMETRY(fourcc)                                  \
+  AccumulateCategorical((parsedImg.unsupported_features_bitfield & \
+                         (1 << MP4PARSE_FEATURE_##fourcc))         \
+                            ? LABELS_AVIF_##fourcc::present        \
+                            : LABELS_AVIF_##fourcc::absent)
+    FEATURE_TELEMETRY(A1LX);
+    FEATURE_TELEMETRY(A1OP);
+    FEATURE_TELEMETRY(CLAP);
+    FEATURE_TELEMETRY(GRID);
+    FEATURE_TELEMETRY(IPRO);
+    FEATURE_TELEMETRY(LSEL);
   }
 
-  if (parsedInfo.nclx_colour_information) {
-    const auto& nclx = *parsedInfo.nclx_colour_information;
+  if (parsedImg.nclx_colour_information) {
+    const auto& nclx = *parsedImg.nclx_colour_information;
     MOZ_LOG(
         sAVIFLog, LogLevel::Debug,
         ("[this=%p] colr type CICP: cp/tc/mc/full-range %u/%u/%u/%s", this,
@@ -1533,60 +1313,58 @@
          nclx.matrix_coefficients, nclx.full_range_flag ? "true" : "false"));
   }
 
-  if (!parsedInfo.icc_colour_information.data &&
-      !parsedInfo.nclx_colour_information) {
+  if (!parsedImg.icc_colour_information.data &&
+      !parsedImg.nclx_colour_information) {
     MOZ_LOG(sAVIFLog, LogLevel::Debug,
             ("[this=%p] colr box not present", this));
   }
 
-  AVIFImage parsedImage;
-  DecodeResult r = mParser->GetImage(parsedImage);
-  if (!IsDecodeSuccess(r)) {
-    return r;
-  }
-  bool isDone =
-      !IsMetadataDecode() && r == DecodeResult(NonDecoderResult::Complete);
-
-  if (mIsAnimated) {
-    PostIsAnimated(parsedImage.mDuration);
-  }
-  if (mHasAlpha) {
+  if (parsedImg.alpha_image.coded_data.data) {
     PostHasTransparency();
   }
 
   Orientation orientation = StaticPrefs::image_avif_apply_transforms()
-                                ? GetImageOrientation(parsedInfo)
+                                ? GetImageOrientation(parsedImg)
                                 : Orientation{};
-  // TODO: Orientation should probably also apply to animated AVIFs.
-  if (mIsAnimated) {
-    orientation = Orientation{};
-  }
-
-  MaybeIntSize parsedImageSize = GetImageSize(parsedInfo);
+  MaybeIntSize parsedImageSize = GetImageSize(parsedImg);
+  Maybe<uint8_t> primaryBitDepth =
+      BitsPerChannelToBitDepth(parsedImg.primary_image.bits_per_channel);
+  Maybe<uint8_t> alphaBitDepth =
+      BitsPerChannelToBitDepth(parsedImg.alpha_image.bits_per_channel);
 
   if (parsedImageSize.isSome()) {
     MOZ_LOG(sAVIFLog, LogLevel::Debug,
             ("[this=%p] Parser returned image size %d x %d (%d/%d bit)", this,
              parsedImageSize->width, parsedImageSize->height,
-             mIsAnimated ? parsedInfo.color_track_bit_depth
-                         : parsedInfo.primary_item_bit_depth,
-             mIsAnimated ? parsedInfo.alpha_track_bit_depth
-                         : parsedInfo.alpha_item_bit_depth));
+             primaryBitDepth.valueOr(0), alphaBitDepth.valueOr(0)));
     PostSize(parsedImageSize->width, parsedImageSize->height, orientation);
     if (IsMetadataDecode()) {
       MOZ_LOG(
           sAVIFLog, LogLevel::Debug,
           ("[this=%p] Finishing metadata decode without image decode", this));
-      return AsVariant(NonDecoderResult::Complete);
+      return AsVariant(NonDecoderResult::MetadataOk);
     }
   } else {
     MOZ_LOG(sAVIFLog, LogLevel::Error,
             ("[this=%p] Parser returned no image size, decoding...", this));
   }
 
-  CreateDecoder();
-  MOZ_ASSERT(mDecoder);
-  r = mDecoder->Decode(IsMetadataDecode(), parsedInfo, parsedImage);
+  UniquePtr<AVIFDecoderInterface> decoder;
+  DecodeResult r = StaticPrefs::image_avif_use_dav1d()
+                       ? Dav1dDecoder::Create(std::move(parser), decoder)
+                       : AOMDecoder::Create(std::move(parser), decoder);
+
+  MOZ_LOG(sAVIFLog, LogLevel::Debug,
+          ("[this=%p] Create %sDecoder %ssuccessfully", this,
+           StaticPrefs::image_avif_use_dav1d() ? "Dav1d" : "AOM",
+           IsDecodeSuccess(r) ? "" : "un"));
+
+  if (!IsDecodeSuccess(r)) {
+    return r;
+  }
+
+  MOZ_ASSERT(decoder);
+  r = decoder->Decode(IsMetadataDecode(), parsedImg);
   MOZ_LOG(sAVIFLog, LogLevel::Debug,
           ("[this=%p] Decoder%s->Decode() %s", this,
            StaticPrefs::image_avif_use_dav1d() ? "Dav1d" : "AOM",
@@ -1596,60 +1374,111 @@
     return r;
   }
 
-  UniquePtr<AVIFDecodedData> decodedData = mDecoder->GetDecodedData();
-
-  MOZ_ASSERT_IF(mHasAlpha, decodedData->mAlpha.isSome());
+  AVIFDecodedData& decodedData = decoder->GetDecodedData();
 
-  MOZ_ASSERT(decodedData->mColourPrimaries !=
+  MOZ_ASSERT(decodedData.mColourPrimaries !=
              CICP::ColourPrimaries::CP_UNSPECIFIED);
-  MOZ_ASSERT(decodedData->mTransferCharacteristics !=
+  MOZ_ASSERT(decodedData.mTransferCharacteristics !=
              CICP::TransferCharacteristics::TC_UNSPECIFIED);
-  MOZ_ASSERT(decodedData->mColorRange <= gfx::ColorRange::_Last);
-  MOZ_ASSERT(decodedData->mYUVColorSpace <= gfx::YUVColorSpace::_Last);
+  MOZ_ASSERT(decodedData.mColorRange <= gfx::ColorRange::_Last);
+  MOZ_ASSERT(decodedData.mYUVColorSpace <= gfx::YUVColorSpace::_Last);
 
   MOZ_LOG(sAVIFLog, LogLevel::Debug,
           ("[this=%p] decodedData.mColorRange: %hhd", this,
-           static_cast<uint8_t>(decodedData->mColorRange)));
+           static_cast<uint8_t>(decodedData.mColorRange)));
 
   // Technically it's valid but we don't handle it now (Bug 1682318).
-  if (decodedData->mAlpha &&
-      decodedData->mAlpha->mSize != decodedData->YDataSize()) {
+  if (decodedData.mAlpha &&
+      decodedData.mAlpha->mSize != decodedData.YDataSize()) {
     return AsVariant(NonDecoderResult::AlphaYSizeMismatch);
   }
 
   if (parsedImageSize.isNothing()) {
-    MOZ_LOG(
-        sAVIFLog, LogLevel::Error,
-        ("[this=%p] Using decoded image size: %d x %d", this,
-         decodedData->mPictureRect.width, decodedData->mPictureRect.height));
-    PostSize(decodedData->mPictureRect.width, decodedData->mPictureRect.height,
+    MOZ_LOG(sAVIFLog, LogLevel::Error,
+            ("[this=%p] Using decoded image size: %d x %d", this,
+             decodedData.mPictureRect.width, decodedData.mPictureRect.height));
+    PostSize(decodedData.mPictureRect.width, decodedData.mPictureRect.height,
              orientation);
     AccumulateCategorical(LABELS_AVIF_ISPE::absent);
-  } else if (decodedData->mPictureRect.width != parsedImageSize->width ||
-             decodedData->mPictureRect.height != parsedImageSize->height) {
-    MOZ_LOG(
-        sAVIFLog, LogLevel::Error,
-        ("[this=%p] Metadata image size doesn't match decoded image size: "
-         "(%d x %d) != (%d x %d)",
-         this, parsedImageSize->width, parsedImageSize->height,
-         decodedData->mPictureRect.width, decodedData->mPictureRect.height));
+  } else if (decodedData.mPictureRect.width != parsedImageSize->width ||
+             decodedData.mPictureRect.height != parsedImageSize->height) {
+    MOZ_LOG(sAVIFLog, LogLevel::Error,
+            ("[this=%p] Metadata image size doesn't match decoded image size: "
+             "(%d x %d) != (%d x %d)",
+             this, parsedImageSize->width, parsedImageSize->height,
+             decodedData.mPictureRect.width, decodedData.mPictureRect.height));
     AccumulateCategorical(LABELS_AVIF_ISPE::bitstream_mismatch);
     return AsVariant(NonDecoderResult::MetadataImageSizeMismatch);
   } else {
     AccumulateCategorical(LABELS_AVIF_ISPE::valid);
   }
 
+  const bool hasAlpha = decodedData.mAlpha.isSome();
+  if (hasAlpha) {
+    PostHasTransparency();
+  }
+
   if (IsMetadataDecode()) {
-    return AsVariant(NonDecoderResult::Complete);
+    return AsVariant(NonDecoderResult::MetadataOk);
   }
 
-  IntSize rgbSize = decodedData->mPictureRect.Size();
+  // The following telemetry may depend on the results of decoding.
+  // These data must be recorded after metadata has been decoded
+  // (IsMetadataDecode()=false) or else they would be double-counted.
+
+  AccumulateCategorical(
+      gColorSpaceLabel[static_cast<size_t>(decodedData.mYUVColorSpace)]);
+  AccumulateCategorical(
+      gColorDepthLabel[static_cast<size_t>(decodedData.mColorDepth)]);
+
+  RecordPixiTelemetry(primaryBitDepth,
+                      BitDepthForColorDepth(decodedData.mColorDepth),
+                      "primary");
+
+  if (decodedData.mAlpha) {
+    AccumulateCategorical(LABELS_AVIF_ALPHA::present);
+    RecordPixiTelemetry(alphaBitDepth,
+                        BitDepthForColorDepth(decodedData.mAlpha->mDepth),
+                        "alpha");
+  } else {
+    AccumulateCategorical(LABELS_AVIF_ALPHA::absent);
+  }
+
+  IntSize rgbSize = decodedData.mPictureRect.Size();
   MOZ_ASSERT(
       rgbSize ==
       GetImageMetadata().GetOrientation().ToUnoriented(Size()).ToUnknownSize());
 
-  if (parsedImage.mFrameNum == 0) {
-    RecordFrameTelem(mIsAnimated, parsedInfo, *decodedData);
+  if (parsedImg.nclx_colour_information &&
+      parsedImg.icc_colour_information.data) {
+    AccumulateCategorical(LABELS_AVIF_COLR::both);
+  } else if (parsedImg.nclx_colour_information) {
+    AccumulateCategorical(LABELS_AVIF_COLR::nclx);
+  } else if (parsedImg.icc_colour_information.data) {
+    AccumulateCategorical(LABELS_AVIF_COLR::icc);
+  } else {
+    AccumulateCategorical(LABELS_AVIF_COLR::absent);
+  }
+
+  if (CICP::IsReserved(decodedData.mColourPrimaries)) {
+    AccumulateCategorical(LABELS_AVIF_CICP_CP::RESERVED_REST);
+  } else {
+    AccumulateCategorical(
+        static_cast<LABELS_AVIF_CICP_CP>(decodedData.mColourPrimaries));
+  }
+
+  if (CICP::IsReserved(decodedData.mTransferCharacteristics)) {
+    AccumulateCategorical(LABELS_AVIF_CICP_TC::RESERVED);
+  } else {
+    AccumulateCategorical(
+        static_cast<LABELS_AVIF_CICP_TC>(decodedData.mTransferCharacteristics));
+  }
+
+  if (CICP::IsReserved(decodedData.mMatrixCoefficients)) {
+    AccumulateCategorical(LABELS_AVIF_CICP_MC::RESERVED);
+  } else {
+    AccumulateCategorical(
+        static_cast<LABELS_AVIF_CICP_MC>(decodedData.mMatrixCoefficients));
   }
 
   // Read color profile
@@ -1658,12 +1487,12 @@
             ("[this=%p] Processing color profile", this));
 
     // See comment on AVIFDecodedData
-    if (parsedInfo.icc_colour_information.data) {
-      const auto& icc = parsedInfo.icc_colour_information;
+    if (parsedImg.icc_colour_information.data) {
+      const auto& icc = parsedImg.icc_colour_information;
       mInProfile = qcms_profile_from_memory(icc.data, icc.length);
     } else {
-      const auto& cp = decodedData->mColourPrimaries;
-      const auto& tc = decodedData->mTransferCharacteristics;
+      const auto& cp = decodedData.mColourPrimaries;
+      const auto& tc = decodedData.mTransferCharacteristics;
 
       if (CICP::IsReserved(cp)) {
         MOZ_LOG(sAVIFLog, LogLevel::Error,
@@ -1712,7 +1541,7 @@
       // have an alpha channel, because the swizzle and premultiplication
       // happens after color management. Otherwise it will be in BGRA because
       // the swizzle happens at the start.
-      if (mHasAlpha) {
+      if (hasAlpha) {
         inType = QCMS_DATA_RGBA_8;
         outType = QCMS_DATA_RGBA_8;
       } else {
@@ -1720,7 +1549,7 @@
         outType = inType;
       }
     } else {
-      if (mHasAlpha) {
+      if (hasAlpha) {
         inType = QCMS_DATA_GRAYA_8;
         outType = gfxPlatform::GetCMSOSRGBAType();
       } else {
@@ -1736,8 +1565,8 @@
   // Get suggested format and size. Note that GetYCbCrToRGBDestFormatAndSize
   // force format to be B8G8R8X8 if it's not.
   gfx::SurfaceFormat format = SurfaceFormat::OS_RGBX;
-  gfx::GetYCbCrToRGBDestFormatAndSize(*decodedData, format, rgbSize);
-  if (mHasAlpha) {
+  gfx::GetYCbCrToRGBDestFormatAndSize(decodedData, format, rgbSize);
+  if (hasAlpha) {
     // We would use libyuv to do the YCbCrA -> ARGB convertion, which only
     // works for B8G8R8A8.
     format = SurfaceFormat::B8G8R8A8;
@@ -1767,10 +1596,10 @@
     return AsVariant(NonDecoderResult::OutOfMemory);
   }
 
-  if (decodedData->mAlpha) {
+  if (decodedData.mAlpha) {
     const auto wantPremultiply =
         !bool(GetSurfaceFlags() & SurfaceFlags::NO_PREMULTIPLY_ALPHA);
-    const bool& hasPremultiply = decodedData->mAlpha->mPremultiplied;
+    const bool& hasPremultiply = decodedData.mAlpha->mPremultiplied;
 
     PremultFunc premultOp = nullptr;
     if (wantPremultiply && !hasPremultiply) {
@@ -1782,39 +1611,21 @@
     MOZ_LOG(sAVIFLog, LogLevel::Debug,
             ("[this=%p] calling gfx::ConvertYCbCrAToARGB premultOp: %p", this,
              premultOp));
-    gfx::ConvertYCbCrAToARGB(*decodedData, *decodedData->mAlpha, format,
-                             rgbSize, rgbBuf.get(), rgbStride.value(),
-                             premultOp);
+    gfx::ConvertYCbCrAToARGB(decodedData, *decodedData.mAlpha, format, rgbSize,
+                             rgbBuf.get(), rgbStride.value(), premultOp);
   } else {
     MOZ_LOG(sAVIFLog, LogLevel::Debug,
             ("[this=%p] calling gfx::ConvertYCbCrToRGB", this));
-    gfx::ConvertYCbCrToRGB(*decodedData, format, rgbSize, rgbBuf.get(),
+    gfx::ConvertYCbCrToRGB(decodedData, format, rgbSize, rgbBuf.get(),
                            rgbStride.value());
   }
 
   MOZ_LOG(sAVIFLog, LogLevel::Debug,
           ("[this=%p] calling SurfacePipeFactory::CreateSurfacePipe", this));
-
-  Maybe<SurfacePipe> pipe = Nothing();
+  Maybe<SurfacePipe> pipe = SurfacePipeFactory::CreateReorientSurfacePipe(
+      this, Size(), OutputSize(), format, mTransform, GetOrientation());
 
-  if (mIsAnimated) {
-    SurfaceFormat outFormat =
-        decodedData->mAlpha ? SurfaceFormat::OS_RGBA : SurfaceFormat::OS_RGBX;
-    Maybe<AnimationParams> animParams;
-    if (!IsFirstFrameDecode()) {
-      animParams.emplace(decodedData->mRenderRect.ToUnknownRect(),
-                         parsedImage.mDuration, parsedImage.mFrameNum,
-                         BlendMethod::SOURCE, DisposalMethod::CLEAR_ALL);
-    }
-    pipe = SurfacePipeFactory::CreateSurfacePipe(
-        this, Size(), OutputSize(), decodedData->mRenderRect, format, outFormat,
-        animParams, mTransform, SurfacePipeFlags());
-  } else {
-    pipe = SurfacePipeFactory::CreateReorientSurfacePipe(
-        this, Size(), OutputSize(), format, mTransform, GetOrientation());
-  }
-
-  if (pipe.isNothing()) {
+  if (!pipe) {
     MOZ_LOG(sAVIFLog, LogLevel::Debug,
             ("[this=%p] could not initialize surface pipe", this));
     return AsVariant(NonDecoderResult::PipeInitError);
@@ -1845,20 +1656,10 @@
           ("[this=%p] writing to surface complete", this));
 
   if (writeBufferResult == WriteState::FINISHED) {
-    PostFrameStop(mHasAlpha ? Opacity::SOME_TRANSPARENCY
-                            : Opacity::FULLY_OPAQUE);
-
-    if (!mIsAnimated || IsFirstFrameDecode()) {
-      PostDecodeDone(0);
-      return DecodeResult(NonDecoderResult::Complete);
-    }
-
-    if (isDone) {
-      PostDecodeDone(-1);
-      return DecodeResult(NonDecoderResult::Complete);
-    }
-
-    return DecodeResult(NonDecoderResult::OutputAvailable);
+    PostFrameStop(hasAlpha ? Opacity::SOME_TRANSPARENCY
+                           : Opacity::FULLY_OPAQUE);
+    PostDecodeDone();
+    return r;
   }
 
   return AsVariant(NonDecoderResult::WriteBufferError);
@@ -1866,10 +1667,11 @@
 
 /* static */
 bool nsAVIFDecoder::IsDecodeSuccess(const DecodeResult& aResult) {
-  return aResult == DecodeResult(NonDecoderResult::OutputAvailable) ||
-         aResult == DecodeResult(NonDecoderResult::Complete) ||
-         aResult == DecodeResult(Dav1dResult(0)) ||
-         aResult == DecodeResult(AOMResult(AOM_CODEC_OK));
+  if (aResult.is<Dav1dResult>() || aResult.is<AOMResult>()) {
+    return aResult == DecodeResult(Dav1dResult(0)) ||
+           aResult == DecodeResult(AOMResult(AOM_CODEC_OK));
+  }
+  return false;
 }
 
 void nsAVIFDecoder::RecordDecodeResultTelemetry(
@@ -1890,7 +1692,7 @@
       case MP4PARSE_STATUS_OOM:
         AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::out_of_memory);
         return;
-      case MP4PARSE_STATUS_MISSING_AVIF_OR_AVIS_BRAND:
+      case MP4PARSE_STATUS_MISSING_BRAND:
         AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::missing_brand);
         return;
       case MP4PARSE_STATUS_FTYP_NOT_FIRST:
@@ -1899,10 +1701,10 @@
       case MP4PARSE_STATUS_NO_IMAGE:
         AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::no_image);
         return;
-      case MP4PARSE_STATUS_MOOV_BAD_QUANTITY:
+      case MP4PARSE_STATUS_MULTIPLE_MOOV:
         AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::multiple_moov);
         return;
-      case MP4PARSE_STATUS_MOOV_MISSING:
+      case MP4PARSE_STATUS_NO_MOOV:
         AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::no_moov);
         return;
       case MP4PARSE_STATUS_LSEL_NO_ESSENTIAL:
@@ -1917,7 +1719,7 @@
       case MP4PARSE_STATUS_TXFORM_NO_ESSENTIAL:
         AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::txform_no_essential);
         return;
-      case MP4PARSE_STATUS_PITM_MISSING:
+      case MP4PARSE_STATUS_NO_PRIMARY_ITEM:
         AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::no_primary_item);
         return;
       case MP4PARSE_STATUS_IMAGE_ITEM_TYPE:
@@ -1929,15 +1731,12 @@
       case MP4PARSE_STATUS_CONSTRUCTION_METHOD:
         AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::construction_method);
         return;
-      case MP4PARSE_STATUS_ILOC_MISSING:
+      case MP4PARSE_STATUS_ITEM_LOC_NOT_FOUND:
         AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::item_loc_not_found);
         return;
-      case MP4PARSE_STATUS_IDAT_MISSING:
+      case MP4PARSE_STATUS_NO_ITEM_DATA_BOX:
         AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::no_item_data_box);
         return;
-      default:
-        AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::uncategorized);
-        return;
     }
 
     MOZ_LOG(sAVIFLog, LogLevel::Error,
@@ -1950,9 +1749,10 @@
     switch (aResult.as<NonDecoderResult>()) {
       case NonDecoderResult::NeedMoreData:
         return;
-      case NonDecoderResult::OutputAvailable:
+      case NonDecoderResult::MetadataOk:
         return;
-      case NonDecoderResult::Complete:
+      case NonDecoderResult::NoPrimaryItem:
+        AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::no_primary_item);
         return;
       case NonDecoderResult::SizeOverflow:
         AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::size_overflow);
@@ -1978,9 +1778,6 @@
       case NonDecoderResult::InvalidCICP:
         AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::invalid_cicp);
         return;
-      case NonDecoderResult::NoSamples:
-        AccumulateCategorical(LABELS_AVIF_DECODE_RESULT::no_samples);
-        return;
     }
     MOZ_ASSERT_UNREACHABLE("unknown NonDecoderResult");
   } else {